[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 100,
            "classifier:CustomMLPClassifier:tol": 0.0001,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2367087856229932,
        "time": 18.091170072555542,
        "additional_info": {
            "duration": 18.071888208389282,
            "num_run": 2,
            "train_loss": 1.1855734782226404,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005897913068713326,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015283020493786284,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 1.4677592009332837e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009994383306256792,
            "feature_preprocessor:select_percentile_classification:percentile": 83.71076102633408,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.397885799407959,
        "additional_info": {
            "duration": 0.38796496391296387,
            "num_run": 3,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017335374469244055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21446023234155723,
            "classifier:CustomMLPClassifier:max_iter": 394,
            "classifier:CustomMLPClassifier:num_units": 393,
            "classifier:CustomMLPClassifier:tol": 0.00020669606778637786,
            "feature_preprocessor:select_rates_classification:alpha": 0.37074326113847605,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2654910087585449,
        "additional_info": {
            "duration": 0.25269412994384766,
            "num_run": 4,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001265432263937216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025210486300051585,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 172,
            "classifier:CustomMLPClassifier:tol": 1.3134515968729273e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.886128143254935,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.783099889755249,
        "additional_info": {
            "duration": 0.7720029354095459,
            "num_run": 5,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.476537348642138e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6094187968363136,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.000623601061960284,
            "feature_preprocessor:select_rates_classification:alpha": 0.37277199716070397,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3030369517356415,
        "time": 0.881397008895874,
        "additional_info": {
            "duration": 0.8705470561981201,
            "num_run": 6,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.150721995132133e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010880231565364893,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0032008478454880612,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.034494424153546144,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8627567984926874,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.22914783173691,
        "time": 0.5301451683044434,
        "additional_info": {
            "duration": 0.5182552337646484,
            "num_run": 7,
            "train_loss": 1.1656863517037521,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.1977691813522454e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.44966367306334676,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.005806128069380193,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008876578344611543,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 93,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.27320045729587017,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.27195119857788086,
        "additional_info": {
            "duration": 0.2571089267730713,
            "num_run": 8,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03859643951467421,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07212176876171598,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 361,
            "classifier:CustomMLPClassifier:tol": 0.003501543999506037,
            "feature_preprocessor:select_percentile_classification:percentile": 48.494598649907545,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2167779925267004,
        "time": 0.6212677955627441,
        "additional_info": {
            "duration": 0.6104958057403564,
            "num_run": 9,
            "train_loss": 1.1667923204412074,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.024396726173774e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000792752159797921,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.008568517736793516,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4481637321671371,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2371047037875345,
        "time": 0.30535101890563965,
        "additional_info": {
            "duration": 0.29410409927368164,
            "num_run": 10,
            "train_loss": 1.2151499079822088,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06862574858369185,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2414705937698689,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.0004247433846422957,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0045061439293198995,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9751862084707652,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18855683871509393,
            "feature_preprocessor:select_rates_classification:alpha": 0.3892699199835357,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2213615635729156,
        "time": 0.7919330596923828,
        "additional_info": {
            "duration": 0.7821698188781738,
            "num_run": 11,
            "train_loss": 1.1648081939338708,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.723027284717073e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.505587032871814,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 5.6354003801170204e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9722544287969952,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21522768778089335,
            "feature_preprocessor:select_rates_classification:alpha": 0.1812799335421737,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2322797260042366,
        "time": 0.38051700592041016,
        "additional_info": {
            "duration": 0.3581428527832031,
            "num_run": 12,
            "train_loss": 1.215879277445933,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02683719952638259,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06633170750014386,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.00031530305446425235,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001668707509960177,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3886107328722359,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.6628537178039551,
        "additional_info": {
            "duration": 0.6507210731506348,
            "num_run": 13,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.05249542172866937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004188909157346811,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.00026476726661527685,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004410345835796556,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1518,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.43663722520916537,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2047976285425104,
        "time": 1.179542064666748,
        "additional_info": {
            "duration": 1.1655361652374268,
            "num_run": 14,
            "train_loss": 1.1917542425810492,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00030747037210996975,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029201272021023533,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 68,
            "classifier:CustomMLPClassifier:tol": 0.002123318180609504,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001781538005544095,
            "feature_preprocessor:select_percentile_classification:percentile": 94.77192508451762,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2163772545642122,
        "time": 0.37403392791748047,
        "additional_info": {
            "duration": 0.3650069236755371,
            "num_run": 15,
            "train_loss": 1.1567113095486505,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.144926298297148e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0044571831041700614,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.0001494872415880724,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012064204297113131,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1852,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3961415674757193,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.263167309388715,
        "time": 3.52042818069458,
        "additional_info": {
            "duration": 3.509864091873169,
            "num_run": 16,
            "train_loss": 1.1495059321472427,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.013667450274511318,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002683940614542233,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.0032198373003722897,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030313169974890076,
            "feature_preprocessor:select_percentile_classification:percentile": 59.448412553942156,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2311499281830431,
        "time": 0.5885171890258789,
        "additional_info": {
            "duration": 0.5783851146697998,
            "num_run": 17,
            "train_loss": 1.1856635546226895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.019679291100255097,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005625785062777898,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.0008281794768626896,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6428823248551099,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.212928311061893,
        "time": 2.2632687091827393,
        "additional_info": {
            "duration": 2.25173282623291,
            "num_run": 18,
            "train_loss": 1.1743777778870355,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.058329075522913554,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008323775013215857,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.0002203549281278223,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47198491449459856,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5225647996842755,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.21443953787952,
        "time": 0.37239599227905273,
        "additional_info": {
            "duration": 0.3545050621032715,
            "num_run": 19,
            "train_loss": 1.1824386317122362,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.857283223899601e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07840471570087341,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 382,
            "classifier:CustomMLPClassifier:tol": 0.002569699344738012,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1517,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 52.94814165425963,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2170161827568997,
        "time": 1.2076282501220703,
        "additional_info": {
            "duration": 1.1960439682006836,
            "num_run": 20,
            "train_loss": 1.0758063424219795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06370771208734785,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00262116186723666,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.0002506626945432468,
            "feature_preprocessor:select_rates_classification:alpha": 0.443933282692911,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2164013932529694,
        "time": 2.345839023590088,
        "additional_info": {
            "duration": 2.335103988647461,
            "num_run": 21,
            "train_loss": 1.1497267815734389,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0013867022051473113,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4870231510181037,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 0.0005660026212963992,
            "feature_preprocessor:select_percentile_classification:percentile": 6.685533457577548,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2380880463356103,
        "time": 0.3303709030151367,
        "additional_info": {
            "duration": 0.32003092765808105,
            "num_run": 22,
            "train_loss": 1.2182969559688943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0654140214410158,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005677333767602436,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 0.0003698540693409464,
            "feature_preprocessor:select_rates_classification:alpha": 0.08244652302451608,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2212102785770955,
        "time": 0.6827361583709717,
        "additional_info": {
            "duration": 0.6730539798736572,
            "num_run": 23,
            "train_loss": 1.177277240461923,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.076721240773074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00040293315961202007,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.0008810184439816845,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030474828505277312,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7383569263246159,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15253960813617048,
            "feature_preprocessor:select_rates_classification:alpha": 0.39311692359257144,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2170322752160712,
        "time": 2.375310182571411,
        "additional_info": {
            "duration": 2.3648858070373535,
            "num_run": 24,
            "train_loss": 1.1420338063163769,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.411177586270234e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026402468607873864,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.0012645991098751326,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7404375532907088,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2256956717277077,
        "time": 0.5066089630126953,
        "additional_info": {
            "duration": 0.4946482181549072,
            "num_run": 25,
            "train_loss": 1.1948925698621424,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05839383084348327,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3978285683302013,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.0009567879479089988,
            "feature_preprocessor:select_percentile_classification:percentile": 50.0,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.229909076513958,
        "time": 1.2395870685577393,
        "additional_info": {
            "duration": 1.228895902633667,
            "num_run": 26,
            "train_loss": 1.1150813699966453,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000236531628342111,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001230094442752762,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 0.007852946437910447,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3361998099599953,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.36681103706359863,
        "additional_info": {
            "duration": 0.3486630916595459,
            "num_run": 27,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.04746510094727654,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09485871126857565,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 3.647761482654516e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 711,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.3476501193967589,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3030369517356415,
        "time": 0.3539698123931885,
        "additional_info": {
            "duration": 0.34413695335388184,
            "num_run": 28,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.010427372232218486,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022125373469100338,
            "classifier:CustomMLPClassifier:max_iter": 334,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 8.419072842643754e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008158111563969839,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1601501538350173,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.0149619579315186,
        "additional_info": {
            "duration": 1.0043408870697021,
            "num_run": 29,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0022974930347272908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002028108749596068,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 4.5034407114629256e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 280,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.41080638139000764,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2098318281445477,
        "time": 1.2183411121368408,
        "additional_info": {
            "duration": 1.2073719501495361,
            "num_run": 30,
            "train_loss": 1.156436414282425,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009006223980979343,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01298385489308749,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.0004940919741222152,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3994394529286782,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2178965276114249,
        "time": 1.3594489097595215,
        "additional_info": {
            "duration": 1.34757399559021,
            "num_run": 31,
            "train_loss": 1.0596671933603932,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018778636262654757,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14663604996262836,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.004966855183906988,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006073959831932285,
            "feature_preprocessor:select_percentile_classification:percentile": 51.417540690277164,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.5280711650848389,
        "additional_info": {
            "duration": 0.5129590034484863,
            "num_run": 32,
            "train_loss": 1.2244567981454293,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0024533236510533548,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00030241277614746136,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 8.721494562098615e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005301373180308817,
            "feature_preprocessor:select_percentile_classification:percentile": 26.341910581141473,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2252659653537594,
        "time": 2.0921077728271484,
        "additional_info": {
            "duration": 2.082426071166992,
            "num_run": 33,
            "train_loss": 1.202247883307357,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004692660894520014,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015523019535397435,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 1.7743788009285407e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1613,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.49519137754687104,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2080952870490094,
        "time": 0.7254171371459961,
        "additional_info": {
            "duration": 0.714946985244751,
            "num_run": 34,
            "train_loss": 1.1579277029992041,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03817059476630297,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031854278613732256,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 125,
            "classifier:CustomMLPClassifier:tol": 0.003265606131491408,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011483525856696548,
            "feature_preprocessor:select_percentile_classification:percentile": 34.6049440157356,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.22864294052124023,
        "additional_info": {
            "duration": 0.21779108047485352,
            "num_run": 35,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1959137858133926e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28533161872552937,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 357,
            "classifier:CustomMLPClassifier:tol": 0.005843509541824004,
            "feature_preprocessor:select_percentile_classification:percentile": 78.21066347779224,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5383617877960205,
        "additional_info": {
            "duration": 0.5266947746276855,
            "num_run": 36,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0067344424500983355,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008584940867169083,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.0007120559739830838,
            "feature_preprocessor:select_rates_classification:alpha": 0.0587415496138743,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.6266067028045654,
        "additional_info": {
            "duration": 0.6162800788879395,
            "num_run": 37,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00061386733614085,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015555790201091628,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 119,
            "classifier:CustomMLPClassifier:tol": 2.0652854333698714e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 121,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.4003974682140337,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.21896677539388,
        "time": 5.5792388916015625,
        "additional_info": {
            "duration": 5.568626880645752,
            "num_run": 38,
            "train_loss": 1.1904570673048642,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0934817660030496e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00047804257340836547,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 0.00040434219594676405,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0612780639002047,
            "feature_preprocessor:select_percentile_classification:percentile": 20.305570779932296,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2216319387214578,
        "time": 0.5327508449554443,
        "additional_info": {
            "duration": 0.5233778953552246,
            "num_run": 39,
            "train_loss": 1.1989131095526309,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0047330866349142055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017538020225101553,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.002374056562909372,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1568,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.37060821217178047,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2842198540766154,
        "time": 0.6805529594421387,
        "additional_info": {
            "duration": 0.6709527969360352,
            "num_run": 40,
            "train_loss": 1.1444846084974938,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04660009916434344,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0167279550653417,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 90,
            "classifier:CustomMLPClassifier:tol": 0.009403207369778472,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037127710392000483,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 132,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.4065209962496317,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2146889908461884,
        "time": 0.622546911239624,
        "additional_info": {
            "duration": 0.6112771034240723,
            "num_run": 41,
            "train_loss": 1.0189874726983084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0848591290985738,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010851622542453919,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.008269182466601294,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039500041995325495,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1857,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 86.60860196991611,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2008208007706398,
        "time": 0.2216329574584961,
        "additional_info": {
            "duration": 0.21214890480041504,
            "num_run": 42,
            "train_loss": 1.1696017066160456,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.015997304796426456,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020103244220069094,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 0.000881337222417273,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12033845884348994,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1248,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5430596490780737,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2178965276114249,
        "time": 1.4159538745880127,
        "additional_info": {
            "duration": 1.4005670547485352,
            "num_run": 43,
            "train_loss": 1.1810217371485356,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05001536156550614,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08213603697006888,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0025484200575993958,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 911,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2372962199312831,
        "time": 0.8065509796142578,
        "additional_info": {
            "duration": 0.792769193649292,
            "num_run": 44,
            "train_loss": 1.2103860381875005,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05249542172866937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004188909157346811,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.0001622094392045569,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0029453681128475792,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1518,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4384770393371582,
        "additional_info": {
            "duration": 0.42792701721191406,
            "num_run": 45,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05872579881824996,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009726516832935041,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 2.724752688381913e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007445058716574334,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1477,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.10068509104331522,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2040363837654622,
        "time": 0.4029827117919922,
        "additional_info": {
            "duration": 0.39168882369995117,
            "num_run": 46,
            "train_loss": 1.1733706062552216,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08068060479409035,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003625580023296855,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 0.0008991118251829686,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006846691241123535,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1766,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2407623242621932,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2115603230105,
        "time": 1.2763309478759766,
        "additional_info": {
            "duration": 1.2663109302520752,
            "num_run": 47,
            "train_loss": 1.1872716557251197,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.297589587238001e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.035037175753381306,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 2.754400854302113e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015775334898099232,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1929,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.40655897731876445,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2098479206037192,
        "time": 0.538707971572876,
        "additional_info": {
            "duration": 0.5280570983886719,
            "num_run": 48,
            "train_loss": 1.1634866157051227,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004349844857173234,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016120417809628865,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 5.154407760025788e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01817330894350736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1896,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.31525008751360156,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2185225798518244,
        "time": 7.509442090988159,
        "additional_info": {
            "duration": 7.498624086380005,
            "num_run": 49,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.020771278626069097,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014142455050655745,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 2.724752688381913e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1421,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.11052654389430319,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.203646908539443,
        "time": 0.47840094566345215,
        "additional_info": {
            "duration": 0.4129350185394287,
            "num_run": 50,
            "train_loss": 1.17033107607977,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03368331568756396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01904737441300726,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 2.724752688381913e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1425,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.11052654389430319,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.219105184437412,
        "time": 0.5512793064117432,
        "additional_info": {
            "duration": 0.5409588813781738,
            "num_run": 51,
            "train_loss": 1.172812095017178,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06784620324591227,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017152265283810003,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 3.6396215716906125e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1483,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2171304531116744,
        "time": 1.90049409866333,
        "additional_info": {
            "duration": 1.8904078006744385,
            "num_run": 52,
            "train_loss": 1.0086286596376617,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.036399842561504324,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12154607824041103,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 67,
            "classifier:CustomMLPClassifier:tol": 1.5649743336346207e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1571,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.059810594955318847,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.200951163584586,
        "time": 0.3939700126647949,
        "additional_info": {
            "duration": 0.3790779113769531,
            "num_run": 53,
            "train_loss": 1.0987452005926008,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0054508073091038825,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011481955619431215,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 90,
            "classifier:CustomMLPClassifier:tol": 1.0242735972698086e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1546,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.06008272601232386,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2115522767809144,
        "time": 0.34826207160949707,
        "additional_info": {
            "duration": 0.3378109931945801,
            "num_run": 54,
            "train_loss": 1.1740668520607904,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0019737104373195938,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04694277984879483,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.0005723755078965789,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1247,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.42431705974285794,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.8117749691009521,
        "additional_info": {
            "duration": 0.7883913516998291,
            "num_run": 55,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007472157078530408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032304989951199466,
            "classifier:CustomMLPClassifier:max_iter": 385,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.001981227137640852,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05819635563521129,
            "feature_preprocessor:select_rates_classification:alpha": 0.26587143497144206,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.39540982246398926,
        "additional_info": {
            "duration": 0.3801901340484619,
            "num_run": 56,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00026010460032213027,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006393074915203024,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 4.148684711678321e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1546,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2001818725779523,
        "time": 1.6646881103515625,
        "additional_info": {
            "duration": 1.6482582092285156,
            "num_run": 57,
            "train_loss": 1.0616995519040309,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.99651083057105e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09761901963123036,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 117,
            "classifier:CustomMLPClassifier:tol": 1.9160953522255673e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7004586268252957,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.206144694412029,
        "time": 1.506504774093628,
        "additional_info": {
            "duration": 1.4935939311981201,
            "num_run": 58,
            "train_loss": 1.132260814348201,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00025139633064297744,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022184211802711476,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 1.6451721128990695e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1960,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.35411081759550056,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2360698574303055,
        "time": 1.3722710609436035,
        "additional_info": {
            "duration": 1.3563387393951416,
            "num_run": 59,
            "train_loss": 1.0103082479913064,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.001782508911505772,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014654635450241784,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 0.0003348007027440291,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004547904345264383,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9574247629627,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.01493915821827229,
            "feature_preprocessor:select_percentile_classification:percentile": 80.59059205125176,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2322684533430126,
        "time": 1.752690076828003,
        "additional_info": {
            "duration": 1.7428579330444336,
            "num_run": 60,
            "train_loss": 1.0134704043561376,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00012538723550569822,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03590649060267577,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 212,
            "classifier:CustomMLPClassifier:tol": 0.001988755024440317,
            "feature_preprocessor:select_percentile_classification:percentile": 37.63367876529304,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2675094637730926,
        "time": 0.6882288455963135,
        "additional_info": {
            "duration": 0.6777417659759521,
            "num_run": 61,
            "train_loss": 1.0472882232323903,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.018284840414558776,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11128748852764536,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 4.011333393440612e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004578900357245931,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1640,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.04327499989179474,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2011732613556139,
        "time": 0.31859922409057617,
        "additional_info": {
            "duration": 0.3083059787750244,
            "num_run": 62,
            "train_loss": 1.1809473429954571,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.687161163919677e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010082582610034469,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 1.0104069022446043e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000394133056993782,
            "feature_preprocessor:select_rates_classification:alpha": 0.2838798626521474,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2032864017248832,
        "time": 2.1946229934692383,
        "additional_info": {
            "duration": 2.1842668056488037,
            "num_run": 63,
            "train_loss": 1.151463322668977,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02155912130058087,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4061599811277009,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 2.414929615972391e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27754083112688427,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1492,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2400499017090594,
        "time": 0.6477289199829102,
        "additional_info": {
            "duration": 0.6375868320465088,
            "num_run": 64,
            "train_loss": 1.1864074585957343,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.019644497657925607,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12154607824041103,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 2.5334474681753785e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007809367880625184,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1598,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.059810594955318847,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2485378745361184,
        "time": 0.8156559467315674,
        "additional_info": {
            "duration": 0.8033058643341064,
            "num_run": 65,
            "train_loss": 1.051265770821481,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0955021907833516,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11042180794741838,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.0006707473374969002,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018073982548354805,
            "feature_preprocessor:select_percentile_classification:percentile": 1.1279337957411615,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3481729030609131,
        "additional_info": {
            "duration": 0.3343961238861084,
            "num_run": 66,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04018344145588125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6270328768994716,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.009532451553204105,
            "feature_preprocessor:select_rates_classification:alpha": 0.12455221908514486,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12150406837463379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005491435925007868,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5817931378789849,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 409,
            "classifier:CustomMLPClassifier:tol": 0.008539910985001696,
            "feature_preprocessor:select_rates_classification:alpha": 0.35969692586296176,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4509408473968506,
        "additional_info": {
            "duration": 0.4400780200958252,
            "num_run": 68,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.003487613651442055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5684031553533019,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.009253931522108088,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.28980145579651206,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2064971549970032,
        "time": 1.4352610111236572,
        "additional_info": {
            "duration": 1.4213457107543945,
            "num_run": 69,
            "train_loss": 1.0870142442338657,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.263538124208306e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001662355510388048,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.00039440793734790784,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06536587390098643,
            "feature_preprocessor:select_rates_classification:alpha": 0.17441705914673908,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.22531366348266602,
        "additional_info": {
            "duration": 0.16442394256591797,
            "num_run": 70,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.712178573596775e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7330189207737281,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.009623360202585203,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023797930129803614,
            "feature_preprocessor:select_rates_classification:alpha": 0.3555955160041511,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2258372972781226,
        "time": 0.34139013290405273,
        "additional_info": {
            "duration": 0.32364988327026367,
            "num_run": 71,
            "train_loss": 1.1861534855113827,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015987793769387227,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.009726079835735176,
            "feature_preprocessor:select_rates_classification:alpha": 0.02462410299946722,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12195491790771484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00034088325177356776,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09834490117602246,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.0006880901012131309,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01876771917566287,
            "feature_preprocessor:select_rates_classification:alpha": 0.28955503844736763,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.5308312845892662,
        "time": 0.8029580116271973,
        "additional_info": {
            "duration": 0.7857332229614258,
            "num_run": 73,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005137304057668938,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013015543715525211,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 230,
            "classifier:CustomMLPClassifier:tol": 0.00012852303348711468,
            "feature_preprocessor:select_rates_classification:alpha": 0.4703879492295781,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.319760799407959,
        "additional_info": {
            "duration": 0.30959081649780273,
            "num_run": 74,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002015764977627209,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1187396863357382,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 291,
            "classifier:CustomMLPClassifier:tol": 0.0031251415218264706,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14220062354246824,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 410,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2251189314161538,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2449553517129697,
        "time": 0.8256890773773193,
        "additional_info": {
            "duration": 0.8035478591918945,
            "num_run": 75,
            "train_loss": 1.1290417052414763,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.003487613651442055,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8478200648967732,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.00959799511122787,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.75,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_rates_classification:alpha": 0.2801222745567852,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2353327513420147,
        "time": 1.2108781337738037,
        "additional_info": {
            "duration": 1.1987378597259521,
            "num_run": 76,
            "train_loss": 1.1340868579749632,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.9498849579373572e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6157301317909962,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.009508998848409927,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010776286188935369,
            "feature_preprocessor:select_rates_classification:alpha": 0.324165013337425,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3030369517356415,
        "time": 0.7169458866119385,
        "additional_info": {
            "duration": 0.7050931453704834,
            "num_run": 77,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.978251238824336e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026045270098192873,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 3.349208023702451e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001641412144662612,
            "feature_preprocessor:select_percentile_classification:percentile": 69.82307145957195,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2119369222842313,
        "time": 4.863576173782349,
        "additional_info": {
            "duration": 4.851860046386719,
            "num_run": 78,
            "train_loss": 1.0294212537808582,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00046682111337745344,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7695613341060388,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.009977006901634944,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7629483790657838,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.01033842187844464,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7280169652874974,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.4002809524536133,
        "additional_info": {
            "duration": 0.38527584075927734,
            "num_run": 79,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04018344145588125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6270328768994716,
            "classifier:CustomMLPClassifier:max_iter": 246,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.009532451553204105,
            "feature_preprocessor:select_rates_classification:alpha": 0.14315771842862535,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.289691816206942,
        "time": 1.7252748012542725,
        "additional_info": {
            "duration": 1.709017038345337,
            "num_run": 80,
            "train_loss": 1.2138678410841692,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.712178573596775e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.897375725708568,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.009623360202585203,
            "feature_preprocessor:select_rates_classification:alpha": 0.3735166605043393,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.2096700668334961,
        "additional_info": {
            "duration": 0.19856500625610352,
            "num_run": 81,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.22112308946174e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4627794348325334,
            "classifier:CustomMLPClassifier:max_iter": 145,
            "classifier:CustomMLPClassifier:num_units": 364,
            "classifier:CustomMLPClassifier:tol": 0.00016758388811196975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1537,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 62.58442851145582,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2340162670997747,
        "time": 1.2363059520721436,
        "additional_info": {
            "duration": 1.2252569198608398,
            "num_run": 82,
            "train_loss": 1.2119220781698914,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.177603951486227e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018681432164459555,
            "classifier:CustomMLPClassifier:max_iter": 327,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 3.0448619292611056e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011155536895018357,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9361706808022429,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21845006334326272,
            "feature_preprocessor:select_rates_classification:alpha": 0.25086503760666135,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2270942414063792,
        "time": 2.5771570205688477,
        "additional_info": {
            "duration": 2.567415237426758,
            "num_run": 83,
            "train_loss": 1.2236861581867822,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02314862770899447,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8979822349929073,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.009944353611295581,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.16319195656325605,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.5308312845892662,
        "time": 0.4383420944213867,
        "additional_info": {
            "duration": 0.4271218776702881,
            "num_run": 84,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0024610888263716835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.009756337557488256,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.03554848581013665,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09536623954772949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00017067442654526398,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.058743851522569335,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.00013595352214231833,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005567783420910715,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1045,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6281715960591949,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.206751437686374,
        "time": 0.8109619617462158,
        "additional_info": {
            "duration": 0.8001971244812012,
            "num_run": 86,
            "train_loss": 1.1789085967792663,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.551476914170198e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026533909311567444,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 215,
            "classifier:CustomMLPClassifier:tol": 0.008696151422960244,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1929,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.36031824286111547,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2132968641060384,
        "time": 0.4161651134490967,
        "additional_info": {
            "duration": 0.4004700183868408,
            "num_run": 87,
            "train_loss": 1.1610241859165493,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04160281341775082,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.040901372197335424,
            "classifier:CustomMLPClassifier:max_iter": 103,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.009757487780421603,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002442633173667993,
            "feature_preprocessor:select_rates_classification:alpha": 0.10234255775994128,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3423171043395996,
        "additional_info": {
            "duration": 0.3304481506347656,
            "num_run": 88,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0019487459093043254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6864585084657618,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048748993847909226,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.22775406914263407,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.46832704544067383,
        "additional_info": {
            "duration": 0.45667505264282227,
            "num_run": 89,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04018344145588125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9590025742053296,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.009709093832504479,
            "feature_preprocessor:select_rates_classification:alpha": 0.11820157936386562,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12254476547241211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004202150431689469,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9432582049285833,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.009784708828772871,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048748993847909226,
            "feature_preprocessor:select_percentile_classification:percentile": 50.701162496988196,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2500024272672952,
        "time": 0.6192841529846191,
        "additional_info": {
            "duration": 0.6085927486419678,
            "num_run": 91,
            "train_loss": 1.183137784419669,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01600775182566876,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9762761893108409,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.009936005210484577,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1021,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.16319195656325605,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.5742530822753906,
        "additional_info": {
            "duration": 0.5630331039428711,
            "num_run": 92,
            "train_loss": 1.2243341719560497,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04018344145588125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9978666280802154,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 0.009821948954972966,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.1410025822448329,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2473614026284745,
        "time": 0.36197781562805176,
        "additional_info": {
            "duration": 0.34837794303894043,
            "num_run": 93,
            "train_loss": 1.168929289894215,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06252512159836274,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472638616959933,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.009948897921256817,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 940,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1549728606420669,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1840106292804495,
        "time": 1.0023632049560547,
        "additional_info": {
            "duration": 0.988210916519165,
            "num_run": 94,
            "train_loss": 1.1590819037729607,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012014306831076634,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029890843976479963,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 358,
            "classifier:CustomMLPClassifier:tol": 0.004443038112969675,
            "feature_preprocessor:select_rates_classification:alpha": 0.02503000569292193,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.3851778507232666,
        "additional_info": {
            "duration": 0.31490302085876465,
            "num_run": 95,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008857483610769294,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012739954211833661,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 3.5656585259406875e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.051202472047363876,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 928,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 26.999525941036538,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.250642968675802,
        "time": 3.0613789558410645,
        "additional_info": {
            "duration": 3.0477187633514404,
            "num_run": 96,
            "train_loss": 1.1161960594396931,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.859420463809753e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03081192485686142,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 0.0012261422160405435,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7259048971528742,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07364608092156574,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.762797736857617,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.20598214667974,
        "time": 0.6679770946502686,
        "additional_info": {
            "duration": 0.6560649871826172,
            "num_run": 97,
            "train_loss": 1.184494819339612,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07280699091911962,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018617071212441955,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 0.00025317347589732007,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07225184689644489,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9078286998761704,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03505223582880262,
            "feature_preprocessor:select_rates_classification:alpha": 0.33242284616775286,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5083038806915283,
        "additional_info": {
            "duration": 0.44302892684936523,
            "num_run": 98,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.011686976037342298,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03628988705389542,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1005098819732666,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005968588179813861,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9895603894098801,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 7.005729604358916e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.288484890979534,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09632301330566406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0014436677036753541,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.994255684722812,
            "classifier:CustomMLPClassifier:max_iter": 379,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 1.9250900433532044e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06698369378963454,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5236361026763916,
        "additional_info": {
            "duration": 0.5119340419769287,
            "num_run": 101,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002193791619471991,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012250162462577412,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 408,
            "classifier:CustomMLPClassifier:tol": 3.0664053196246924e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036059427598014453,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.751201988666758,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2401577291253125,
        "time": 3.672563314437866,
        "additional_info": {
            "duration": 3.6596381664276123,
            "num_run": 102,
            "train_loss": 1.1789295189611402,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010462185751109803,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.009742194204250562,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008978187890359377,
            "feature_preprocessor:select_rates_classification:alpha": 0.012769181240628516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12243771553039551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.389871033294922e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038266232660094965,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.0006039921744738981,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039204566177455095,
            "feature_preprocessor:select_rates_classification:alpha": 0.257345879746788,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2115764154696715,
        "time": 0.7084879875183105,
        "additional_info": {
            "duration": 0.6913759708404541,
            "num_run": 104,
            "train_loss": 1.145545252100512,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001112369279350432,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.034238198013998584,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.000534960261934283,
            "feature_preprocessor:select_rates_classification:alpha": 0.13644484617784725,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2316295251503249,
        "time": 0.7741010189056396,
        "additional_info": {
            "duration": 0.7638697624206543,
            "num_run": 105,
            "train_loss": 1.0374251548641653,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09941939521328784,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25646145306121476,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 1.0353272836129426e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.34226554921750224,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.7715082168579102,
        "additional_info": {
            "duration": 0.7599077224731445,
            "num_run": 106,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0024610888263716835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.009756337557488256,
            "feature_preprocessor:select_rates_classification:alpha": 0.01641952335383442,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12183594703674316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06631066514801422,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9511606496176751,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.00996651206919396,
            "feature_preprocessor:select_rates_classification:alpha": 0.11820157936386562,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12234187126159668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06631066514801422,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9511606496176751,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.00996651206919396,
            "feature_preprocessor:select_percentile_classification:percentile": 50.64996260429643,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.5166018009185791,
        "additional_info": {
            "duration": 0.5052549839019775,
            "num_run": 109,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005221983592020964,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.009550384600494977,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.050428303091468625,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10032320022583008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.9324348870885577e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014841208002991477,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.0020402556640258178,
            "feature_preprocessor:select_rates_classification:alpha": 0.06916691439937546,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.537194013595581,
        "additional_info": {
            "duration": 0.5237331390380859,
            "num_run": 111,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005220043345050836,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9709995187731267,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 0.009709093832504479,
            "feature_preprocessor:select_rates_classification:alpha": 0.0909771109071026,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2192435934809438,
        "time": 0.7553339004516602,
        "additional_info": {
            "duration": 0.7446110248565674,
            "num_run": 112,
            "train_loss": 1.1808694680716898,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.000845128889431381,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 312,
            "classifier:CustomMLPClassifier:tol": 0.009756337557488256,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008096655928014888,
            "feature_preprocessor:select_rates_classification:alpha": 0.03554848581013665,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12245607376098633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010462185751109803,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.009742194204250562,
            "feature_preprocessor:select_rates_classification:alpha": 0.012769181240628516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12200331687927246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005871282182905094,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04849302470689175,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 0.0002769426334821877,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033784217845155305,
            "feature_preprocessor:select_percentile_classification:percentile": 67.68626640594601,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2350832983753466,
        "time": 0.824312686920166,
        "additional_info": {
            "duration": 0.814687967300415,
            "num_run": 115,
            "train_loss": 1.0363552166867296,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010849516983158945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002979382545512401,
            "classifier:CustomMLPClassifier:max_iter": 370,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 5.4252167729722555e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002003881894205015,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9165493616605088,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2667033223915673,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5117559161655617,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2011571688964424,
        "time": 1.320904016494751,
        "additional_info": {
            "duration": 1.3092570304870605,
            "num_run": 116,
            "train_loss": 1.1886490389581117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005839886027249374,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 204,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.009852944521134619,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010692696937960188,
            "feature_preprocessor:select_rates_classification:alpha": 0.05426734064688601,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2575971792875407,
        "time": 0.8583922386169434,
        "additional_info": {
            "duration": 0.8474619388580322,
            "num_run": 117,
            "train_loss": 1.0837689730103637,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.421983094498663e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9569067068950349,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.00959229127832403,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016536607775402626,
            "feature_preprocessor:select_rates_classification:alpha": 0.32215326490461843,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.3436288833618164,
        "additional_info": {
            "duration": 0.33186817169189453,
            "num_run": 118,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005191775976426612,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.006583847854867859,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.037523734614145765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13299989700317383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.258883582653066e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9986678684701634,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0001752189967041971,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007253123546124878,
            "feature_preprocessor:select_rates_classification:alpha": 0.048550604669722226,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.5308312845892662,
        "time": 0.608173131942749,
        "additional_info": {
            "duration": 0.5870048999786377,
            "num_run": 120,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012526447136743581,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9535376268723639,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "feature_preprocessor:select_rates_classification:alpha": 0.08765661951151232,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12864375114440918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006314988552468429,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001453048179705194,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.006636690050280634,
            "feature_preprocessor:select_rates_classification:alpha": 0.4888182329177332,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.357712984085083,
        "additional_info": {
            "duration": 0.34729528427124023,
            "num_run": 122,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0006160608950732962,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9792252065739406,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 3.0309919539921455e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.32398881070815977,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09545230865478516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00020800161809819966,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005812447061531481,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 333,
            "classifier:CustomMLPClassifier:tol": 0.007877541487585932,
            "feature_preprocessor:select_rates_classification:alpha": 0.25925971328101505,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3711056709289551,
        "additional_info": {
            "duration": 0.35719823837280273,
            "num_run": 124,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0012927208016231127,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.008421467192908217,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008978187890359377,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7271672706503381,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_rates_classification:alpha": 0.012769181240628516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.4213503067912998,
        "time": 0.2415940761566162,
        "additional_info": {
            "duration": 0.22939109802246094,
            "num_run": 125,
            "train_loss": 1.3927409811722409,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008784749690255232,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011302059741353893,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 0.001558930446393995,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006981880245823534,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 707,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.308152628327259,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.44376492500305176,
        "additional_info": {
            "duration": 0.4289700984954834,
            "num_run": 126,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09034691899480192,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018583431304568894,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 1.714006388148144e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.23523303778393972,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12138986587524414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9413395299025374e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016382549173836179,
            "classifier:CustomMLPClassifier:max_iter": 334,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 3.18484560725472e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 52.40581751334767,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2123344437398365,
        "time": 8.500658988952637,
        "additional_info": {
            "duration": 8.489654064178467,
            "num_run": 128,
            "train_loss": 1.0423325730301274,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.023871412394781584,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7063788940716542,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "feature_preprocessor:select_rates_classification:alpha": 0.10190953563109623,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0952610969543457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018594454786002223,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.008209854652264304,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09554505348205566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014389056311645042,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.805670009889839,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 1.6729606061602636e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4447584382111107,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.28643298149108887,
        "additional_info": {
            "duration": 0.2768728733062744,
            "num_run": 131,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018442028975074363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6397595174018756,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.008197147377445077,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017202584910977033,
            "feature_preprocessor:select_rates_classification:alpha": 0.02462410299946722,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1538081169128418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.3544650187311458e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9655466890347995,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 0.0012562022266058002,
            "feature_preprocessor:select_rates_classification:alpha": 0.2658840360565555,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10051989555358887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.018334791617743516,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.041666776288094745,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.0009160124769006042,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020923457340558155,
            "feature_preprocessor:select_percentile_classification:percentile": 65.46056784643145,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.8905761241912842,
        "additional_info": {
            "duration": 0.8799190521240234,
            "num_run": 134,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.029575274166845272,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9599197783012187,
            "classifier:CustomMLPClassifier:max_iter": 473,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.008095293909179558,
            "feature_preprocessor:select_rates_classification:alpha": 0.11315418522062691,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12701106071472168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05098066519787829,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016057919257590604,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 3.769047518663165e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.37581849175552057,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 3.924957036972046,
        "additional_info": {
            "duration": 3.913464069366455,
            "num_run": 136,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006742769893868684,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22589951820115864,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.003140838203807794,
            "feature_preprocessor:select_rates_classification:alpha": 0.4358021129375621,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12354898452758789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004326060465851802,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.008970457682046708,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.029802681570473118,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1268019676208496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00044768721478368167,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029660743271464843,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.000867430016384975,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009458659400933956,
            "feature_preprocessor:select_rates_classification:alpha": 0.36403039373197704,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2623939514160156,
        "additional_info": {
            "duration": 0.2505800724029541,
            "num_run": 139,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001290212983084183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07135253125904663,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 72,
            "classifier:CustomMLPClassifier:tol": 0.00018581778193633213,
            "feature_preprocessor:select_rates_classification:alpha": 0.480887034559806,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3030369517356415,
        "time": 0.31321096420288086,
        "additional_info": {
            "duration": 0.30443906784057617,
            "num_run": 140,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017974493357419245,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.009332322980307204,
            "feature_preprocessor:select_rates_classification:alpha": 0.04386705871199287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09489297866821289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022142560533467782,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4835131611169588,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 1.4409073648962321e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005505863480491896,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.38210384010458254,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3923032283782959,
        "additional_info": {
            "duration": 0.38147687911987305,
            "num_run": 142,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003801518421204781,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0934592638019372,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.003140838203807794,
            "feature_preprocessor:select_rates_classification:alpha": 0.4358021129375621,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13441109657287598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.1408563922923404e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9859552641568303,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.008262918746474477,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00809141549395813,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7676945122221934,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2257069344641764,
        "time": 0.7123210430145264,
        "additional_info": {
            "duration": 0.6993260383605957,
            "num_run": 144,
            "train_loss": 1.057470938132453,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.013518958653730245,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017080534568623282,
            "classifier:CustomMLPClassifier:max_iter": 300,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 0.00013060328748488046,
            "feature_preprocessor:select_percentile_classification:percentile": 86.63433300348096,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.34475183486938477,
        "additional_info": {
            "duration": 0.3269379138946533,
            "num_run": 145,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001423089423911111,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05374155615157093,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 1.1353935728669824e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005178895935899579,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8044806718885603,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2520931301834691,
            "feature_preprocessor:select_rates_classification:alpha": 0.3426024071318466,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5847129821777344,
        "additional_info": {
            "duration": 0.5740940570831299,
            "num_run": 146,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0018442028975074363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.37635104215220044,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.00988842705138294,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022706760139347772,
            "feature_preprocessor:select_rates_classification:alpha": 0.01692450019412484,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1232459545135498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.8476145541609893e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10753560705548862,
            "classifier:CustomMLPClassifier:max_iter": 377,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0008802785727399409,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011658114370408099,
            "feature_preprocessor:select_rates_classification:alpha": 0.19318996466386398,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15390515327453613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.0677181655085854e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005464348286607301,
            "classifier:CustomMLPClassifier:max_iter": 426,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 0.000971904014569892,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022003564615553054,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.22182996161462953,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2312529258765936,
        "time": 0.3707718849182129,
        "additional_info": {
            "duration": 0.35749197006225586,
            "num_run": 149,
            "train_loss": 1.1837985735340433,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0033748235395084803,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017096675968226636,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.0001639741437622606,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06675918316951268,
            "feature_preprocessor:select_rates_classification:alpha": 0.43101516176089827,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09577107429504395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.031267670615078465,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006540800380404522,
            "classifier:CustomMLPClassifier:max_iter": 203,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 0.008032458744656598,
            "feature_preprocessor:select_rates_classification:alpha": 0.323205122313384,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12668609619140625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.848093619455556e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0023928295343249766,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 0.00019151953431149814,
            "feature_preprocessor:select_rates_classification:alpha": 0.1300969471291081,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12270808219909668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008181908745208874,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012720882273719538,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 5.0223220139881655e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1651280680058271,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09475398063659668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.905254951721235e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01721271012362381,
            "classifier:CustomMLPClassifier:max_iter": 118,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 5.079490221221602e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023745292506877874,
            "feature_preprocessor:select_rates_classification:alpha": 0.17546339387218715,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.5436956882476807,
        "additional_info": {
            "duration": 0.5248150825500488,
            "num_run": 154,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.624746297688672e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000929723939919975,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 1.331495752595934e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.42889832472811557,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12207198143005371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00047014266095949086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5171020104635579,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 2.4967686716247357e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8133239902392346,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.267984240942427,
        "time": 0.5279941558837891,
        "additional_info": {
            "duration": 0.5148391723632812,
            "num_run": 156,
            "train_loss": 1.1730445720508307,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0724377705025268e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021386473399803227,
            "classifier:CustomMLPClassifier:max_iter": 407,
            "classifier:CustomMLPClassifier:num_units": 257,
            "classifier:CustomMLPClassifier:tol": 4.519677222723765e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.09528357278165078,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.202684488173241,
        "time": 9.643624782562256,
        "additional_info": {
            "duration": 9.610913038253784,
            "num_run": 157,
            "train_loss": 1.144950710302449,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.031302100842645425,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9535376268723639,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.08765661951151232,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12752676010131836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.038404685519068796,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05088002878513645,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 0.00016562147321011366,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002978998876645794,
            "feature_preprocessor:select_rates_classification:alpha": 0.1375956031570904,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12253594398498535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0018594454786002223,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 409,
            "classifier:CustomMLPClassifier:tol": 0.009865075898529857,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022685774153979,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12696170806884766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.015187820701810056,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018962401013161958,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.00010164397240748255,
            "feature_preprocessor:select_rates_classification:alpha": 0.3523305733452254,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12072992324829102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0018594454786002223,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.009956964973299844,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019930736657160525,
            "feature_preprocessor:select_rates_classification:alpha": 0.03314536358934305,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.5979421138763428,
        "additional_info": {
            "duration": 0.5875039100646973,
            "num_run": 162,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.8826200741672548e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010764514111987247,
            "classifier:CustomMLPClassifier:max_iter": 155,
            "classifier:CustomMLPClassifier:num_units": 240,
            "classifier:CustomMLPClassifier:tol": 0.00038908360112918666,
            "feature_preprocessor:select_rates_classification:alpha": 0.04871342668118632,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10034894943237305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.026090978361966354,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010957187294714558,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 9.629115746509468e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013105547947491566,
            "feature_preprocessor:select_rates_classification:alpha": 0.4822013839224181,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10097312927246094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.445571768621289e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012655648160011118,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.0011306846175520519,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015287713367198997,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2653304483880746,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2359636333051167,
        "time": 0.7181570529937744,
        "additional_info": {
            "duration": 0.7059869766235352,
            "num_run": 165,
            "train_loss": 1.183134877517805,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.196657271719643e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021180475871517956,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 0.00016435945767596485,
            "feature_preprocessor:select_rates_classification:alpha": 0.011937551238035627,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12751007080078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.257897486070926e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032345030606787624,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.0005391440287742838,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0035567999849007263,
            "feature_preprocessor:select_percentile_classification:percentile": 84.20883474811278,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2194978761703146,
        "time": 0.6098439693450928,
        "additional_info": {
            "duration": 0.5931828022003174,
            "num_run": 167,
            "train_loss": 1.1533968841069733,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.700834831024346e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.96866808345265,
            "classifier:CustomMLPClassifier:max_iter": 391,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.00042802307845210194,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01304414242635562,
            "feature_preprocessor:select_rates_classification:alpha": 0.1543054639384429,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2329411895946174,
        "time": 0.3368091583251953,
        "additional_info": {
            "duration": 0.3261740207672119,
            "num_run": 168,
            "train_loss": 1.1978245822263602,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.4684084563788814e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10753560705548862,
            "classifier:CustomMLPClassifier:max_iter": 383,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.0006993011671949144,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016314261933195174,
            "feature_preprocessor:select_rates_classification:alpha": 0.1399381571332991,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2972688625521966,
        "time": 0.442425012588501,
        "additional_info": {
            "duration": 0.4302809238433838,
            "num_run": 169,
            "train_loss": 1.251215694893392,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000512657626034129,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02017250446494449,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0022382384614429767,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8582027729120744,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.230507773558717,
        "time": 0.6130549907684326,
        "additional_info": {
            "duration": 0.5947792530059814,
            "num_run": 170,
            "train_loss": 1.1807108113222906,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009264269497671442,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017975816972003518,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 67,
            "classifier:CustomMLPClassifier:tol": 0.0026481869815803,
            "feature_preprocessor:select_percentile_classification:percentile": 28.012050354958294,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.18439507484436035,
        "additional_info": {
            "duration": 0.1649777889251709,
            "num_run": 171,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011927177570521458,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016804256849400682,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.004002338723972071,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06628396400041135,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07026919145269028,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2397183633059594,
        "time": 0.3269360065460205,
        "additional_info": {
            "duration": 0.31580209732055664,
            "num_run": 172,
            "train_loss": 1.1907110403892156,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012003148773287502,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005628229533697096,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 244,
            "classifier:CustomMLPClassifier:tol": 0.00034872350384830775,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009516969633812463,
            "feature_preprocessor:select_rates_classification:alpha": 0.011098986018527365,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10063624382019043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009772402351041973,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11602394916453035,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.006038338911504853,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03225442956493914,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7108196561400605,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1686040098619058,
            "feature_preprocessor:select_percentile_classification:percentile": 58.42544750341795,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.21986642921446,
        "time": 0.8654348850250244,
        "additional_info": {
            "duration": 0.8545060157775879,
            "num_run": 174,
            "train_loss": 1.0754541461008114,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0919941747876028,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.791137071382973,
            "classifier:CustomMLPClassifier:max_iter": 471,
            "classifier:CustomMLPClassifier:num_units": 454,
            "classifier:CustomMLPClassifier:tol": 0.00014742481213616564,
            "feature_preprocessor:select_percentile_classification:percentile": 75.56666494107196,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2453190750344127,
        "time": 0.5733821392059326,
        "additional_info": {
            "duration": 0.5498030185699463,
            "num_run": 175,
            "train_loss": 1.1881649218731465,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.813489931078601e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009241789709862986,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.003930100147116746,
            "feature_preprocessor:select_rates_classification:alpha": 0.40662724197738287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12293291091918945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06943807126709847,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007120893998907406,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 3.41896642690778e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3972016372414642,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12748980522155762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.7644292313974444e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006672656075660762,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 182,
            "classifier:CustomMLPClassifier:tol": 3.549285459373491e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010163719414388214,
            "feature_preprocessor:select_percentile_classification:percentile": 20.45042473755652,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.5596339702606201,
        "additional_info": {
            "duration": 0.5490570068359375,
            "num_run": 178,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.04018344145588125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5999298374695904,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.003662756302231072,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01525728929379593,
            "feature_preprocessor:select_rates_classification:alpha": 0.14219534834920736,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.3030369517356415,
        "time": 0.23169517517089844,
        "additional_info": {
            "duration": 0.2192070484161377,
            "num_run": 179,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.1936214513654825e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015655113103534411,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 9.066513567374952e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.43458050050913316,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09663987159729004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0989332872995422e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006279524607037867,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 1.905631746199252e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.24587559365122463,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2398873539767703,
        "time": 6.669858932495117,
        "additional_info": {
            "duration": 6.6571290493011475,
            "num_run": 181,
            "train_loss": 1.0152156661572682,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.9032521329669004e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035321871187742704,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 0.002871857048100022,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021206520404405736,
            "feature_preprocessor:select_rates_classification:alpha": 0.08141913414755368,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12184000015258789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0022407483919318705,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03005754703141232,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 0.008806557430526914,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006181335620928695,
            "feature_preprocessor:select_rates_classification:alpha": 0.34272234192633955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10576105117797852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01687568592862864,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7483099948578403,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.004391913537610175,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.03866878188918258,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.3337957855219928,
        "time": 0.25855207443237305,
        "additional_info": {
            "duration": 0.2475888729095459,
            "num_run": 184,
            "train_loss": 1.2980697922413327,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0018442028975074363,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4868607513414535,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.006909591340173175,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022706760139347772,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.01692450019412484,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.233856935874369,
        "time": 0.40126490592956543,
        "additional_info": {
            "duration": 0.38896894454956055,
            "num_run": 185,
            "train_loss": 1.2314151640038637,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.1527335750296045e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004873765238581686,
            "classifier:CustomMLPClassifier:max_iter": 175,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 1.917676944621739e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 49.25524507410049,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.210605948873884,
        "time": 4.461226940155029,
        "additional_info": {
            "duration": 4.4494850635528564,
            "num_run": 186,
            "train_loss": 1.1704449815635571,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0238342654303386e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9511461024801549,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0014444242139472437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007544346934129028,
            "feature_preprocessor:select_rates_classification:alpha": 0.41483641851640524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09596967697143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007249591853352574,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006450976930039154,
            "classifier:CustomMLPClassifier:max_iter": 124,
            "classifier:CustomMLPClassifier:num_units": 273,
            "classifier:CustomMLPClassifier:tol": 0.00022353021311454454,
            "feature_preprocessor:select_rates_classification:alpha": 0.4900836345428955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09606385231018066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011712467511606113,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19254310154122037,
            "classifier:CustomMLPClassifier:max_iter": 229,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 3.4479096867020305e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011338475390194955,
            "feature_preprocessor:select_percentile_classification:percentile": 14.438594064532278,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.24067306518554688,
        "additional_info": {
            "duration": 0.23023486137390137,
            "num_run": 189,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06359009993274492,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015101917573314727,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 420,
            "classifier:CustomMLPClassifier:tol": 6.378145474501574e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.14543693485288928,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12687420845031738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0016421159116975796,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2880174759488714,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 3.585024701808974e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003477569566012705,
            "feature_preprocessor:select_rates_classification:alpha": 0.2263475731746477,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09645414352416992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005648687821346546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09215824599110131,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.002077163282500548,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18827546211887217,
            "feature_preprocessor:select_rates_classification:alpha": 0.3826694343535374,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09504294395446777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.05516572665497794,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.915269552283033,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.0036088844814583672,
            "feature_preprocessor:select_rates_classification:alpha": 0.044048924942546475,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.2644968032836914,
        "additional_info": {
            "duration": 0.2533597946166992,
            "num_run": 193,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008353878701671438,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020035790365791925,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 476,
            "classifier:CustomMLPClassifier:tol": 0.0028417158600411137,
            "feature_preprocessor:select_rates_classification:alpha": 0.32437236048052265,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2143043453428715,
        "time": 0.703223705291748,
        "additional_info": {
            "duration": 0.6931116580963135,
            "num_run": 194,
            "train_loss": 1.1564933670243185,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002908649638090957,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017507032286835872,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.001305281600333487,
            "feature_preprocessor:select_rates_classification:alpha": 0.3234221120006807,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12235212326049805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00012370550665083085,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005128695596905985,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 5.139527694841644e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4552559470969843,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2204731724888047,
        "time": 0.908092737197876,
        "additional_info": {
            "duration": 0.8971929550170898,
            "num_run": 196,
            "train_loss": 1.1634000200757628,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007242166792513377,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0934592638019372,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.00487042381574328,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.40948770404941415,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2334932125529259,
        "time": 0.41812992095947266,
        "additional_info": {
            "duration": 0.40410804748535156,
            "num_run": 197,
            "train_loss": 1.165202234618787,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005400376561630343,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005954329180731243,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 380,
            "classifier:CustomMLPClassifier:tol": 0.000129597113987198,
            "feature_preprocessor:select_rates_classification:alpha": 0.10702918247783394,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12236690521240234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009054761781433675,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0019354542125885337,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.00278741738731266,
            "feature_preprocessor:select_rates_classification:alpha": 0.13254304170262862,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12221407890319824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3480507253170816e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9655466890347995,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 181,
            "classifier:CustomMLPClassifier:tol": 0.0012620240070893769,
            "feature_preprocessor:select_rates_classification:alpha": 0.2658840360565555,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2438046317099023,
        "time": 0.3478732109069824,
        "additional_info": {
            "duration": 0.3366379737854004,
            "num_run": 200,
            "train_loss": 1.226357809794095,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.77348506567405e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14054977188568546,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.004396728703600119,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003762315227745916,
            "feature_preprocessor:select_percentile_classification:percentile": 80.0016601175371,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2191212768965833,
        "time": 1.4884111881256104,
        "additional_info": {
            "duration": 1.4781429767608643,
            "num_run": 201,
            "train_loss": 1.0103082479913064,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010755182978051955,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6378193422640699,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.004102041371482878,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005519909190097919,
            "feature_preprocessor:select_rates_classification:alpha": 0.03592952072094447,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.5057632842726303,
        "time": 0.35909199714660645,
        "additional_info": {
            "duration": 0.3438072204589844,
            "num_run": 202,
            "train_loss": 1.4977733161968347,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06486811251609752,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9511606496176751,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.00996651206919396,
            "feature_preprocessor:select_rates_classification:alpha": 0.11820157936386562,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16019201278686523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.98415000232239e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009826005378985885,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 5.030750664022999e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00034503416294266,
            "feature_preprocessor:select_rates_classification:alpha": 0.020004684274812796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1271650791168213,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011173755862034457,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01424336048806965,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.007887649964881331,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9634693472157627,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5310811996459961,
        "additional_info": {
            "duration": 0.5198788642883301,
            "num_run": 205,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0026732120225634918,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012212723069359806,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 0.000492279286081426,
            "feature_preprocessor:select_percentile_classification:percentile": 16.181448704645476,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.235514617965114,
        "time": 1.209709882736206,
        "additional_info": {
            "duration": 1.1995048522949219,
            "num_run": 206,
            "train_loss": 1.204860249139737,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011568954975138056,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11864549968259022,
            "classifier:CustomMLPClassifier:max_iter": 264,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.0008588841569495371,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028932136789376263,
            "feature_preprocessor:select_rates_classification:alpha": 0.42788409646899545,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.3030369517356415,
        "time": 0.7346692085266113,
        "additional_info": {
            "duration": 0.7237980365753174,
            "num_run": 207,
            "train_loss": 1.2648651043119776,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09715305254593515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6262860493716252,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021391561515011502,
            "feature_preprocessor:select_rates_classification:alpha": 0.06586075347192996,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12220907211303711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.397253927310605e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00721692231873552,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 126,
            "classifier:CustomMLPClassifier:tol": 0.004018014529599321,
            "feature_preprocessor:select_percentile_classification:percentile": 60.09820654206005,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2378466296737725,
        "time": 0.7606878280639648,
        "additional_info": {
            "duration": 0.748687744140625,
            "num_run": 209,
            "train_loss": 1.0325659687345046,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.344399846168314e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017496811880128387,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 3.176592695365268e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 62.96640936583355,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2102325661070361,
        "time": 3.448741912841797,
        "additional_info": {
            "duration": 3.437443971633911,
            "num_run": 210,
            "train_loss": 1.0845965657109045,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014699467680074092,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046359450721693193,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.004333541205921906,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025168593128054462,
            "feature_preprocessor:select_rates_classification:alpha": 0.3560995794553064,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12174582481384277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.006005594634498509,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03979582484897208,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 2.362355282560894e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12094272152759662,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12267899513244629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017464948705083574,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007373921955345988,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.00021672012462875453,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14579285032263278,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2078812355075674,
        "time": 4.430552005767822,
        "additional_info": {
            "duration": 4.418649196624756,
            "num_run": 213,
            "train_loss": 1.0853828879165224,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.06780328647093e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007292605091907005,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 0.0041107193782293815,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06902718677293883,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11021688204926239,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2387977873035054,
        "time": 0.44719696044921875,
        "additional_info": {
            "duration": 0.4346439838409424,
            "num_run": 214,
            "train_loss": 1.1843065197027465,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010231958965958084,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00936302796881917,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.001074635169297539,
            "feature_preprocessor:select_rates_classification:alpha": 0.04681016268381773,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12188315391540527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009806733883758256,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028656289488657165,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.00044691787608570167,
            "feature_preprocessor:select_rates_classification:alpha": 0.37344774067497194,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15626811981201172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.9580458528885756e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016607265841896283,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 179,
            "classifier:CustomMLPClassifier:tol": 0.005133865321689185,
            "feature_preprocessor:select_rates_classification:alpha": 0.09173361017574398,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1949802955209232,
        "time": 0.33964991569519043,
        "additional_info": {
            "duration": 0.32635498046875,
            "num_run": 217,
            "train_loss": 1.1375326303116127,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.5431799009883015e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17090306034876934,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.0029357546393155277,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005920655990393446,
            "feature_preprocessor:select_percentile_classification:percentile": 45.05410751950291,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.5308312845892662,
        "time": 0.28180599212646484,
        "additional_info": {
            "duration": 0.26454925537109375,
            "num_run": 218,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.023836246621039416,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6270328768994716,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.009532451553204105,
            "feature_preprocessor:select_rates_classification:alpha": 0.09218465019177044,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.7414708137512207,
        "additional_info": {
            "duration": 0.7281811237335205,
            "num_run": 219,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5717876045170676e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008450195964985134,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 5.374448354044702e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032536830310802585,
            "feature_preprocessor:select_percentile_classification:percentile": 98.48223501452084,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2364625491632082,
        "time": 3.519970655441284,
        "additional_info": {
            "duration": 3.508359909057617,
            "num_run": 220,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.525995788258739e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9769680814369247,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 112,
            "classifier:CustomMLPClassifier:tol": 0.0013234226822843168,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027431134326740544,
            "feature_preprocessor:select_rates_classification:alpha": 0.0859346769676442,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16101288795471191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003476785541640137,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20589548139528205,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 1.5366323753906057e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003847720383522017,
            "feature_preprocessor:select_rates_classification:alpha": 0.19707682276852342,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09632492065429688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006781750527406561,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08829767919133899,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 9.943404850943864e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8063983321795282,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2323746774682014,
        "time": 0.9061729907989502,
        "additional_info": {
            "duration": 0.8933932781219482,
            "num_run": 223,
            "train_loss": 1.1480919444854063,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.012437054365773288,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014852634661943148,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 159,
            "classifier:CustomMLPClassifier:tol": 0.004453204682122483,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04130129297028042,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9521730307986851,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.010766069140128592,
            "feature_preprocessor:select_percentile_classification:percentile": 59.654441975476175,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2455218539146307,
        "time": 1.3618066310882568,
        "additional_info": {
            "duration": 1.351073980331421,
            "num_run": 224,
            "train_loss": 1.078362329381291,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.5924912997142085e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011087192012459316,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0017042284802375092,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1179,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 97.18703570573581,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2098318281445477,
        "time": 0.36837315559387207,
        "additional_info": {
            "duration": 0.35877370834350586,
            "num_run": 225,
            "train_loss": 1.1660542302718908,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00014692693071943655,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005986735728914216,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 1.6764775826917254e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.16494260204518127,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4720458984375,
        "additional_info": {
            "duration": 0.45864129066467285,
            "num_run": 226,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9760255754068582e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020939650959658556,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.00045163747663968027,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06614822012216867,
            "feature_preprocessor:select_rates_classification:alpha": 0.1571534960897485,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15610408782958984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00023527062907078522,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12568953438916133,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 116,
            "classifier:CustomMLPClassifier:tol": 1.3094941520140244e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04994563415673805,
            "feature_preprocessor:select_percentile_classification:percentile": 20.965578713128217,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.21566319465637207,
        "additional_info": {
            "duration": 0.20397019386291504,
            "num_run": 228,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.3891483497948762e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012879988279411777,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 0.007106364447321296,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05750124478286126,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.04778784775631295,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.197867556619529,
        "time": 0.5767779350280762,
        "additional_info": {
            "duration": 0.563845157623291,
            "num_run": 229,
            "train_loss": 1.1994954498744124,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025666424969192064,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1259750158507693,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 141,
            "classifier:CustomMLPClassifier:tol": 0.0003356129433679635,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002824585861858377,
            "feature_preprocessor:select_rates_classification:alpha": 0.31837072151291085,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0963892936706543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.591879769493543e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008995460018869344,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 58,
            "classifier:CustomMLPClassifier:tol": 3.312363607123064e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.31150893707919136,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1000218391418457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004008340289240484,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000249551498144469,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 0.0009830004242444806,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014920072608350377,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 784,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5322684575859801,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231835530462181,
        "time": 1.06083083152771,
        "additional_info": {
            "duration": 1.0376029014587402,
            "num_run": 232,
            "train_loss": 1.203476478234192,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.206024237556033e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7195327904671586,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 0.0003768419351400995,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04478549039005032,
            "feature_preprocessor:select_rates_classification:alpha": 0.01121345116999561,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09599685668945312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006727789761803135,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47987700449352394,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.007008410522922354,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007501922704530356,
            "feature_preprocessor:select_rates_classification:alpha": 0.03554848581013665,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.3638641834259033,
        "additional_info": {
            "duration": 0.3517577648162842,
            "num_run": 234,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004449909420114045,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9174044114730354,
            "classifier:CustomMLPClassifier:max_iter": 256,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 1.4993228152664052e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 53.50639806793471,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2157946499786245,
        "time": 0.2709341049194336,
        "additional_info": {
            "duration": 0.2527289390563965,
            "num_run": 235,
            "train_loss": 1.0777730275181312,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.239040338292733e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07056471954337629,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 0.009429754524605666,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8495879604360441,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2022724187800997,
            "feature_preprocessor:select_rates_classification:alpha": 0.01739302194448778,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.241929681570832,
        "time": 0.34147095680236816,
        "additional_info": {
            "duration": 0.32870006561279297,
            "num_run": 236,
            "train_loss": 1.243896412008197,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09281771470475945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018709484299762043,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.0010425385574884434,
            "feature_preprocessor:select_percentile_classification:percentile": 35.01673866914178,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1961100933421167,
        "time": 0.5836977958679199,
        "additional_info": {
            "duration": 0.5736918449401855,
            "num_run": 237,
            "train_loss": 1.174607921887649,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00034121319936630795,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038474744226611327,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 0.0013071241328976504,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007579476072849856,
            "feature_preprocessor:select_rates_classification:alpha": 0.34568250294556935,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.22576594352722168,
        "additional_info": {
            "duration": 0.2152252197265625,
            "num_run": 238,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.21411886767614e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1539774383958876,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0025364817204473265,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03455850881105229,
            "feature_preprocessor:select_rates_classification:alpha": 0.10056315390955088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.216045716161112,
        "time": 0.5215239524841309,
        "additional_info": {
            "duration": 0.5087549686431885,
            "num_run": 239,
            "train_loss": 1.2110142775125439,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006022521228547936,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024887990253259205,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 96,
            "classifier:CustomMLPClassifier:tol": 0.0012099144794155796,
            "feature_preprocessor:select_percentile_classification:percentile": 67.56758568355605,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.2986001968383789,
        "additional_info": {
            "duration": 0.2875850200653076,
            "num_run": 240,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.19398343556106e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31373401706931514,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.00389690951674663,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1586372301218351,
            "feature_preprocessor:select_rates_classification:alpha": 0.33445408378181124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12222695350646973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00032021484299734026,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7796557684753848,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 4.6186184053135825e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.015726448326081013,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 4.36346697807312,
        "additional_info": {
            "duration": 4.3468239307403564,
            "num_run": 242,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0007278873245462698,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018846620656426104,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 2.0991963234974445e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 1.569096872070971,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 2.828150749206543,
        "additional_info": {
            "duration": 2.817599058151245,
            "num_run": 243,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06886301181573509,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032617500378357393,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 0.00020483087443996613,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008322784883950374,
            "feature_preprocessor:select_rates_classification:alpha": 0.27390121363775627,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2078780190006841,
        "time": 1.9065852165222168,
        "additional_info": {
            "duration": 1.8951809406280518,
            "num_run": 244,
            "train_loss": 1.1809473429954571,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018266542071102067,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.679589305396215,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 455,
            "classifier:CustomMLPClassifier:tol": 0.0002197883755909654,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4876823609499199,
            "feature_preprocessor:select_rates_classification:alpha": 0.38311698430755464,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.126723051071167,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.0888586708018685e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10117777142734732,
            "classifier:CustomMLPClassifier:max_iter": 406,
            "classifier:CustomMLPClassifier:num_units": 332,
            "classifier:CustomMLPClassifier:tol": 3.9113403647493105e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41485750253469533,
            "feature_preprocessor:select_percentile_classification:percentile": 73.95598093271374,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.5308312845892662,
        "time": 0.4346737861633301,
        "additional_info": {
            "duration": 0.4221360683441162,
            "num_run": 246,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008764740187066949,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02890263996406503,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 0.00025897430194836435,
            "feature_preprocessor:select_rates_classification:alpha": 0.2453669319506947,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12231802940368652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.901488665388216e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013012962112804753,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 0.0007407355195029067,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2115046178170514,
            "feature_preprocessor:select_rates_classification:alpha": 0.14637604498332504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09569978713989258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.219887266033726e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00178569165681712,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 0.0033409702045835515,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18816583867802644,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9465536266194763,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2384372804889459,
        "time": 0.4051220417022705,
        "additional_info": {
            "duration": 0.39198923110961914,
            "num_run": 249,
            "train_loss": 1.1681970135286266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04288056963944698,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006124940871022208,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 0.0010401886636416688,
            "feature_preprocessor:select_rates_classification:alpha": 0.33806085080880444,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2674601078033447,
        "additional_info": {
            "duration": 0.255234956741333,
            "num_run": 250,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.301431341312217e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024055332327832415,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.00014391818542559175,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1833740063235506,
            "feature_preprocessor:select_rates_classification:alpha": 0.49209182787546274,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.20870494842529297,
        "additional_info": {
            "duration": 0.1968400478363037,
            "num_run": 251,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0494360938246498e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011888831829730575,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 1.3187720959003e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 90.0253103317483,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.6809210777282715,
        "additional_info": {
            "duration": 0.6657571792602539,
            "num_run": 252,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.326057612269226e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0031922228172687477,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 324,
            "classifier:CustomMLPClassifier:tol": 0.0001669970801491528,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9351110039134012,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28349418619804617,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8964041166383317,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.214664852157431,
        "time": 1.0433809757232666,
        "additional_info": {
            "duration": 1.0308890342712402,
            "num_run": 253,
            "train_loss": 1.158976718994766,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.190214582480863e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026092855287198846,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 366,
            "classifier:CustomMLPClassifier:tol": 0.0018439597942461025,
            "feature_preprocessor:select_rates_classification:alpha": 0.4039892944453437,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09543299674987793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1118385625326698e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003605900316288065,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 124,
            "classifier:CustomMLPClassifier:tol": 0.0020582399345559763,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7584149434140125,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2454363725136189,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6262334230913719,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222938773443048,
        "time": 0.40361809730529785,
        "additional_info": {
            "duration": 0.3845200538635254,
            "num_run": 255,
            "train_loss": 1.1794078222423772,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011469745524333232,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012162782328257335,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 0.002341912875669628,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014210538863940877,
            "feature_preprocessor:select_rates_classification:alpha": 0.38531654162853635,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09540510177612305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.4456880785595875e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008577522739135174,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.006227005157416837,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12304085063633202,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5211848127113115,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3344409465789795,
        "additional_info": {
            "duration": 0.3205759525299072,
            "num_run": 257,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012143226161416104,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18752034272965853,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00018447963328312487,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15000433352829917,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8245338535839659,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.024715302682728344,
            "feature_preprocessor:select_rates_classification:alpha": 0.12375524224757786,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2255041555839585,
        "time": 0.40491199493408203,
        "additional_info": {
            "duration": 0.39180588722229004,
            "num_run": 258,
            "train_loss": 1.2165516941677637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.46999131142604e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05960472662741441,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.002468634289229363,
            "feature_preprocessor:select_rates_classification:alpha": 0.3605381292953405,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12324976921081543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4218448441808596e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8905369811708695,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 4.1386976150229895e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007656937123752855,
            "feature_preprocessor:select_rates_classification:alpha": 0.28089354621866025,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12204694747924805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4083660098963066e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001697974373555173,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 395,
            "classifier:CustomMLPClassifier:tol": 0.0007257404901368831,
            "feature_preprocessor:select_percentile_classification:percentile": 10.23555780061992,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.41500210762023926,
        "additional_info": {
            "duration": 0.3924679756164551,
            "num_run": 261,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010520644494646002,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09989158321910961,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.00023592206445915203,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4071846576122796,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3407449722290039,
        "additional_info": {
            "duration": 0.32943105697631836,
            "num_run": 262,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002431198220445318,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014615687759329664,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 0.0002852506511725342,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9292626489536436,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13468051947797155,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24483878811069404,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2096145600962223,
        "time": 1.4331581592559814,
        "additional_info": {
            "duration": 1.421597957611084,
            "num_run": 263,
            "train_loss": 1.1825043051597224,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00015016032624829535,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6662584478618243,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.00022318056050096892,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4876823609499199,
            "feature_preprocessor:select_rates_classification:alpha": 0.41113372015731553,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12810134887695312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2469112261311075e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015960264998982185,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.00548851233479444,
            "feature_preprocessor:select_rates_classification:alpha": 0.17609154576301836,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1283729076385498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0957353213321384e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029423357543691938,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 1.8810915848949238e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032558409783457424,
            "feature_preprocessor:select_rates_classification:alpha": 0.1152016186324973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.4569680690765381,
        "additional_info": {
            "duration": 0.44680213928222656,
            "num_run": 266,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002767839877577521,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008048925365487016,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 3.1681287275680516e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2724691194527492,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12222909927368164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1238173675039484e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001327866118762258,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 1.0298366450510431e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2723141368529784,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0957021713256836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018890839394156852,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7727861230087988,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 2.585947499514821e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 246,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.015209408090477074,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.3517796993255615,
        "additional_info": {
            "duration": 0.3306858539581299,
            "num_run": 269,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0021534530784199216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022957836394041607,
            "classifier:CustomMLPClassifier:max_iter": 241,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.0034619970694380747,
            "feature_preprocessor:select_rates_classification:alpha": 0.02582704725406529,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0950920581817627,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.2898755402122875e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2161601689479528,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.0034899350227192284,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0705384829760308,
            "feature_preprocessor:select_percentile_classification:percentile": 16.28933242027189,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.25572872161865234,
        "additional_info": {
            "duration": 0.24556612968444824,
            "num_run": 271,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.587770157272245e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8280981490627659,
            "classifier:CustomMLPClassifier:max_iter": 351,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.004308127624360591,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018865892661353257,
            "feature_preprocessor:select_rates_classification:alpha": 0.1685151234378538,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1223609447479248,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001966805287763598,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09834490117602246,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.0009214458082989726,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01876771917566287,
            "feature_preprocessor:select_rates_classification:alpha": 0.3191769187730071,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.23243422750694,
        "time": 0.6690738201141357,
        "additional_info": {
            "duration": 0.6450831890106201,
            "num_run": 273,
            "train_loss": 1.2250966650779294,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0074073754075895185,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014825244435480805,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 0.0012594298564945405,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01565531416941754,
            "feature_preprocessor:select_rates_classification:alpha": 0.05100167424745609,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12278413772583008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7293416790559434e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016111974745416,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 2.6033021307417188e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001584842518765445,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9967002512254897,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1791561558290846,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.44294264323189303,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2254333428087512,
        "time": 1.7032172679901123,
        "additional_info": {
            "duration": 1.6916539669036865,
            "num_run": 275,
            "train_loss": 1.0801401409717521,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08853010534039515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005912121649656241,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.00035173438582534544,
            "feature_preprocessor:select_rates_classification:alpha": 0.16596622563989327,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 2.0177431106567383,
        "additional_info": {
            "duration": 2.0016820430755615,
            "num_run": 276,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.372534634577303e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001114100032541722,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 0.00027831597636072416,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017613139688223291,
            "feature_preprocessor:select_percentile_classification:percentile": 21.926385047761357,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2377034008322934,
        "time": 1.1294310092926025,
        "additional_info": {
            "duration": 1.1114141941070557,
            "num_run": 277,
            "train_loss": 1.1935715655022192,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0023658891624819033,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014383965233879306,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.0014860824373020029,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12870767896458146,
            "feature_preprocessor:select_percentile_classification:percentile": 41.98772299894022,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2281323042704912,
        "time": 0.25879502296447754,
        "additional_info": {
            "duration": 0.24701380729675293,
            "num_run": 278,
            "train_loss": 1.164063716092001,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000437754568523773,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.578794115253452,
            "classifier:CustomMLPClassifier:max_iter": 225,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 0.0002360631934598087,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.20219182278911763,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2503307392387568,
        "time": 0.8571720123291016,
        "additional_info": {
            "duration": 0.8461968898773193,
            "num_run": 279,
            "train_loss": 1.056989154080527,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01062931643861179,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03068983803522624,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 1.3208916262517295e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2909594696294769,
            "feature_preprocessor:select_percentile_classification:percentile": 60.66764132224505,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.8297762870788574,
        "additional_info": {
            "duration": 0.8192529678344727,
            "num_run": 280,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.7121675471034945e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12260293494301545,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.0044799202543902225,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00581382564025817,
            "feature_preprocessor:select_rates_classification:alpha": 0.07024280964192774,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09576892852783203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06909986008041903,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.025102994383989247,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 0.0028026421409701845,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021549515692126202,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.859505676792289,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.02535798739301347,
            "feature_preprocessor:select_rates_classification:alpha": 0.40893663893565224,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2752227783203125,
        "additional_info": {
            "duration": 0.2647392749786377,
            "num_run": 282,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00015773032714147515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05522790527613833,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 53,
            "classifier:CustomMLPClassifier:tol": 0.0033953795444245393,
            "feature_preprocessor:select_rates_classification:alpha": 0.21472853704177272,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1227867603302002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00033027153835910646,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029342447850059447,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.0005264120733111977,
            "feature_preprocessor:select_rates_classification:alpha": 0.4839211282723442,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09618306159973145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007961938611620738,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16395218974554532,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 2.915933634088764e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8226928606881039,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222340076398289,
        "time": 0.36524200439453125,
        "additional_info": {
            "duration": 0.35266590118408203,
            "num_run": 285,
            "train_loss": 1.1919756658760703,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.18905102031206e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006126504616342041,
            "classifier:CustomMLPClassifier:max_iter": 276,
            "classifier:CustomMLPClassifier:num_units": 316,
            "classifier:CustomMLPClassifier:tol": 0.0005295070091249565,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 194,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.34480518869498594,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2061286019528576,
        "time": 6.003942251205444,
        "additional_info": {
            "duration": 5.9928412437438965,
            "num_run": 286,
            "train_loss": 1.0325090159926111,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.0084526367215993e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002909664481622061,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 1.714168232184137e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005582281542114742,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7054643533486118,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2501907561455063,
            "feature_preprocessor:select_percentile_classification:percentile": 60.77504943484996,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2343252701051817,
        "time": 5.87830924987793,
        "additional_info": {
            "duration": 5.867910146713257,
            "num_run": 287,
            "train_loss": 1.0229568734506314,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.35996054497921e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001631792109006363,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 157,
            "classifier:CustomMLPClassifier:tol": 1.3642073676140732e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0026477257396135974,
            "feature_preprocessor:select_rates_classification:alpha": 0.06888309304045552,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09454822540283203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00773968803114504,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8319667831604988,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 288,
            "classifier:CustomMLPClassifier:tol": 0.00014429053288473188,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05979098239637322,
            "feature_preprocessor:select_percentile_classification:percentile": 77.13089498054393,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3139960765838623,
        "additional_info": {
            "duration": 0.3013620376586914,
            "num_run": 289,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005897853759914132,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000455344221300801,
            "classifier:CustomMLPClassifier:max_iter": 116,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 1.1947955396670984e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13340807195501306,
            "feature_preprocessor:select_percentile_classification:percentile": 82.26267681911783,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 1.1902031898498535,
        "additional_info": {
            "duration": 1.1795508861541748,
            "num_run": 290,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.094027394620797e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009098763543124037,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 216,
            "classifier:CustomMLPClassifier:tol": 0.007642985445639207,
            "feature_preprocessor:select_rates_classification:alpha": 0.2777485892172971,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09482407569885254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.995624579086118e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01058073974069824,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 1.3025930062625077e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07361235062894413,
            "feature_preprocessor:select_rates_classification:alpha": 0.08211830576502523,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10100817680358887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004858997949535244,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031066512622993488,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.00027182340114681436,
            "feature_preprocessor:select_rates_classification:alpha": 0.020533152715961834,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4179878234863281,
        "additional_info": {
            "duration": 0.406383752822876,
            "num_run": 293,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011061471199033389,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1294637469582977,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.00015460088153715086,
            "feature_preprocessor:select_percentile_classification:percentile": 84.69288904258711,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2347179618380844,
        "time": 7.4310832023620605,
        "additional_info": {
            "duration": 7.4188783168792725,
            "num_run": 294,
            "train_loss": 1.0085629861901757,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.5599359563541221e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9888471703431838,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 84,
            "classifier:CustomMLPClassifier:tol": 0.0014444242139472437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030926540654688073,
            "feature_preprocessor:select_rates_classification:alpha": 0.42242078034165176,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.5308312845892662,
        "time": 0.4662818908691406,
        "additional_info": {
            "duration": 0.45357489585876465,
            "num_run": 295,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.50910120785772e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020903994159823247,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 0.00892307027744417,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013159381166829642,
            "feature_preprocessor:select_rates_classification:alpha": 0.2171512557572141,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1271381378173828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.013959600638754531,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1830000322910937,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.004342575150821187,
            "feature_preprocessor:select_rates_classification:alpha": 0.09689886549413067,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09997391700744629,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.960236884053948e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024465581403897876,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 231,
            "classifier:CustomMLPClassifier:tol": 1.4023442796405393e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.23533049820563454,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09464192390441895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02287373904324599,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7587712078653822,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 57,
            "classifier:CustomMLPClassifier:tol": 1.5180140652649164e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4924569549447169,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1222541332244873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01218132759535765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005946533973313053,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 7.755978995841173e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 232,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 12.4125657039677,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.252880028920496,
        "time": 3.1294288635253906,
        "additional_info": {
            "duration": 3.117851972579956,
            "num_run": 300,
            "train_loss": 1.2232682884181278,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.4940140087517374e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.27227544227186684,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 64,
            "classifier:CustomMLPClassifier:tol": 0.0014539321015686342,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1324,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5630786785853393,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2332083482362763,
        "time": 0.40064120292663574,
        "additional_info": {
            "duration": 0.3881809711456299,
            "num_run": 301,
            "train_loss": 1.1857507241208742,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.389513268005396e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4160503835507457,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.004580315443945951,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012571317657727232,
            "feature_preprocessor:select_rates_classification:alpha": 0.4055757356121006,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09577393531799316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00030637428837366825,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 0.008466470708516251,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010181317849008734,
            "feature_preprocessor:select_rates_classification:alpha": 0.012769181240628516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.2481369972229004,
        "additional_info": {
            "duration": 0.22979187965393066,
            "num_run": 303,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011211397605629802,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012991574781969213,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.0003849847069039424,
            "feature_preprocessor:select_rates_classification:alpha": 0.4579802316389486,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.6125853061676025,
        "additional_info": {
            "duration": 0.5983362197875977,
            "num_run": 304,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09611037304327001,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036408060721289837,
            "classifier:CustomMLPClassifier:max_iter": 337,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.00016301972812305074,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04941762279862379,
            "feature_preprocessor:select_rates_classification:alpha": 0.29898341719876154,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2146407134686739,
        "time": 0.9278888702392578,
        "additional_info": {
            "duration": 0.916614294052124,
            "num_run": 305,
            "train_loss": 1.1501986971821225,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.168949641030863e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00038452292267921714,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 467,
            "classifier:CustomMLPClassifier:tol": 2.472455567117758e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015130512438529258,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12716280992552487,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.8184490203857422,
        "additional_info": {
            "duration": 0.807053804397583,
            "num_run": 306,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003069240774262181,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9265717873579126,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 465,
            "classifier:CustomMLPClassifier:tol": 0.0006465506491689071,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028818616424029633,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8751444349145923,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2559684656082555,
        "time": 0.9096071720123291,
        "additional_info": {
            "duration": 0.8982563018798828,
            "num_run": 307,
            "train_loss": 1.2008966621911423,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06819295370188368,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004310186925723134,
            "classifier:CustomMLPClassifier:max_iter": 123,
            "classifier:CustomMLPClassifier:num_units": 324,
            "classifier:CustomMLPClassifier:tol": 1.5162122831198988e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3801906244141008,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.8776381015777588,
        "additional_info": {
            "duration": 1.8666269779205322,
            "num_run": 308,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.875257750089515e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027294455267749787,
            "classifier:CustomMLPClassifier:max_iter": 341,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.0001285737308393235,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012402074827267925,
            "feature_preprocessor:select_rates_classification:alpha": 0.048093097491611426,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12851619720458984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.470252883974883e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011828003622464996,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.0009513612793017867,
            "feature_preprocessor:select_rates_classification:alpha": 0.2202147137404181,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10155296325683594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08989911872334456,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011000145412041244,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 0.001207702903521714,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.36395275390356707,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.176073076120635,
        "time": 1.3214850425720215,
        "additional_info": {
            "duration": 1.308366060256958,
            "num_run": 311,
            "train_loss": 1.1347470732205125,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0031884300549545946,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022957836394041607,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.0034619970694380747,
            "feature_preprocessor:select_rates_classification:alpha": 0.024356774522315973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09439206123352051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.830427036693939e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26491991773243745,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0005920204923139536,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0042909486876945395,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9930102362674729,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2296042117655983,
            "feature_preprocessor:select_percentile_classification:percentile": 11.194761172493495,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.259441547799332,
        "time": 0.6570439338684082,
        "additional_info": {
            "duration": 0.6469910144805908,
            "num_run": 313,
            "train_loss": 1.2232682884181278,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.026129169713702556,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.030591285434545423,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.0002738158211608353,
            "feature_preprocessor:select_percentile_classification:percentile": 17.643936826245238,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.25397586822509766,
        "additional_info": {
            "duration": 0.23987793922424316,
            "num_run": 314,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007947341536317876,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15672292999523665,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.00787187462699108,
            "feature_preprocessor:select_percentile_classification:percentile": 86.08475808209063,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.244392056093437,
        "time": 0.8207318782806396,
        "additional_info": {
            "duration": 0.8107776641845703,
            "num_run": 315,
            "train_loss": 1.0037869149191858,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.015538656024206357,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002813751548888965,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 1.810677028925452e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.30017997950446496,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2312609721061794,
        "time": 1.1681842803955078,
        "additional_info": {
            "duration": 1.1562089920043945,
            "num_run": 316,
            "train_loss": 1.1739442258714108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00046524340573830103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13509182177501702,
            "classifier:CustomMLPClassifier:max_iter": 378,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.00018831842846505308,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023047337914446058,
            "feature_preprocessor:select_rates_classification:alpha": 0.4890664342965864,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12158799171447754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00013850110391592537,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13166404474762308,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 0.0002619487861173406,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45469426902205745,
            "feature_preprocessor:select_rates_classification:alpha": 0.3963842691889571,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10049104690551758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.003967685848747062,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6375209871565136,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.009695196434596766,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.05670944302928684,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2292781945508562,
        "time": 1.4262161254882812,
        "additional_info": {
            "duration": 1.414599895477295,
            "num_run": 319,
            "train_loss": 1.1125829096480524,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.661236324780763e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.884603160599552,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 5.3267889151945244e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.28089354621866025,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12234997749328613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.582634073003313e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06119540237693915,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 143,
            "classifier:CustomMLPClassifier:tol": 0.00010662247543132594,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011038477748072412,
            "feature_preprocessor:select_rates_classification:alpha": 0.329214725979821,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10088014602661133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007854114982595512,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11198282357135,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.0003456147298773589,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015806091598835368,
            "feature_preprocessor:select_rates_classification:alpha": 0.15767703075781722,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2219715233541437,
        "time": 0.8713200092315674,
        "additional_info": {
            "duration": 0.8605740070343018,
            "num_run": 322,
            "train_loss": 1.1827826811966369,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2656737669874598e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10447099927938702,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.00102281378621399,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03443635864799037,
            "feature_preprocessor:select_rates_classification:alpha": 0.2854653914058232,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12681889533996582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08606492698831424,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017928305146547958,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 196,
            "classifier:CustomMLPClassifier:tol": 0.0005804077247452949,
            "feature_preprocessor:select_rates_classification:alpha": 0.3896408046620331,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09471511840820312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03391933921419396,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006895153524750735,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 3.448414334144645e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001476213506971379,
            "feature_preprocessor:select_percentile_classification:percentile": 85.78017916006296,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 1.2762818336486816,
        "additional_info": {
            "duration": 1.26572585105896,
            "num_run": 325,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009476570558282891,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8413360886709174,
            "classifier:CustomMLPClassifier:max_iter": 338,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 6.918939962703454e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009102933858986817,
            "feature_preprocessor:select_rates_classification:alpha": 0.20848964996694536,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1275026798248291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0050499684202979025,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2094128397633819,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 4.377547199210409e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.015156490122186964,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09659910202026367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07539736677555592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001825104359542812,
            "classifier:CustomMLPClassifier:max_iter": 109,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 0.00032433974770979917,
            "feature_preprocessor:select_rates_classification:alpha": 0.48220880761013774,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09632706642150879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004063810617919118,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005483176981472827,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 1.0099576680750984e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.21805560010098515,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12273621559143066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0021452906584132877,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002529960388092315,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 5.7109858553523636e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11376734268638884,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12381887435913086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3258896956977568e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000332438655672773,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 2.4200224931928015e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2495671626761896,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09982895851135254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04015292970987583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00306762231428202,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 0.0004966661294553127,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.29988245374517997,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.39127397537231445,
        "additional_info": {
            "duration": 0.378342866897583,
            "num_run": 332,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016713096577248766,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006356232463010461,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0002967031183566364,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043215621868465066,
            "feature_preprocessor:select_rates_classification:alpha": 0.2992454614082092,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2059982391389115,
        "time": 2.0492169857025146,
        "additional_info": {
            "duration": 2.038269281387329,
            "num_run": 333,
            "train_loss": 1.1582386288254491,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.029965404181071117,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003131535460434102,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 1.3598661095224957e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019241507711114145,
            "feature_preprocessor:select_rates_classification:alpha": 0.4620417990381053,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2098318281445477,
        "time": 6.339646339416504,
        "additional_info": {
            "duration": 6.32933497428894,
            "num_run": 334,
            "train_loss": 1.161212485553415,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.11066969160865e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9904429936508459,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 0.0003906752304926462,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22694367626266373,
            "feature_preprocessor:select_rates_classification:alpha": 0.41113372015731553,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4307870864868164,
        "additional_info": {
            "duration": 0.41526293754577637,
            "num_run": 335,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04807174592896018,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2521525472815056,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.0007912679989496143,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03989805764299084,
            "feature_preprocessor:select_rates_classification:alpha": 0.11057693944861399,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12230896949768066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00028702440443745155,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6180695838405663,
            "classifier:CustomMLPClassifier:max_iter": 315,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 1.9893638088495352e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 39.964537578211164,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2663716197223134,
        "time": 2.2395081520080566,
        "additional_info": {
            "duration": 2.2258970737457275,
            "num_run": 337,
            "train_loss": 1.1021194856780359,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03198214715623781,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023805581833525048,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.0070690910336207,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016646294185740178,
            "feature_preprocessor:select_rates_classification:alpha": 0.09694853075502884,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.21007108688354492,
        "additional_info": {
            "duration": 0.20016002655029297,
            "num_run": 338,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.013078150568486732,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3059455273409102,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 1.013715058952892e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003249621069300052,
            "feature_preprocessor:select_rates_classification:alpha": 0.2842360939548558,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2814259312261553,
        "time": 0.9262299537658691,
        "additional_info": {
            "duration": 0.9149689674377441,
            "num_run": 339,
            "train_loss": 1.0786337438768274,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0075663541424216335,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023497095113790475,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.00020780026381667828,
            "feature_preprocessor:select_percentile_classification:percentile": 67.89378164232099,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2067594839159597,
        "time": 3.342142343521118,
        "additional_info": {
            "duration": 3.330843925476074,
            "num_run": 340,
            "train_loss": 1.1514720433745695,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0014367999629863156,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00045980939079791886,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 266,
            "classifier:CustomMLPClassifier:tol": 0.005689171379056606,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012077087431103914,
            "feature_preprocessor:select_rates_classification:alpha": 0.19935538806489164,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12732386589050293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06257267676630693,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09448492432882859,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0006931062802003206,
            "feature_preprocessor:select_rates_classification:alpha": 0.0984158248422713,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.1947710737021837,
        "time": 1.3164527416229248,
        "additional_info": {
            "duration": 1.3065760135650635,
            "num_run": 342,
            "train_loss": 1.2028546265817017,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00018700858405948546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0050569292347232555,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 0.00047795942765054564,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9628738975269744,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06027942138142902,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7370734378393659,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2219795695837294,
        "time": 7.911003828048706,
        "additional_info": {
            "duration": 7.897524833679199,
            "num_run": 343,
            "train_loss": 1.039218648701597,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.5406173888896268e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013727994120810447,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.0004788814719672479,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17953335450652108,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.693195743166586,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1903226951926171,
        "time": 0.36817002296447754,
        "additional_info": {
            "duration": 0.356229305267334,
            "num_run": 344,
            "train_loss": 1.1918681480648365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003533008187961499,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016044173239652726,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 458,
            "classifier:CustomMLPClassifier:tol": 0.006219347536292666,
            "feature_preprocessor:select_rates_classification:alpha": 0.10484546016988824,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.2600710391998291,
        "additional_info": {
            "duration": 0.23764705657958984,
            "num_run": 345,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.6271703232664781e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020915226395794456,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.004228061183240711,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00041317821657273023,
            "feature_preprocessor:select_rates_classification:alpha": 0.3520633066461348,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1225881576538086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.066300332121012e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3596437595218126,
            "classifier:CustomMLPClassifier:max_iter": 268,
            "classifier:CustomMLPClassifier:num_units": 160,
            "classifier:CustomMLPClassifier:tol": 0.0017655863165594715,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009829160652307712,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7567809139885874,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0858114909749372,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06224618378064917,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1999646045296268,
        "time": 0.5992629528045654,
        "additional_info": {
            "duration": 0.5295531749725342,
            "num_run": 347,
            "train_loss": 1.1412445772088948,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.859704033878842e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.672626222107896,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.00010595989227585083,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012423737051353032,
            "feature_preprocessor:select_rates_classification:alpha": 0.12186604374886433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2202269360290197,
        "time": 0.7397868633270264,
        "additional_info": {
            "duration": 0.7276301383972168,
            "num_run": 348,
            "train_loss": 1.194334058624099,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.009445649970958446,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12860393524169922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0894260778558806,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017928305146547958,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 0.0005804077247452949,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.37352513254548037,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12206220626831055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002709879311626556,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08767786789909765,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 437,
            "classifier:CustomMLPClassifier:tol": 0.0027178012199440566,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004207765501574136,
            "feature_preprocessor:select_rates_classification:alpha": 0.14898040936434548,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2111837237367689,
        "time": 1.420478105545044,
        "additional_info": {
            "duration": 1.4047789573669434,
            "num_run": 351,
            "train_loss": 1.1000929409381264,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004130452727156253,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10762667010353781,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.001489625221413758,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004001621467800484,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18329678219336365,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.276839143673057,
        "time": 1.572293996810913,
        "additional_info": {
            "duration": 1.5578489303588867,
            "num_run": 352,
            "train_loss": 1.1058401532809108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005180223014787183,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0706001068071828,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.003140838203807794,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.4358021129375621,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16185283660888672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00036454845155287226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005882621144907994,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 169,
            "classifier:CustomMLPClassifier:tol": 0.0009111320922171124,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1108,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 57.98184933438467,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2287792786927645,
        "time": 0.49053001403808594,
        "additional_info": {
            "duration": 0.47969675064086914,
            "num_run": 354,
            "train_loss": 1.1633912993701703,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0030171702709081965,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021285541221623708,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 0.0019431357124987626,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01044306020338972,
            "feature_preprocessor:select_rates_classification:alpha": 0.49352873824737126,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12264490127563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.695960668566708e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1632421778868106,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 0.0005486180184342509,
            "feature_preprocessor:select_rates_classification:alpha": 0.3194812532801608,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12284612655639648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02505349006161478,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001210390436650814,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 70,
            "classifier:CustomMLPClassifier:tol": 0.00011792648945054094,
            "feature_preprocessor:select_rates_classification:alpha": 0.436849305883557,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09612107276916504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3186936512077464e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010234642861864711,
            "classifier:CustomMLPClassifier:max_iter": 500,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 4.210776303626828e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007166503992491422,
            "feature_preprocessor:select_rates_classification:alpha": 0.4024512419078176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2911579722291826,
        "time": 1.1604559421539307,
        "additional_info": {
            "duration": 1.1483519077301025,
            "num_run": 358,
            "train_loss": 1.3449366649343797,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00023336441906311167,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0332640830774782,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 1.0170327790801488e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011099212814053107,
            "feature_preprocessor:select_rates_classification:alpha": 0.3241383868892666,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0963752269744873,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.409759721692395e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005704290730125271,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 6.574291923961026e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1448764622585949,
            "feature_preprocessor:select_rates_classification:alpha": 0.42006877363554296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09643292427062988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03128875601470632,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003343944363784422,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 0.00999732042714972,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030453476163424713,
            "feature_preprocessor:select_rates_classification:alpha": 0.4674649021786745,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.128676176071167,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.016194849900606923,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015859837691295397,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 2.3800894894670847e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.08411967565164077,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 1.9891281127929688,
        "additional_info": {
            "duration": 1.9784910678863525,
            "num_run": 362,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.540570901577644e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00949437066326433,
            "classifier:CustomMLPClassifier:max_iter": 375,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 4.274658914608938e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014352173166821218,
            "feature_preprocessor:select_percentile_classification:percentile": 57.58107569096397,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.47650718688964844,
        "additional_info": {
            "duration": 0.46651625633239746,
            "num_run": 363,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.046611395381406e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9150070997602249,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0003162968515460867,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4958140374754253,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2516826348309782,
        "time": 0.6442461013793945,
        "additional_info": {
            "duration": 0.6296379566192627,
            "num_run": 364,
            "train_loss": 1.1983203269187819,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03615063818575386,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001863852468936741,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 0.002687346577923715,
            "feature_preprocessor:select_percentile_classification:percentile": 23.873275502316996,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2417912725273001,
        "time": 0.37926387786865234,
        "additional_info": {
            "duration": 0.36797618865966797,
            "num_run": 365,
            "train_loss": 1.1924899997173268,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002414796219647121,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010443683254029654,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 0.00024110475892444804,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.44912147842375383,
            "feature_preprocessor:select_rates_classification:alpha": 0.18510560935690354,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10102725028991699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.9562150359358635e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009316715441529603,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.00023537588173758807,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000399938396613975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1880,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3693167436849673,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.220616411255039,
        "time": 0.46068382263183594,
        "additional_info": {
            "duration": 0.45070600509643555,
            "num_run": 367,
            "train_loss": 1.2012889437118441,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.207197368494022e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2522237265825853,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 500,
            "classifier:CustomMLPClassifier:tol": 2.6988533989615268e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01731194043189125,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 845,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1511896081457187,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.8403971195220947,
        "additional_info": {
            "duration": 0.8268370628356934,
            "num_run": 368,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010508688440450202,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000941277193863382,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 3.1993927508935e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034308100181087344,
            "feature_preprocessor:select_rates_classification:alpha": 0.01599275952185642,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0963277816772461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00381484259912091,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012126709431126634,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 0.005041591448662404,
            "feature_preprocessor:select_rates_classification:alpha": 0.12365132839887642,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10242509841918945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.004071761171975663,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8730705901571609,
            "classifier:CustomMLPClassifier:max_iter": 285,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.0001654138247462888,
            "feature_preprocessor:select_rates_classification:alpha": 0.2987400160459411,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12332582473754883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005221983592020964,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3671340361568696,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.009937985847624361,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00799314266039716,
            "feature_preprocessor:select_rates_classification:alpha": 0.050428303091468625,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12377405166625977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.3508145491295585e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03480378627709087,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.0002739776428049377,
            "feature_preprocessor:select_percentile_classification:percentile": 71.99841206680736,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.248225645099073,
        "time": 0.962975263595581,
        "additional_info": {
            "duration": 0.9529142379760742,
            "num_run": 373,
            "train_loss": 1.011725142555007,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.680331712779636e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31723336198849356,
            "classifier:CustomMLPClassifier:max_iter": 267,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 3.316781754533648e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011997666916932482,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8378412274531029,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.247784675988656,
        "time": 0.7832019329071045,
        "additional_info": {
            "duration": 0.7666499614715576,
            "num_run": 374,
            "train_loss": 1.0525722406720834,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011365827679982485,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004125765096191428,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 184,
            "classifier:CustomMLPClassifier:tol": 0.00024148180270588222,
            "feature_preprocessor:select_rates_classification:alpha": 0.13729675797362173,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12853479385375977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00048194735329280597,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010649873374288923,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 1.170671360399404e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006010836518870721,
            "feature_preprocessor:select_percentile_classification:percentile": 54.85420473907975,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.526076078414917,
        "additional_info": {
            "duration": 0.5155739784240723,
            "num_run": 376,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.4247985702777286e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014812619312916194,
            "classifier:CustomMLPClassifier:max_iter": 268,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 4.583403829015661e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.010817025021698581,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12280607223510742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.6272824579389523e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011014406779872807,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.0003959290994036385,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001406455614981142,
            "feature_preprocessor:select_rates_classification:alpha": 0.023079310014281575,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15665793418884277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1515586459266208e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17531050064918444,
            "classifier:CustomMLPClassifier:max_iter": 415,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 6.276378919711282e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.484013593210543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2212183248066815,
        "time": 0.6950876712799072,
        "additional_info": {
            "duration": 0.6849219799041748,
            "num_run": 379,
            "train_loss": 1.0345082508780934,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002682857096024544,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007208556181290528,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 1.3010586979928932e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011566632498706613,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7528730586899749,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18785886970690852,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4850773012608157,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2283704945006904,
        "time": 0.794497013092041,
        "additional_info": {
            "duration": 0.7825720310211182,
            "num_run": 380,
            "train_loss": 1.1990857269425257,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1475383791124557e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009597294402762883,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 0.0003553141691628842,
            "feature_preprocessor:select_rates_classification:alpha": 0.35230175723166585,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12971019744873047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.036524775865595584,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8423508677589059,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 6.710936559887515e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03037023112473824,
            "feature_preprocessor:select_rates_classification:alpha": 0.3482512226978395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12392592430114746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00024049914644809522,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09837934267238889,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 0.0008995477617805503,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022210145505717802,
            "feature_preprocessor:select_rates_classification:alpha": 0.448578714597148,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1224360466003418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022003562873080404,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015368035889991563,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.0016717394803790566,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8696601413049222,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.030489503752525536,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6708814918331465,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1963402373427303,
        "time": 0.40770888328552246,
        "additional_info": {
            "duration": 0.38831591606140137,
            "num_run": 384,
            "train_loss": 1.186969450604467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.024361581580109877,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12059817393103282,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 459,
            "classifier:CustomMLPClassifier:tol": 0.00019446806039259608,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03128609844855293,
            "feature_preprocessor:select_rates_classification:alpha": 0.23203524224765626,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12868285179138184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.171619096101308e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005546602836940656,
            "classifier:CustomMLPClassifier:max_iter": 399,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.0001150419593499667,
            "feature_preprocessor:select_rates_classification:alpha": 0.12390987439465857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09604811668395996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.7957531559361e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014833821616437495,
            "classifier:CustomMLPClassifier:max_iter": 152,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.006299078247931872,
            "feature_preprocessor:select_rates_classification:alpha": 0.18773137636794102,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5095102787017822,
        "additional_info": {
            "duration": 0.4988820552825928,
            "num_run": 387,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02267318999448435,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006284089520174085,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 0.00010825246989033769,
            "feature_preprocessor:select_rates_classification:alpha": 0.35253641011506825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1244039535522461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00014539521246512957,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.018859831604223762,
            "classifier:CustomMLPClassifier:max_iter": 463,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 2.9682280165283918e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020644313641301102,
            "feature_preprocessor:select_rates_classification:alpha": 0.36946567629157706,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2054075883237383,
        "time": 1.2538540363311768,
        "additional_info": {
            "duration": 1.237874984741211,
            "num_run": 389,
            "train_loss": 1.0228912000031454,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00023141011089139482,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009258777323274258,
            "classifier:CustomMLPClassifier:max_iter": 327,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.0003567814682968368,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.060939877978610356,
            "feature_preprocessor:select_percentile_classification:percentile": 31.059046990543713,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2353327513420147,
        "time": 0.374859094619751,
        "additional_info": {
            "duration": 0.36422181129455566,
            "num_run": 390,
            "train_loss": 1.1792851960529975,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.085773175126497e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20638707194536512,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 3.4420446614573644e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21740939402446074,
            "feature_preprocessor:select_rates_classification:alpha": 0.3648910947700097,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12297201156616211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.866079869532198e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020673906269387194,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.0018572052854196179,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006276872264769294,
            "feature_preprocessor:select_rates_classification:alpha": 0.45016904375445366,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.229705810546875,
        "additional_info": {
            "duration": 0.21922516822814941,
            "num_run": 392,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.09515129129194472,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009494812371811986,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 3.607221873651527e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011393383271927009,
            "feature_preprocessor:select_percentile_classification:percentile": 60.96179459366394,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 2.3228070735931396,
        "additional_info": {
            "duration": 2.312072992324829,
            "num_run": 393,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.953972557140007e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003929832798157065,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 246,
            "classifier:CustomMLPClassifier:tol": 0.00013226621226256418,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004400025845799615,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1030,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3201867363023282,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.199826195486095,
        "time": 0.483989953994751,
        "additional_info": {
            "duration": 0.4705209732055664,
            "num_run": 394,
            "train_loss": 1.1952691691358737,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012288082863213746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007863134638543081,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.0002005645414390721,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008467844866350546,
            "feature_preprocessor:select_percentile_classification:percentile": 31.937187698383926,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.28291797637939453,
        "additional_info": {
            "duration": 0.2686939239501953,
            "num_run": 395,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.033250379576098665,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028957901009093172,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.004954074027354583,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012279779014173852,
            "feature_preprocessor:select_rates_classification:alpha": 0.1394377861095866,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09592485427856445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00012914790929762754,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046493508430369877,
            "classifier:CustomMLPClassifier:max_iter": 270,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 6.758549316616625e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022020289447493725,
            "feature_preprocessor:select_percentile_classification:percentile": 28.238779990850972,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.25754809379577637,
        "additional_info": {
            "duration": 0.2323930263519287,
            "num_run": 397,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004878079768932637,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034966503146161925,
            "classifier:CustomMLPClassifier:max_iter": 188,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 5.798115195074709e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008236093130110532,
            "feature_preprocessor:select_percentile_classification:percentile": 55.45489739777513,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2260513488195648,
        "time": 1.8016068935394287,
        "additional_info": {
            "duration": 1.7913038730621338,
            "num_run": 398,
            "train_loss": 1.12456435832045,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.8091136098789035e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0813866657065212,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 5.3376415286490125e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2801889808072537,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10024499893188477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011038626740939904,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00038896566852239365,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 0.0017004753984611206,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15535969304391523,
            "feature_preprocessor:select_rates_classification:alpha": 0.15216501489793188,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5721008777618408,
        "additional_info": {
            "duration": 0.5613002777099609,
            "num_run": 400,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.82098352815124e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13029093787059787,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 129,
            "classifier:CustomMLPClassifier:tol": 0.005700073059744995,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.342311956522779,
            "feature_preprocessor:select_rates_classification:alpha": 0.07938177226501464,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12849092483520508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.319953919454141e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00039701736595438447,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00011331021649990509,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07932632084177653,
            "feature_preprocessor:select_rates_classification:alpha": 0.11303380224024678,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1236572265625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.013142177495287002,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002678447169925491,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.00020104385709725434,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8292446579016909,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.006764185494317432,
            "feature_preprocessor:select_rates_classification:alpha": 0.24996368565267982,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2208175868441928,
        "time": 1.8356750011444092,
        "additional_info": {
            "duration": 1.8255720138549805,
            "num_run": 403,
            "train_loss": 1.165136561171301,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.010045258779334e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07817685851710525,
            "classifier:CustomMLPClassifier:max_iter": 168,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 3.357528839727479e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3381002143043688,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09649085998535156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011476345479159273,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008777027859285672,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 389,
            "classifier:CustomMLPClassifier:tol": 0.0002967612578062976,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015041617168119184,
            "feature_preprocessor:select_rates_classification:alpha": 0.37013644524048717,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09693408012390137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.025672934668203595,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3986030355943789,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 3.2248490334029104e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003268738729750721,
            "feature_preprocessor:select_rates_classification:alpha": 0.11351837655564219,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10123014450073242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0137252914841916e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08864085173132495,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.0025313286166042666,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09350182201949564,
            "feature_preprocessor:select_rates_classification:alpha": 0.02339655745218443,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.220243028488191,
        "time": 2.708404064178467,
        "additional_info": {
            "duration": 2.6976330280303955,
            "num_run": 407,
            "train_loss": 1.0544936006337982,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001884283704342404,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028529857408147014,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 403,
            "classifier:CustomMLPClassifier:tol": 2.815931764476089e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009703204383736588,
            "feature_preprocessor:select_rates_classification:alpha": 0.08814176211972131,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0967111587524414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00016566297661632737,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06204331344295179,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 2.7431233781367605e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4784218499647472,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10239291191101074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009968881249898082,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027978474808740043,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 0.0040470159948517844,
            "feature_preprocessor:select_rates_classification:alpha": 0.17120689739247857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1220560073852539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04915542293853704,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.044289761906388996,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 0.00025036964599905624,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9570205048760085,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19162292055727598,
            "feature_preprocessor:select_rates_classification:alpha": 0.2806482206791664,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2377162668598263,
        "time": 0.7057540416717529,
        "additional_info": {
            "duration": 0.6957287788391113,
            "num_run": 411,
            "train_loss": 1.1231805874149048,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1957434995228067e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011311860647337493,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 0.0033276835669956892,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07782581580900072,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5014979839324951,
        "additional_info": {
            "duration": 0.4697730541229248,
            "num_run": 412,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00016566297661632737,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04637893984141769,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 2.7431233781367605e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007639099713076849,
            "feature_preprocessor:select_rates_classification:alpha": 0.49708652778103973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09626293182373047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002968475872152525,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.049057005082432485,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 151,
            "classifier:CustomMLPClassifier:tol": 1.4285204359506417e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 64.16396397057122,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2092170386406171,
        "time": 3.4541118144989014,
        "additional_info": {
            "duration": 3.444126844406128,
            "num_run": 414,
            "train_loss": 1.0341316516043622,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0027637497490801115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002534171476413582,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.00012621513020368775,
            "feature_preprocessor:select_rates_classification:alpha": 0.4500825693325038,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10177397727966309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1702471904274356e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001156433036107233,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 410,
            "classifier:CustomMLPClassifier:tol": 0.0025062659107853375,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008782683862295122,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 641,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6529743544311326,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2388331986534868,
        "time": 0.6193869113922119,
        "additional_info": {
            "duration": 0.6057908535003662,
            "num_run": 416,
            "train_loss": 1.2191727807057362,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00021435970654737056,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1649588376357334,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 0.0077317457930911925,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18494905302122938,
            "feature_preprocessor:select_rates_classification:alpha": 0.47476155161437766,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09678101539611816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.003735214067314705,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.021196798538703192,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0032447940573137315,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2841891601109407,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49508405185313764,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.21443953787952,
        "time": 0.40634799003601074,
        "additional_info": {
            "duration": 0.3943748474121094,
            "num_run": 418,
            "train_loss": 1.1794078222423772,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011103000876464134,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2944200455385806,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 273,
            "classifier:CustomMLPClassifier:tol": 0.0009061633389487375,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001011413421248629,
            "feature_preprocessor:select_rates_classification:alpha": 0.23214354847915725,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09607410430908203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08684195730248723,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023137640734397568,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.005882805236819298,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026930342750347915,
            "feature_preprocessor:select_rates_classification:alpha": 0.21790954408849703,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12340497970581055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0682912897352893,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.048894753219246606,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 109,
            "classifier:CustomMLPClassifier:tol": 0.0011495743019247883,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9454874146584777,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226910771492216,
        "time": 0.47775912284851074,
        "additional_info": {
            "duration": 0.4539010524749756,
            "num_run": 421,
            "train_loss": 1.1673333902680663,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0024781156568444715,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002582380602127502,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 0.00033824816357343375,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2429068861097898,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6673938620022687,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2422596067581129,
        "time": 2.9990358352661133,
        "additional_info": {
            "duration": 2.985805034637451,
            "num_run": 422,
            "train_loss": 1.1902304040749399,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00039609618095233045,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.060186247794106855,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 7.084468124390718e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011291755551843315,
            "feature_preprocessor:select_rates_classification:alpha": 0.13761203641354275,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12359189987182617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00037145993384401355,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06355695675334795,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0003987576441289169,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004002283467956066,
            "feature_preprocessor:select_rates_classification:alpha": 0.3478219055262397,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10133004188537598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06217482025278401,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019775058588466282,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.00011074984649494457,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01790192883159971,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 512,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4268344264959757,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.213280771646867,
        "time": 1.958427906036377,
        "additional_info": {
            "duration": 1.947152853012085,
            "num_run": 425,
            "train_loss": 1.1873460498781983,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004593400569218329,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006494069053922584,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.0016492056587841936,
            "feature_preprocessor:select_rates_classification:alpha": 0.18405867177035198,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16147899627685547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010735476158822725,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010204974564661116,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.0018108578228973546,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016783826822513546,
            "feature_preprocessor:select_rates_classification:alpha": 0.2529504015138442,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.21019196510314941,
        "additional_info": {
            "duration": 0.19957494735717773,
            "num_run": 427,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.010767560282191705,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8482686108400187,
            "classifier:CustomMLPClassifier:max_iter": 404,
            "classifier:CustomMLPClassifier:num_units": 59,
            "classifier:CustomMLPClassifier:tol": 0.00016972549755975007,
            "feature_preprocessor:select_percentile_classification:percentile": 72.90172933161635,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1959797305281705,
        "time": 0.34836816787719727,
        "additional_info": {
            "duration": 0.33274126052856445,
            "num_run": 428,
            "train_loss": 1.1360773721548532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00621682035244344,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018469079513884856,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 3.287689190028414e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006784579199999141,
            "feature_preprocessor:select_rates_classification:alpha": 0.10380515020970471,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12396907806396484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7589245646610956e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015163382139778564,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 0.00718289446701707,
            "feature_preprocessor:select_rates_classification:alpha": 0.360112099956527,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0981149673461914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.171720000256104e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008586664361676193,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 450,
            "classifier:CustomMLPClassifier:tol": 0.00010245073377158143,
            "feature_preprocessor:select_rates_classification:alpha": 0.057493782878557755,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2105979026442981,
        "time": 0.6380560398101807,
        "additional_info": {
            "duration": 0.6272168159484863,
            "num_run": 431,
            "train_loss": 1.1783349771630771,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.057859965792523,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2580491573736366,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 135,
            "classifier:CustomMLPClassifier:tol": 0.0005628742406265305,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7407558895776297,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2520914190230523,
        "time": 0.6243190765380859,
        "additional_info": {
            "duration": 0.6080801486968994,
            "num_run": 432,
            "train_loss": 1.1697034106235513,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03284325059570245,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004111926694616672,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 0.001409780530679828,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019223541962757698,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8553829045248427,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08785295880575816,
            "feature_preprocessor:select_percentile_classification:percentile": 20.85573136954766,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.221139465801888,
        "time": 1.0893049240112305,
        "additional_info": {
            "duration": 1.0775599479675293,
            "num_run": 433,
            "train_loss": 1.1900897626055504,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0014736817215725664,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06950072188538547,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 7.167213616148534e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07077515619344499,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.4955718517303467,
        "additional_info": {
            "duration": 0.4802103042602539,
            "num_run": 434,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.2384058961454864e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026327699385207112,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 3.896086783881127e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9957251570315891,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2347099156084986,
        "time": 1.7947089672088623,
        "additional_info": {
            "duration": 1.7792770862579346,
            "num_run": 435,
            "train_loss": 1.0477304959536076,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.7127759261669928e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028737930930137826,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.003219250600931234,
            "feature_preprocessor:select_rates_classification:alpha": 0.1356796037384124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0958092212677002,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.9943978904005237e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005337337206135859,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 138,
            "classifier:CustomMLPClassifier:tol": 0.00016501508623250323,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006908344141418332,
            "feature_preprocessor:select_rates_classification:alpha": 0.43636772132748797,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0985877513885498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011677720239592587,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9947666679116619,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.008209854652264304,
            "feature_preprocessor:select_rates_classification:alpha": 0.07400240542005966,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09930586814880371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.674399032338745e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00017259905366888146,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.0005887966727231729,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013588050431270822,
            "feature_preprocessor:select_rates_classification:alpha": 0.33616954299469165,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09658503532409668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0461233164659548e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032781249863157086,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.0011810683618449893,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0245662574746636,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6618963117553051,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2325967752392293,
        "time": 0.5460050106048584,
        "additional_info": {
            "duration": 0.5298209190368652,
            "num_run": 440,
            "train_loss": 1.167091044791171,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.6640578464381152e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022888540444959075,
            "classifier:CustomMLPClassifier:max_iter": 177,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.00017030619993526271,
            "feature_preprocessor:select_rates_classification:alpha": 0.3643186735203408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09722304344177246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0016558144667900632,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003608215731731836,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 105,
            "classifier:CustomMLPClassifier:tol": 2.257358882199834e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.024690729588302943,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1269512176513672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2418612730048105e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3882496637617226,
            "classifier:CustomMLPClassifier:max_iter": 150,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 4.9863889823204594e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8302176789750626,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2674225884221794,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.976525374618621,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2197875702096668,
        "time": 0.5676760673522949,
        "additional_info": {
            "duration": 0.5459001064300537,
            "num_run": 443,
            "train_loss": 1.200009209846844,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.64464698162291e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03511986147112529,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.002209101443670767,
            "feature_preprocessor:select_rates_classification:alpha": 0.08164814319484497,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12396812438964844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.839307262401196e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027090080379947846,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 481,
            "classifier:CustomMLPClassifier:tol": 6.933610101376953e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0772431963916406,
            "feature_preprocessor:select_rates_classification:alpha": 0.4321969695991945,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.5552492141723633,
        "additional_info": {
            "duration": 0.5318830013275146,
            "num_run": 445,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.48379612612286e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6444585841962847,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 0.00046300194488613976,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008677434390974396,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 185,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.39647818825901426,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2015579068589308,
        "time": 0.5828328132629395,
        "additional_info": {
            "duration": 0.5717918872833252,
            "num_run": 446,
            "train_loss": 1.1544941321388364,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.2554611881677575e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006416324111317997,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 1.682528834670438e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033963273231989596,
            "feature_preprocessor:select_rates_classification:alpha": 0.07109001711708474,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12428903579711914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010076502608293,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09841657878194802,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 4.7731694250626186e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03537986690554805,
            "feature_preprocessor:select_rates_classification:alpha": 0.3384173693998403,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09560775756835938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.6465456806328296e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002581621484076755,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 6.176108313110108e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35166417758270824,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12851595878601074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0019176076431360208,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.053627268703506724,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 3.9158060906654164e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20826349597217766,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9597692917974746,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2652707903125795,
        "time": 0.7777400016784668,
        "additional_info": {
            "duration": 0.7655320167541504,
            "num_run": 450,
            "train_loss": 1.179886125523614,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.7968638003999144e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6207675265256019,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.0009756749407120747,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00027903970537614657,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7217877837148323,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2623239791752352,
        "time": 1.1949303150177002,
        "additional_info": {
            "duration": 1.183152198791504,
            "num_run": 451,
            "train_loss": 1.1834492841147393,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001306641657390441,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1503746216091132,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 1.177751496616931e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004212315344377963,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.46719504793666367,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2603251091607404,
        "time": 0.8314709663391113,
        "additional_info": {
            "duration": 0.8178789615631104,
            "num_run": 452,
            "train_loss": 1.1534387284707213,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0097614443946764e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0668452140448025,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 468,
            "classifier:CustomMLPClassifier:tol": 0.00014265605868222337,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008032922108344259,
            "feature_preprocessor:select_rates_classification:alpha": 0.27127309408206574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09947919845581055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02287373904324599,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9757453530212162,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 69,
            "classifier:CustomMLPClassifier:tol": 3.5274930683914966e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4924569549447169,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12317919731140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.025788667435584667,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007801703627725201,
            "classifier:CustomMLPClassifier:max_iter": 207,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 5.4328518177608615e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008621030122100774,
            "feature_preprocessor:select_rates_classification:alpha": 0.484178974570843,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09514784812927246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1709077321585564e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028247417863376395,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 0.0007025628880394192,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12157355421379132,
            "feature_preprocessor:select_rates_classification:alpha": 0.4095896579928604,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10188698768615723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.392862534218813e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011620563467473307,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.0001242264051098508,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007285226385801298,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5300390988828685,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2175360207968653,
        "time": 2.5954151153564453,
        "additional_info": {
            "duration": 2.583017110824585,
            "num_run": 457,
            "train_loss": 1.2027232796867298,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01798261479402912,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017157302195400048,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 410,
            "classifier:CustomMLPClassifier:tol": 0.00028504179011436465,
            "feature_preprocessor:select_rates_classification:alpha": 0.3571890152117837,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12304878234863281,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.180074307805151e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00036032833831428965,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.007080954453116839,
            "feature_preprocessor:select_rates_classification:alpha": 0.32155625702905727,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.129256010055542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.607366536174585e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09198701826001739,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.004296287105929895,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.16212953948874465,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1953568947946545,
        "time": 0.469804048538208,
        "additional_info": {
            "duration": 0.4567842483520508,
            "num_run": 460,
            "train_loss": 1.1954400273615544,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001770317380529035,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009560874955282808,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0002271280485217743,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007858697848418549,
            "feature_preprocessor:select_rates_classification:alpha": 0.3537609831967775,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.34578776359558105,
        "additional_info": {
            "duration": 0.33507299423217773,
            "num_run": 461,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.051295660732184466,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001874613567871723,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.00045114554804947583,
            "feature_preprocessor:select_rates_classification:alpha": 0.15167863958453695,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 1.5753819942474365,
        "additional_info": {
            "duration": 1.5651037693023682,
            "num_run": 462,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014811470573628001,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03669599257224242,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.0005188844494764675,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21210638924565206,
            "feature_preprocessor:select_rates_classification:alpha": 0.3470696725731837,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.33204078674316406,
        "additional_info": {
            "duration": 0.31519508361816406,
            "num_run": 463,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0019738986628012063,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00073654710198957,
            "classifier:CustomMLPClassifier:max_iter": 262,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.009470131677257458,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 52,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1563143716947979,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2365301454315325,
        "time": 0.26197195053100586,
        "additional_info": {
            "duration": 0.24566197395324707,
            "num_run": 464,
            "train_loss": 1.2045400287390746,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.1426822640998714e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5963027133391283,
            "classifier:CustomMLPClassifier:max_iter": 432,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 0.007633217071807689,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05288152090984583,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1213,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3864465106070512,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2828679584843943,
        "time": 0.4821507930755615,
        "additional_info": {
            "duration": 0.470170259475708,
            "num_run": 465,
            "train_loss": 1.239747432324601,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.47545981913676e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02815780904521404,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0008364189768584068,
            "feature_preprocessor:select_percentile_classification:percentile": 59.91634153134676,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 1.0775055885314941,
        "additional_info": {
            "duration": 1.0673890113830566,
            "num_run": 466,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0015807501119927993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029651547432410136,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 234,
            "classifier:CustomMLPClassifier:tol": 7.50208799258947e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.164981291409136,
            "feature_preprocessor:select_rates_classification:alpha": 0.10926637262639846,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09548687934875488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1995646031226255e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.164388529228865,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 382,
            "classifier:CustomMLPClassifier:tol": 0.0006196933977445537,
            "feature_preprocessor:select_rates_classification:alpha": 0.1961838567137783,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10188579559326172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.9361716136665455e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3766025440250834,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.004580315443945951,
            "feature_preprocessor:select_rates_classification:alpha": 0.4055757356121006,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12390899658203125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00031348130723421496,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014926679081120765,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 201,
            "classifier:CustomMLPClassifier:tol": 5.2579946335657216e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.24451249879263431,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.14675688743591309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3116134276471077e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011429118470358753,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 2.296637802466497e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031971233281818147,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4374540804447822,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2177532888451905,
        "time": 4.036987066268921,
        "additional_info": {
            "duration": 4.024605989456177,
            "num_run": 471,
            "train_loss": 1.1683283604235986,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0024856456365722353,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10127894884926755,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.0005247754853333893,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4059141231152152,
            "feature_preprocessor:select_rates_classification:alpha": 0.35330804980965685,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10186886787414551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05350748044245257,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001111269487958862,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.0001045493060021435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1598,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7854228795464833,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2289064249998276,
        "time": 3.3698511123657227,
        "additional_info": {
            "duration": 3.3555469512939453,
            "num_run": 473,
            "train_loss": 1.1898206811430532,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.088234386646624e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08370232633741925,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 5.7765256825364544e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7788093672512401,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03295947154618377,
            "feature_preprocessor:select_percentile_classification:percentile": 8.914532671215536,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2321493631902904,
        "time": 0.9817230701446533,
        "additional_info": {
            "duration": 0.9714200496673584,
            "num_run": 474,
            "train_loss": 1.2253727080818049,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.076852758025219e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10279566816713545,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.008282284671832249,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024694193687863217,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8918925757076552,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.187546721830637,
            "feature_preprocessor:select_rates_classification:alpha": 0.09473560766988395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2341949072912355,
        "time": 0.4136009216308594,
        "additional_info": {
            "duration": 0.4024660587310791,
            "num_run": 475,
            "train_loss": 1.195233712444679,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.104516861380584e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035171785767010087,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 9.36705642972417e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013904788673218147,
            "feature_preprocessor:select_rates_classification:alpha": 0.17462758292402533,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.5308312845892662,
        "time": 0.24488401412963867,
        "additional_info": {
            "duration": 0.23374199867248535,
            "num_run": 476,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.6919262261865025e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017573816449785166,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 335,
            "classifier:CustomMLPClassifier:tol": 0.0003733335549707155,
            "feature_preprocessor:select_rates_classification:alpha": 0.02272294282652021,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12874102592468262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.533682300980451e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014711354486135928,
            "classifier:CustomMLPClassifier:max_iter": 275,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 2.371756598764022e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10212576797220933,
            "feature_preprocessor:select_percentile_classification:percentile": 41.912863790305884,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.232989466972132,
        "time": 5.120179891586304,
        "additional_info": {
            "duration": 5.110169172286987,
            "num_run": 478,
            "train_loss": 1.0672113803112984,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00023773528616924999,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01297498134153612,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.0038204165097914184,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18178370786584527,
            "feature_preprocessor:select_rates_classification:alpha": 0.07071267497872305,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12381291389465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.391835038158438e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.031927567196498544,
            "classifier:CustomMLPClassifier:max_iter": 429,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.002294562100540176,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8763555831857738,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04327783690231447,
            "feature_preprocessor:select_percentile_classification:percentile": 62.996113432932084,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.245751997915244,
        "time": 2.296647787094116,
        "additional_info": {
            "duration": 2.278563976287842,
            "num_run": 480,
            "train_loss": 1.021286005802579,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05914610513820383,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024077730280972937,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.00015124500651056614,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8718909648363045,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27652881954496583,
            "feature_preprocessor:select_percentile_classification:percentile": 62.52304175196058,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2226104515468312,
        "time": 7.328617811203003,
        "additional_info": {
            "duration": 7.316636085510254,
            "num_run": 481,
            "train_loss": 1.1160711002172745,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.346139421860556e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05103596543673174,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.0024764942742192017,
            "feature_preprocessor:select_percentile_classification:percentile": 34.32828320848763,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.34519505500793457,
        "additional_info": {
            "duration": 0.3290221691131592,
            "num_run": 482,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0027237615949255987,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013403557281708264,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 2.5055843742230986e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.27756153995490734,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13390159606933594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1283871566489383e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001334038831936785,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.002266536793419422,
            "feature_preprocessor:select_rates_classification:alpha": 0.24833108640710663,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09612178802490234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06015505479845609,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002380125317485771,
            "classifier:CustomMLPClassifier:max_iter": 421,
            "classifier:CustomMLPClassifier:num_units": 90,
            "classifier:CustomMLPClassifier:tol": 0.006013999028241275,
            "feature_preprocessor:select_rates_classification:alpha": 0.2613790404161762,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12311792373657227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.774950313072685e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003345943559061764,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.007168109795470064,
            "feature_preprocessor:select_rates_classification:alpha": 0.2690083650228523,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10159611701965332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.581549713655502e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09231653383823707,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 82,
            "classifier:CustomMLPClassifier:tol": 9.695221603565291e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2105106365924398,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12328124046325684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004093762940213518,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013965623910857945,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.000296837346925537,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018728978124118496,
            "feature_preprocessor:select_rates_classification:alpha": 0.3924348555753211,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2146568059278453,
        "time": 2.3875088691711426,
        "additional_info": {
            "duration": 2.3762450218200684,
            "num_run": 488,
            "train_loss": 1.172812095017178,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03318027710155367,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004004266106602575,
            "classifier:CustomMLPClassifier:max_iter": 149,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 2.9732893056000813e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031521230001671924,
            "feature_preprocessor:select_rates_classification:alpha": 0.181229013468414,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10121989250183105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002965101280930796,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019200487465123885,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 8.067127944610796e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4772914632136459,
            "feature_preprocessor:select_rates_classification:alpha": 0.07160094556798466,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12367701530456543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021375751925484924,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002996035194804404,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.002499601551830136,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08187346809645545,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.37766932553869426,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2084638400931549,
        "time": 1.1495988368988037,
        "additional_info": {
            "duration": 1.1357698440551758,
            "num_run": 491,
            "train_loss": 1.1920651684072945,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003411779576928213,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010530819189492737,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 7.057556849792026e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4478889847431609,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1225588321685791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008358222682552758,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03417994237270014,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0012914246682975616,
            "feature_preprocessor:select_rates_classification:alpha": 0.24316948355285825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12400603294372559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2523730122585096e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28774388957198554,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 3.241733590144859e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22237087456181026,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.37072300910949707,
        "additional_info": {
            "duration": 0.3588297367095947,
            "num_run": 494,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2893488165077672e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003070015169702075,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 0.007873164131311169,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001586387476752607,
            "feature_preprocessor:select_percentile_classification:percentile": 23.504373050966674,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2230063697113724,
        "time": 0.3618440628051758,
        "additional_info": {
            "duration": 0.3468050956726074,
            "num_run": 495,
            "train_loss": 1.2290445697795536,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05573807847953977,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7781393140712521,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 2.870979497957928e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0045708900201968505,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1860,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4254153692256242,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.224330900183198,
        "time": 0.6042768955230713,
        "additional_info": {
            "duration": 0.588313102722168,
            "num_run": 496,
            "train_loss": 1.1883776244625752,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.2223459185232235e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023515170074072143,
            "classifier:CustomMLPClassifier:max_iter": 222,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.00032753288982304257,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.041717483468574255,
            "feature_preprocessor:select_rates_classification:alpha": 0.45850408643988555,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12412691116333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00169653154332117,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001071333149520078,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.00022918909719947135,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2710638363404748,
            "feature_preprocessor:select_percentile_classification:percentile": 55.94322080952759,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4433000087738037,
        "additional_info": {
            "duration": 0.43338608741760254,
            "num_run": 498,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.010864652494143935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6067403458875675,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 448,
            "classifier:CustomMLPClassifier:tol": 0.00010682180331143511,
            "feature_preprocessor:select_percentile_classification:percentile": 6.149570563200323,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 1.0609688758850098,
        "additional_info": {
            "duration": 1.0414750576019287,
            "num_run": 499,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0015471025470528475,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022957836394041607,
            "classifier:CustomMLPClassifier:max_iter": 252,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.004849958183654268,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.05379864312806252,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12888717651367188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.3959177350191307e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002745285890986663,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 5.551220711537478e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.44745764149991607,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2049988041316642,
        "time": 0.850379228591919,
        "additional_info": {
            "duration": 0.838853120803833,
            "num_run": 501,
            "train_loss": 1.1883293924262741,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00019442755192553417,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002061069615950033,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 259,
            "classifier:CustomMLPClassifier:tol": 0.0006931930038955751,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018469500471297038,
            "feature_preprocessor:select_rates_classification:alpha": 0.2581703225669192,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10191512107849121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.003871510465177342,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005730214187829482,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 50,
            "classifier:CustomMLPClassifier:tol": 0.00021191350130119773,
            "feature_preprocessor:select_rates_classification:alpha": 0.16421851017661782,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12840008735656738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0031347147074515845,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024536785621760504,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.00015616082093981683,
            "feature_preprocessor:select_rates_classification:alpha": 0.2851883743695662,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12861061096191406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06767537345131046,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002204542828639685,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 191,
            "classifier:CustomMLPClassifier:tol": 7.299589445099793e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003211579135195443,
            "feature_preprocessor:select_rates_classification:alpha": 0.14657947836658414,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12296700477600098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07146576228861709,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0866977471822278,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.004157831494813855,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1945,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 24.917672729739312,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.206003068861614,
        "time": 0.6445789337158203,
        "additional_info": {
            "duration": 0.6274769306182861,
            "num_run": 506,
            "train_loss": 1.1802359888117429,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.010712906974111192,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020120089427040795,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.006258400053422137,
            "feature_preprocessor:select_rates_classification:alpha": 0.021120293397081248,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.3424849510192871,
        "additional_info": {
            "duration": 0.3286001682281494,
            "num_run": 507,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1855522125205276e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9888471703431838,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 138,
            "classifier:CustomMLPClassifier:tol": 0.0014444242139472437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.42242078034165176,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.32622623443603516,
        "additional_info": {
            "duration": 0.3124217987060547,
            "num_run": 508,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009244773242293263,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008382161021636138,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 0.005569946268038957,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0029012519051762158,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.835882924842059,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10925884241022044,
            "feature_preprocessor:select_rates_classification:alpha": 0.1269803650448145,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2269558323628473,
        "time": 0.302232027053833,
        "additional_info": {
            "duration": 0.2916297912597656,
            "num_run": 509,
            "train_loss": 1.1925074411285117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005717805691806411,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7891636517762451,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 2.811188645991763e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04353869086415098,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.835829697774604,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19621439960371392,
            "feature_preprocessor:select_percentile_classification:percentile": 66.25098633606426,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.188426822871673,
        "time": 0.32288503646850586,
        "additional_info": {
            "duration": 0.31043100357055664,
            "num_run": 510,
            "train_loss": 1.1954365465908654,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06320414903735758,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002785664812778778,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 2.2887259197270638e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2439312067078223,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.214672898387017,
        "time": 2.8433260917663574,
        "additional_info": {
            "duration": 2.8314507007598877,
            "num_run": 511,
            "train_loss": 1.068474858060503,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00025350580145440074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08331646321994914,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 3.1586505321584766e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 799,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 52.85690386119963,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2202349822586054,
        "time": 2.7870171070098877,
        "additional_info": {
            "duration": 2.7719929218292236,
            "num_run": 512,
            "train_loss": 1.0359425868529788,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06320710965388984,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6923017327983758,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014401341362272974,
            "feature_preprocessor:select_rates_classification:alpha": 0.025677739844848335,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09565997123718262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009444657712004846,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004510627272313904,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.00016658914729050545,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001443079127707101,
            "feature_preprocessor:select_rates_classification:alpha": 0.3990556275487826,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10105586051940918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.311999408586912e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004716575293068209,
            "classifier:CustomMLPClassifier:max_iter": 179,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 0.00014123397196450071,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023043886961199904,
            "feature_preprocessor:select_rates_classification:alpha": 0.2106938064079081,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09602785110473633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00020506725236596942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032292821732248636,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.0009063327494447577,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15504920951641993,
            "feature_preprocessor:select_rates_classification:alpha": 0.14168274476480966,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0963280200958252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.8006833913719885e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07838160136706068,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 378,
            "classifier:CustomMLPClassifier:tol": 0.0003074132689216306,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2510548382162865,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09451151395492075,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5567710399627686,
        "additional_info": {
            "duration": 0.5428650379180908,
            "num_run": 517,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.9674190381331086e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011519706349548288,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.0007369148705641957,
            "feature_preprocessor:select_rates_classification:alpha": 0.1570298890011738,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.11469006538391113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002083506219393029,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06589784992750332,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.0003725970984840553,
            "feature_preprocessor:select_rates_classification:alpha": 0.03675614074762922,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.42642998695373535,
        "additional_info": {
            "duration": 0.41568517684936523,
            "num_run": 519,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.07332639341855605,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002055100892211545,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 70,
            "classifier:CustomMLPClassifier:tol": 0.0003886775579129776,
            "feature_preprocessor:select_rates_classification:alpha": 0.4642954759448524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1229410171508789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.018438185772461226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03799741935458278,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 7.908721261695046e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00218736407050863,
            "feature_preprocessor:select_rates_classification:alpha": 0.3689259009881369,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12807679176330566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.5551476495710304e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11701548316109173,
            "classifier:CustomMLPClassifier:max_iter": 447,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.0005181085334278307,
            "feature_preprocessor:select_rates_classification:alpha": 0.03213309755880581,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1014859676361084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011910251173438274,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009950592560589078,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 341,
            "classifier:CustomMLPClassifier:tol": 0.0015566441627369333,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5347932037970405,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2397569911628241,
        "time": 1.4667470455169678,
        "additional_info": {
            "duration": 1.4014227390289307,
            "num_run": 523,
            "train_loss": 1.1912788462016768,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.311931645502021e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1819571947289171,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.0018436291810844288,
            "feature_preprocessor:select_percentile_classification:percentile": 96.55812882766477,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 1.4852399826049805,
        "additional_info": {
            "duration": 1.4743931293487549,
            "num_run": 524,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07903987416271961,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001636494906253842,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 123,
            "classifier:CustomMLPClassifier:tol": 0.0006914251076821889,
            "feature_preprocessor:select_rates_classification:alpha": 0.2074391218264239,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1278090476989746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012403986789320675,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005217442547947454,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 2.4622807978233197e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4440261906999829,
            "feature_preprocessor:select_percentile_classification:percentile": 17.940356078781953,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.234940059609112,
        "time": 0.9102728366851807,
        "additional_info": {
            "duration": 0.8996672630310059,
            "num_run": 526,
            "train_loss": 1.2232770091237204,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015471025470528475,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022957836394041607,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.006304008922620786,
            "feature_preprocessor:select_rates_classification:alpha": 0.05379864312806252,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12477684020996094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.249899047857439e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04826146034583441,
            "classifier:CustomMLPClassifier:max_iter": 165,
            "classifier:CustomMLPClassifier:num_units": 360,
            "classifier:CustomMLPClassifier:tol": 0.00025082001424555137,
            "feature_preprocessor:select_rates_classification:alpha": 0.16026765668306173,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1255178451538086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.258883582653066e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9986678684701634,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.0002816001742923629,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011255193790632848,
            "feature_preprocessor:select_rates_classification:alpha": 0.048550604669722226,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.5308312845892662,
        "time": 0.29057884216308594,
        "additional_info": {
            "duration": 0.27730393409729004,
            "num_run": 529,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005191775976426612,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 209,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.007060583372334924,
            "feature_preprocessor:select_rates_classification:alpha": 0.037523734614145765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09845614433288574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005038874180168484,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016248362368779149,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 257,
            "classifier:CustomMLPClassifier:tol": 0.0074431470554287334,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011174538049409574,
            "feature_preprocessor:select_rates_classification:alpha": 0.3552309126816468,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1280348300933838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.0840930311419774e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07636727156776817,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.005299521891062315,
            "feature_preprocessor:select_rates_classification:alpha": 0.09688913850772667,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12958192825317383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06153413461088691,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001027912973275896,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.00011480897829867603,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010093275541310173,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18442805108557336,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.239895400206356,
        "time": 10.956872940063477,
        "additional_info": {
            "duration": 10.943881034851074,
            "num_run": 533,
            "train_loss": 1.0942231024059628,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.25685299685553e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008228272720073252,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 0.00014898036472920447,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3695967230586943,
            "feature_preprocessor:select_rates_classification:alpha": 0.11598978943670124,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1226811408996582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4958261324806135e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24480107355076214,
            "classifier:CustomMLPClassifier:max_iter": 245,
            "classifier:CustomMLPClassifier:num_units": 232,
            "classifier:CustomMLPClassifier:tol": 2.7178152090044748e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003989978570130879,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4581379404111151,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2033234163659285,
        "time": 0.5323309898376465,
        "additional_info": {
            "duration": 0.5204381942749023,
            "num_run": 535,
            "train_loss": 1.1877075407737836,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001460769459962246,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006805204682028357,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.00011633554357920425,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6888279263596215,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1978756028491147,
        "time": 0.7853431701660156,
        "additional_info": {
            "duration": 0.7724812030792236,
            "num_run": 536,
            "train_loss": 1.1897550076955672,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.024194836611898765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7063788940716542,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.006538211757330447,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.07720433150892543,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.2853357791900635,
        "additional_info": {
            "duration": 0.26944470405578613,
            "num_run": 537,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005265313479974132,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08050683896368682,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 3.023605922458607e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00161960938642037,
            "feature_preprocessor:select_rates_classification:alpha": 0.1705431924522368,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1277468204498291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003031218196808254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18403884909634444,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.000731825265268074,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024080802772687666,
            "feature_preprocessor:select_percentile_classification:percentile": 90.37888906053782,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.228196674107177,
        "time": 3.4127049446105957,
        "additional_info": {
            "duration": 3.401129961013794,
            "num_run": 539,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.077711272283049e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004956645210370628,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 351,
            "classifier:CustomMLPClassifier:tol": 0.0008123797490305541,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7814520598014049,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.013155198453325537,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.923908893660563,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2063828846422284,
        "time": 5.870635986328125,
        "additional_info": {
            "duration": 5.858076095581055,
            "num_run": 540,
            "train_loss": 1.0295438799702379,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010816461590278483,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023513342677857429,
            "classifier:CustomMLPClassifier:max_iter": 464,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 0.000176231178825131,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09493879154825494,
            "feature_preprocessor:select_rates_classification:alpha": 0.4432673460999826,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5285177230834961,
        "additional_info": {
            "duration": 0.5109171867370605,
            "num_run": 541,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.7004731681161726e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009217855662590794,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 0.002647593078769689,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08342342363276162,
            "feature_preprocessor:select_rates_classification:alpha": 0.36283691670733703,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1017911434173584,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.465136191563472e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00923745044676765,
            "classifier:CustomMLPClassifier:max_iter": 194,
            "classifier:CustomMLPClassifier:num_units": 381,
            "classifier:CustomMLPClassifier:tol": 0.007439663218007565,
            "feature_preprocessor:select_rates_classification:alpha": 0.2397463617653422,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09813904762268066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008721080883986793,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15399270577919102,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 0.0014233721752183511,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025349022621210703,
            "feature_preprocessor:select_rates_classification:alpha": 0.45117490041628716,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0975489616394043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009682425344022015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14024487658536205,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.0025379871001673417,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08178645079790799,
            "feature_preprocessor:select_rates_classification:alpha": 0.37524567061507125,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09661173820495605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002195950483882036,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10001020519884724,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 1.676394518456276e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10679975031902203,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1554,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.19443762668754414,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.6424548625946045,
        "additional_info": {
            "duration": 0.6256179809570312,
            "num_run": 546,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0011059959096310565,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.026116688234151853,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 2.267656439776478e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006024369851770417,
            "feature_preprocessor:select_rates_classification:alpha": 0.10512796606658402,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2986631393432617,
        "additional_info": {
            "duration": 0.2880120277404785,
            "num_run": 547,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.5647922610157435e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05036124862288069,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 0.00037965949811843817,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17207543799620584,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2641667443959623,
        "time": 3.7259559631347656,
        "additional_info": {
            "duration": 3.7068240642547607,
            "num_run": 548,
            "train_loss": 1.1103082056275195,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00035237299181055295,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011894580622867192,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.00034620799121869134,
            "feature_preprocessor:select_percentile_classification:percentile": 82.5052512926895,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.214280206654114,
        "time": 2.995126247406006,
        "additional_info": {
            "duration": 2.979369878768921,
            "num_run": 549,
            "train_loss": 1.166496502993108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.047231988107338446,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013535810690823314,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 1.7982847785038794e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006671527940061084,
            "feature_preprocessor:select_rates_classification:alpha": 0.24954915590892,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2160247939792381,
        "time": 2.1358628273010254,
        "additional_info": {
            "duration": 2.1257200241088867,
            "num_run": 550,
            "train_loss": 1.1582386288254491,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.017032055958689014,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001094366432553274,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 443,
            "classifier:CustomMLPClassifier:tol": 1.39042107356394e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0045891184015612796,
            "feature_preprocessor:select_rates_classification:alpha": 0.39050727981151706,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12233614921569824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.02710941794544429,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1414830092401459,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 345,
            "classifier:CustomMLPClassifier:tol": 0.004003402667062752,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06173112146019022,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225658657086662,
        "time": 0.5464491844177246,
        "additional_info": {
            "duration": 0.5335416793823242,
            "num_run": 552,
            "train_loss": 1.1797274687742147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.014416948161289939,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00337575484167279,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 0.0076923352644588175,
            "feature_preprocessor:select_rates_classification:alpha": 0.1673361734543216,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10120320320129395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.04700604192292158,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013052594917801674,
            "classifier:CustomMLPClassifier:max_iter": 470,
            "classifier:CustomMLPClassifier:num_units": 221,
            "classifier:CustomMLPClassifier:tol": 0.0004309010369310583,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3523760105911385,
            "feature_preprocessor:select_rates_classification:alpha": 0.09576003961298372,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12377595901489258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003248263714059577,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 0.005881601208028294,
            "feature_preprocessor:select_rates_classification:alpha": 0.037523734614145765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09649896621704102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0109094899835151,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2671780259994591,
            "classifier:CustomMLPClassifier:max_iter": 358,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.005228716418015744,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015315885224872659,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8121312676408236,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.37685680389404297,
        "additional_info": {
            "duration": 0.3595600128173828,
            "num_run": 556,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0309543555823393e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004021036594880227,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 207,
            "classifier:CustomMLPClassifier:tol": 3.314128400563329e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3227520120110928,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12873506546020508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.489363025886784e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9287968215935052,
            "classifier:CustomMLPClassifier:max_iter": 154,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 0.0010630592552008595,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002598816624836316,
            "feature_preprocessor:select_rates_classification:alpha": 0.19741655061475208,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09740519523620605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003618674624466296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002242543118321539,
            "classifier:CustomMLPClassifier:max_iter": 303,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 8.915061326055529e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13009864676130678,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9192895294266862,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.14334741427664524,
            "feature_preprocessor:select_rates_classification:alpha": 0.48748392108905575,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2112320011142834,
        "time": 7.022191286087036,
        "additional_info": {
            "duration": 7.009171962738037,
            "num_run": 559,
            "train_loss": 1.1167400361684159,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001011166186106859,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005734252327375955,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.00017115294216381888,
            "feature_preprocessor:select_rates_classification:alpha": 0.015330099123699672,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0962522029876709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.413737643242119e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3039468558986101,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.0029009210994816763,
            "feature_preprocessor:select_rates_classification:alpha": 0.2962305414791389,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.8960237503051758,
        "additional_info": {
            "duration": 0.8856298923492432,
            "num_run": 561,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.042795154553801416,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010869530727137219,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 9.657344920300571e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.09488507331322259,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.4015822410583496,
        "additional_info": {
            "duration": 0.387592077255249,
            "num_run": 562,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.3502495374057786e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008938371724152792,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 1.0758630707524999e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.015334468743735119,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2360779036598915,
        "time": 1.5570769309997559,
        "additional_info": {
            "duration": 1.5429937839508057,
            "num_run": 563,
            "train_loss": 1.193350716076023,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006836609013768963,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09125570748636024,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 2.2547141241942935e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7100166234536095,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3791689872741699,
        "additional_info": {
            "duration": 0.3536350727081299,
            "num_run": 564,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.708499756394929e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015891222019746005,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.0032800167103012295,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017294385021987865,
            "feature_preprocessor:select_rates_classification:alpha": 0.14742012940416574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12313485145568848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002660720997335929,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004885678784953862,
            "classifier:CustomMLPClassifier:max_iter": 161,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.0002691044630271476,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04532190035474844,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5810810956143306,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2061495241347315,
        "time": 0.45673322677612305,
        "additional_info": {
            "duration": 0.440201997756958,
            "num_run": 566,
            "train_loss": 1.1725755633440114,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.4008060885049264e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012788957941723644,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 1.728717671605784e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020365645727957768,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8125992282077596,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2177613350747762,
        "time": 0.3517169952392578,
        "additional_info": {
            "duration": 0.33400511741638184,
            "num_run": 567,
            "train_loss": 1.1656863517037521,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004884397104741538,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1648321741813849,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 2.925998062345999e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 78.75868651583812,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2413036194056777,
        "time": 0.5929679870605469,
        "additional_info": {
            "duration": 0.574639081954956,
            "num_run": 568,
            "train_loss": 1.0331570297618786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011538382786305597,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05521483847666951,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 324,
            "classifier:CustomMLPClassifier:tol": 0.0004531522840910409,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07942935029245081,
            "feature_preprocessor:select_rates_classification:alpha": 0.1589259261928394,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09615492820739746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.018036629494299548,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027978750818358954,
            "classifier:CustomMLPClassifier:max_iter": 435,
            "classifier:CustomMLPClassifier:num_units": 220,
            "classifier:CustomMLPClassifier:tol": 0.004115562570232575,
            "feature_preprocessor:select_rates_classification:alpha": 0.40127321719076037,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12307310104370117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1552567819839615e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13413982722282664,
            "classifier:CustomMLPClassifier:max_iter": 389,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 4.880166218651197e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.10488731684701633,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5559351444244385,
        "additional_info": {
            "duration": 0.5458760261535645,
            "num_run": 571,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.008213168345541547,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013241012000762535,
            "classifier:CustomMLPClassifier:max_iter": 153,
            "classifier:CustomMLPClassifier:num_units": 165,
            "classifier:CustomMLPClassifier:tol": 0.0007398710637519617,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001503260156428181,
            "feature_preprocessor:select_rates_classification:alpha": 0.15691593567262843,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09694099426269531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.9107671019e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.032697113507428315,
            "classifier:CustomMLPClassifier:max_iter": 186,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.0029471210705266154,
            "feature_preprocessor:select_rates_classification:alpha": 0.014291051960717584,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2287004196879712,
        "time": 0.29280781745910645,
        "additional_info": {
            "duration": 0.28231096267700195,
            "num_run": 573,
            "train_loss": 1.1896562105899255,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07641076777124423,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.413594880058009,
            "classifier:CustomMLPClassifier:max_iter": 250,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 0.003427562411195348,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01657526932307181,
            "feature_preprocessor:select_rates_classification:alpha": 0.15146417530864623,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.1975022200822667,
        "time": 1.1659820079803467,
        "additional_info": {
            "duration": 1.153832197189331,
            "num_run": 574,
            "train_loss": 1.1359396375873279,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.749178801614732e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024768851387150944,
            "classifier:CustomMLPClassifier:max_iter": 141,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.0004504063550550561,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012196696436701078,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6773707997390739,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2001738263483666,
        "time": 1.1988418102264404,
        "additional_info": {
            "duration": 1.1819400787353516,
            "num_run": 575,
            "train_loss": 1.1963332935095812,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.9274807707546367e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.42397846613654655,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 225,
            "classifier:CustomMLPClassifier:tol": 0.0018063320864937797,
            "feature_preprocessor:select_rates_classification:alpha": 0.4799068725855444,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.26633691787719727,
        "additional_info": {
            "duration": 0.24974298477172852,
            "num_run": 576,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0039491623513066365,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028817229428377052,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 9.826957007843123e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.049468743034938444,
            "feature_preprocessor:select_rates_classification:alpha": 0.26271535246212524,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09535694122314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005164992203070054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023157562341979924,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 2.276674747319882e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3047641801164592,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10113096237182617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.773267377128828e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003951115698222257,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 5.9513088916158166e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 66.62251556239777,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2019505985918333,
        "time": 5.764595985412598,
        "additional_info": {
            "duration": 5.753653049468994,
            "num_run": 579,
            "train_loss": 1.0454947293949586,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.013565640352673125,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003589028690348278,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.002206502867032562,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015966939561389275,
            "feature_preprocessor:select_rates_classification:alpha": 0.23222911194455542,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.31615209579467773,
        "additional_info": {
            "duration": 0.30612611770629883,
            "num_run": 580,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03098666506854955,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015725917441368725,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 293,
            "classifier:CustomMLPClassifier:tol": 1.2147420242937641e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002488873626708659,
            "feature_preprocessor:select_rates_classification:alpha": 0.016951534427517578,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09607982635498047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0016799938074835408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06678662888420776,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 288,
            "classifier:CustomMLPClassifier:tol": 0.0011460441210016964,
            "feature_preprocessor:select_percentile_classification:percentile": 12.658121944835148,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2411925754825412,
        "time": 0.5045590400695801,
        "additional_info": {
            "duration": 0.4947478771209717,
            "num_run": 582,
            "train_loss": 1.204483075997181,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009320200654596236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8054969299721871,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 1.0639075243453426e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.07182459134116888,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12328481674194336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2859082266969102e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02852413485808257,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.0005888775279541409,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1416,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.26921757648053657,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2036549547690285,
        "time": 0.6243300437927246,
        "additional_info": {
            "duration": 0.5950069427490234,
            "num_run": 584,
            "train_loss": 1.1683975146417738,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022802145043011555,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3361318677305254,
            "classifier:CustomMLPClassifier:max_iter": 499,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.0004626434234069468,
            "feature_preprocessor:select_rates_classification:alpha": 0.028198962789821924,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09690713882446289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2698382837663729e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00048473964519375664,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.00013409311261693992,
            "feature_preprocessor:select_rates_classification:alpha": 0.42856067246228696,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12811708450317383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09321358366608833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019818057240978296,
            "classifier:CustomMLPClassifier:max_iter": 136,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 4.544529934751992e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.29676977691010076,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3366668224334717,
        "additional_info": {
            "duration": 0.3256800174713135,
            "num_run": 587,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0352875418566101,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016146040484758155,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 0.004306898584080311,
            "feature_preprocessor:select_rates_classification:alpha": 0.3921260509114432,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09699892997741699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004577035067543995,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.24270250631105522,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.008040370319394703,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000445082216071859,
            "feature_preprocessor:select_rates_classification:alpha": 0.3402745715391929,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0955359935760498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002529245970478611,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007710871174200453,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.0005470975727413248,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002628518471925433,
            "feature_preprocessor:select_rates_classification:alpha": 0.43611973449767005,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.130415678024292,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.071598413447416,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1490774771025903,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 0.005953058671174936,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.05987216489880798,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1874434803235971,
        "time": 0.3952600955963135,
        "additional_info": {
            "duration": 0.3823869228363037,
            "num_run": 591,
            "train_loss": 1.164046274680816,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.525746828916067e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11724800761922473,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 3.125441761317726e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.033405656775698074,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12336015701293945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.693090381043972e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015910387364766722,
            "classifier:CustomMLPClassifier:max_iter": 392,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 1.0583345502214444e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5889573903956626,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1843840120472975,
        "time": 1.2970058917999268,
        "additional_info": {
            "duration": 1.2792329788208008,
            "num_run": 593,
            "train_loss": 1.1491618826628422,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.4479560076347116e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007614736650750518,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 139,
            "classifier:CustomMLPClassifier:tol": 0.0004952213855682242,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9300084298614845,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2691510956467036,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2730843870026548,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2175199283376938,
        "time": 0.31585192680358887,
        "additional_info": {
            "duration": 0.2981882095336914,
            "num_run": 594,
            "train_loss": 1.1854037677346096,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001363281853556592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0038275301384303705,
            "classifier:CustomMLPClassifier:max_iter": 203,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.001627088325590035,
            "feature_preprocessor:select_rates_classification:alpha": 0.19795326087585113,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10173988342285156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008190795465134928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06200211910304679,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 1.0433791447936293e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14662832003043172,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1269,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17319832363438692,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2464327803964348,
        "time": 0.4791719913482666,
        "additional_info": {
            "duration": 0.46468687057495117,
            "num_run": 596,
            "train_loss": 1.0728568886465768,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00969021028516938,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001123060465934956,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 0.008644521734259088,
            "feature_preprocessor:select_percentile_classification:percentile": 84.49863601547287,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.3015580177307129,
        "additional_info": {
            "duration": 0.2821650505065918,
            "num_run": 597,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1266699729255142e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01669911843369413,
            "classifier:CustomMLPClassifier:max_iter": 476,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 0.00610543860070879,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14270803846620536,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3181054383666879,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2391824328068224,
        "time": 0.3176758289337158,
        "additional_info": {
            "duration": 0.3052830696105957,
            "num_run": 598,
            "train_loss": 1.1980698346051193,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00018742083479408696,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004098285665157379,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 3.324441972568143e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000124413727823571,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7976907009721143,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.213280771646867,
        "time": 0.8846526145935059,
        "additional_info": {
            "duration": 0.8650760650634766,
            "num_run": 599,
            "train_loss": 1.1919425422179148,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002257196647834765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15310717268472615,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.0005890860668378989,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10335789696545342,
            "feature_preprocessor:select_percentile_classification:percentile": 22.343669289603522,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.1969621181488037,
        "additional_info": {
            "duration": 0.1853349208831787,
            "num_run": 600,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2751963454180187e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007760377565177037,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 0.001330600999771316,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008054078288834242,
            "feature_preprocessor:select_rates_classification:alpha": 0.2950491915992408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09674286842346191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.015941856795954595,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011099462792849525,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 0.00019701087796156457,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010903069198943077,
            "feature_preprocessor:select_rates_classification:alpha": 0.31874354573246266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0965418815612793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.189273616627483e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00034643687684528495,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.00028899330665789984,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7177362509834468,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.053416156277178856,
            "feature_preprocessor:select_rates_classification:alpha": 0.41022620630277257,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2252901040425166,
        "time": 0.5084199905395508,
        "additional_info": {
            "duration": 0.49158191680908203,
            "num_run": 603,
            "train_loss": 1.1745486361127162,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005811723679835498,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2456738922418365,
            "classifier:CustomMLPClassifier:max_iter": 278,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 0.0013515827773568836,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.057449229211314116,
            "feature_preprocessor:select_percentile_classification:percentile": 98.9412216158144,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.219169554274098,
        "time": 0.7444009780883789,
        "additional_info": {
            "duration": 0.7271790504455566,
            "num_run": 604,
            "train_loss": 1.0150843192622963,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.4632412859543553e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2133628374806732,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 59,
            "classifier:CustomMLPClassifier:tol": 0.0025895303128710967,
            "feature_preprocessor:select_rates_classification:alpha": 0.03884017144031416,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1283121109008789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.016822653625386434,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001965207152119497,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 242,
            "classifier:CustomMLPClassifier:tol": 0.0007768682390846765,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07552249448625914,
            "feature_preprocessor:select_percentile_classification:percentile": 44.447634435161824,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2053914958645668,
        "time": 0.6575427055358887,
        "additional_info": {
            "duration": 0.6463899612426758,
            "num_run": 606,
            "train_loss": 1.0649843344582417,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0010445559629718808,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021676586394681855,
            "classifier:CustomMLPClassifier:max_iter": 173,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.0011778501286164875,
            "feature_preprocessor:select_rates_classification:alpha": 0.3154011665743315,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2102084274182787,
        "time": 0.320220947265625,
        "additional_info": {
            "duration": 0.30874204635620117,
            "num_run": 607,
            "train_loss": 1.1653097524300209,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014368459426079368,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3464305266521137,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.0008179044312011441,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007233608754573527,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8207656483898705,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.30792975425720215,
        "additional_info": {
            "duration": 0.2933018207550049,
            "num_run": 608,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.9659065362284954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013894250757984271,
            "classifier:CustomMLPClassifier:max_iter": 328,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 0.0017420736360586676,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016582083279761395,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1830,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.16153258843601112,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2077347802344498,
        "time": 0.34518003463745117,
        "additional_info": {
            "duration": 0.3326427936553955,
            "num_run": 609,
            "train_loss": 1.1582386288254491,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.498982025803699e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003370353427786382,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 99,
            "classifier:CustomMLPClassifier:tol": 0.000792056091160991,
            "feature_preprocessor:select_rates_classification:alpha": 0.25947986712841337,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12385201454162598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.042544558387935985,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19595411699695414,
            "classifier:CustomMLPClassifier:max_iter": 105,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.0007838126616913884,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03989805764299084,
            "feature_preprocessor:select_rates_classification:alpha": 0.14300336309995715,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09692764282226562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0017948914330080728,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09528358637476243,
            "classifier:CustomMLPClassifier:max_iter": 310,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 1.055356792404515e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5163473790330221,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2239382084502954,
        "time": 0.2951819896697998,
        "additional_info": {
            "duration": 0.2767772674560547,
            "num_run": 612,
            "train_loss": 1.1751367902382261,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0020648183319244345,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009634688085170214,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 6.032338845273975e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004395052287964214,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14773314368865098,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2181347178416244,
        "time": 0.5165848731994629,
        "additional_info": {
            "duration": 0.49890995025634766,
            "num_run": 613,
            "train_loss": 1.043618120698856,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.008066016287627e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00708456516339261,
            "classifier:CustomMLPClassifier:max_iter": 121,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 7.612654782972975e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037371510639255673,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3962698556912273,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.33515334129333496,
        "additional_info": {
            "duration": 0.31934380531311035,
            "num_run": 614,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002729809317569408,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00996044182787325,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 180,
            "classifier:CustomMLPClassifier:tol": 1.1957466841607624e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.22330861606718422,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.32889509201049805,
        "additional_info": {
            "duration": 0.31298089027404785,
            "num_run": 615,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0399979057226467e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02381208576711448,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 422,
            "classifier:CustomMLPClassifier:tol": 0.0008390691476220333,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009947450298176872,
            "feature_preprocessor:select_rates_classification:alpha": 0.086590279285916,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2001738263483666,
        "time": 0.25540590286254883,
        "additional_info": {
            "duration": 0.24234890937805176,
            "num_run": 616,
            "train_loss": 1.169216386636722,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002639995430734454,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011821953489130174,
            "classifier:CustomMLPClassifier:max_iter": 115,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0031359317781971827,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001166772320311669,
            "feature_preprocessor:select_percentile_classification:percentile": 24.30779304988258,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.234008220870189,
        "time": 0.3030128479003906,
        "additional_info": {
            "duration": 0.2908918857574463,
            "num_run": 617,
            "train_loss": 1.224080198871698,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006576663521653519,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00395688057685348,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 0.007278143362822534,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11619411759171938,
            "feature_preprocessor:select_rates_classification:alpha": 0.4070882084269088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12643194198608398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011185926033165164,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26824487033359135,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.00020155667649542457,
            "feature_preprocessor:select_rates_classification:alpha": 0.20169488107963063,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0963747501373291,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0072801242544523305,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.22824001329697063,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.00018036477704993915,
            "feature_preprocessor:select_rates_classification:alpha": 0.03859641455081889,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12327289581298828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004976555259487937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020000080529043368,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 249,
            "classifier:CustomMLPClassifier:tol": 2.5553182961754868e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4556127784824815,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.32268810272216797,
        "additional_info": {
            "duration": 0.30455493927001953,
            "num_run": 621,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.14219338545448e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005271684064146274,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 415,
            "classifier:CustomMLPClassifier:tol": 0.009577380676121681,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0031403870469817008,
            "feature_preprocessor:select_rates_classification:alpha": 0.2593226437678327,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.258544921875,
        "additional_info": {
            "duration": 0.24356818199157715,
            "num_run": 622,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021718917176755042,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004237522129749529,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 3.268656012571584e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22492658901319007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1235959529876709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.003132652758276126,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05314116671227675,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.005520622229890254,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3860984593773214,
            "feature_preprocessor:select_percentile_classification:percentile": 21.20867293580466,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.2246379852294922,
        "additional_info": {
            "duration": 0.20889711380004883,
            "num_run": 624,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0529807956976363e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004725866203135176,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.0004590256538168615,
            "feature_preprocessor:select_rates_classification:alpha": 0.4064504486326665,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4851348400115967,
        "additional_info": {
            "duration": 0.47419190406799316,
            "num_run": 625,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.05455075019075534,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001668028639723915,
            "classifier:CustomMLPClassifier:max_iter": 440,
            "classifier:CustomMLPClassifier:num_units": 264,
            "classifier:CustomMLPClassifier:tol": 0.0017256178422617968,
            "feature_preprocessor:select_rates_classification:alpha": 0.31986114939423527,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.26635074615478516,
        "additional_info": {
            "duration": 0.2537510395050049,
            "num_run": 626,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00021685924256736102,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000495846058496056,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.0001181809268371488,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07942327262411696,
            "feature_preprocessor:select_rates_classification:alpha": 0.14050483326787083,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12299180030822754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.13927578292609e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11608238022651622,
            "classifier:CustomMLPClassifier:max_iter": 431,
            "classifier:CustomMLPClassifier:num_units": 258,
            "classifier:CustomMLPClassifier:tol": 0.0005932616038031979,
            "feature_preprocessor:select_rates_classification:alpha": 0.49894325487294855,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10161900520324707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.051444333399198e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014384075548686253,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 362,
            "classifier:CustomMLPClassifier:tol": 0.0002644780219753469,
            "feature_preprocessor:select_rates_classification:alpha": 0.04858208559974817,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12306094169616699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.200966558597935e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0749007724464068,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.00012252997466593769,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006873646317664654,
            "feature_preprocessor:select_rates_classification:alpha": 0.029055389121328802,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2157705112898674,
        "time": 0.3545210361480713,
        "additional_info": {
            "duration": 0.34185099601745605,
            "num_run": 630,
            "train_loss": 1.0551212660900167,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.7959739029041155e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011935057698712651,
            "classifier:CustomMLPClassifier:max_iter": 433,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 1.5161954707573442e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3074723492665553,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09638118743896484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004987427170249796,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005275436289199457,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.000282851370635152,
            "feature_preprocessor:select_rates_classification:alpha": 0.08311743096332126,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1012868881225586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03749551922845159,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08945507121448694,
            "classifier:CustomMLPClassifier:max_iter": 393,
            "classifier:CustomMLPClassifier:num_units": 246,
            "classifier:CustomMLPClassifier:tol": 0.0013658321486886042,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001902462859947108,
            "feature_preprocessor:select_rates_classification:alpha": 0.014077464724104687,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2417751800681287,
        "time": 0.2700951099395752,
        "additional_info": {
            "duration": 0.25512099266052246,
            "num_run": 633,
            "train_loss": 1.2007961059212868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5562118940572403e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.724022815092005,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 409,
            "classifier:CustomMLPClassifier:tol": 0.003429967862398234,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.34119567293903447,
            "feature_preprocessor:select_percentile_classification:percentile": 15.174922298958588,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.1849057674407959,
        "additional_info": {
            "duration": 0.17400813102722168,
            "num_run": 634,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.4845870338737203e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16992839413049604,
            "classifier:CustomMLPClassifier:max_iter": 469,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 0.008461714531978646,
            "feature_preprocessor:select_rates_classification:alpha": 0.02235172132995473,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10100412368774414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010639272694881186,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12318936476707631,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 83,
            "classifier:CustomMLPClassifier:tol": 5.8016075111070367e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.22935311466136013,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12350082397460938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0018376447538876583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0015185570142720796,
            "classifier:CustomMLPClassifier:max_iter": 390,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.0014700285876830042,
            "feature_preprocessor:select_rates_classification:alpha": 0.01868035835078872,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10193204879760742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2080256436596856e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03795409827499976,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 144,
            "classifier:CustomMLPClassifier:tol": 2.134343409582092e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.023791558841207303,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10101509094238281,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0066545640486882504,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010096569056912858,
            "classifier:CustomMLPClassifier:max_iter": 407,
            "classifier:CustomMLPClassifier:num_units": 195,
            "classifier:CustomMLPClassifier:tol": 2.3877228022014704e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.0796467827257918,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09789109230041504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 6.242780735057181e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08350006832760656,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 0.008562053969805902,
            "feature_preprocessor:select_rates_classification:alpha": 0.2545340244373193,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12423110008239746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.02118478184090139,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0022195760481821918,
            "classifier:CustomMLPClassifier:max_iter": 395,
            "classifier:CustomMLPClassifier:num_units": 346,
            "classifier:CustomMLPClassifier:tol": 3.481253338443335e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1643344255058433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12323880195617676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07999118313709214,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.582067061430553,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 1.296002379796258e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000712749612190374,
            "feature_preprocessor:select_rates_classification:alpha": 0.4019980264981985,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.0970461368560791,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.348865057595876e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00046283468555843535,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 7.09858225921229e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002428368761556431,
            "feature_preprocessor:select_rates_classification:alpha": 0.24501134828748367,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13601303100585938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.829806773261436e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6872177296455801,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.007234202495824903,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003816314550440835,
            "feature_preprocessor:select_rates_classification:alpha": 0.07318465579081691,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1018519401550293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.060891785802147734,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009426967102140652,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 211,
            "classifier:CustomMLPClassifier:tol": 0.009399274246286188,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6622183637370389,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2219683068472604,
        "time": 0.3320271968841553,
        "additional_info": {
            "duration": 0.3193519115447998,
            "num_run": 645,
            "train_loss": 1.193236810592236,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0414707671935012,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006048551701313815,
            "classifier:CustomMLPClassifier:max_iter": 346,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.006326587089854446,
            "feature_preprocessor:select_percentile_classification:percentile": 1.9719689259159614,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.20879292488098145,
        "additional_info": {
            "duration": 0.18798589706420898,
            "num_run": 646,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.111270835497135e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032049704777640484,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 114,
            "classifier:CustomMLPClassifier:tol": 5.6496353490922666e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8870174621844754,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12125082251084142,
            "feature_preprocessor:select_rates_classification:alpha": 0.24431892368915212,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.202180742592447,
        "time": 0.2823061943054199,
        "additional_info": {
            "duration": 0.271014928817749,
            "num_run": 647,
            "train_loss": 1.1425987052269737,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.5589927555371753e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006099433212560793,
            "classifier:CustomMLPClassifier:max_iter": 200,
            "classifier:CustomMLPClassifier:num_units": 174,
            "classifier:CustomMLPClassifier:tol": 1.4231217615275216e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5131647959951183,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.209246007052077,
        "time": 0.34116196632385254,
        "additional_info": {
            "duration": 0.3271629810333252,
            "num_run": 648,
            "train_loss": 1.188114930672631,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1062777295998777e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47147248442996653,
            "classifier:CustomMLPClassifier:max_iter": 397,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 3.522295354028718e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18343758313876557,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.3588898181915283,
        "additional_info": {
            "duration": 1.3463830947875977,
            "num_run": 649,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0019290481697714918,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002616276023884774,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.0004566437820504626,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04404676519317103,
            "feature_preprocessor:select_rates_classification:alpha": 0.41442510213294936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.4185190200805664,
        "additional_info": {
            "duration": 0.4044220447540283,
            "num_run": 650,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01135920996523925,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00012936461684773487,
            "classifier:CustomMLPClassifier:max_iter": 446,
            "classifier:CustomMLPClassifier:num_units": 152,
            "classifier:CustomMLPClassifier:tol": 6.915223295622964e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11856167730272343,
            "feature_preprocessor:select_percentile_classification:percentile": 34.89774516101914,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.250536744550613,
        "time": 0.8230946063995361,
        "additional_info": {
            "duration": 0.8045198917388916,
            "num_run": 651,
            "train_loss": 1.1660455095662985,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.31575992362268e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01601207517362492,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 297,
            "classifier:CustomMLPClassifier:tol": 0.00022093050369937476,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023853396290238624,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1378,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.1330675458632254,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2094552288708165,
        "time": 0.26149678230285645,
        "additional_info": {
            "duration": 0.24651193618774414,
            "num_run": 652,
            "train_loss": 1.1793334280892986,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012928295181755086,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3939021495103756,
            "classifier:CustomMLPClassifier:max_iter": 442,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 0.00011923944463193099,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024047420151664084,
            "feature_preprocessor:select_rates_classification:alpha": 0.22010618622251688,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0978858470916748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.9063148443865844e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02562879950855805,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.00417314582683672,
            "feature_preprocessor:select_rates_classification:alpha": 0.20833062623110332,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09607815742492676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3735859735011419e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00032407420205477313,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 487,
            "classifier:CustomMLPClassifier:tol": 0.0019224658112133835,
            "feature_preprocessor:select_percentile_classification:percentile": 2.840841450048651,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2699909210205078,
        "additional_info": {
            "duration": 0.25220823287963867,
            "num_run": 655,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009993068455506942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028291219678798648,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 1.1030937774527018e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.35556620618839574,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12319087982177734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0001934102674061864,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00028025088422648094,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 360,
            "classifier:CustomMLPClassifier:tol": 2.7075979551768076e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.212954667076498,
            "feature_preprocessor:select_percentile_classification:percentile": 42.06285230489952,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.1888195146045757,
        "time": 1.263535737991333,
        "additional_info": {
            "duration": 1.247377872467041,
            "num_run": 657,
            "train_loss": 1.1043279423822576,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.8001877184756978e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002860767067272002,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.0005778036068980774,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16540128941345178,
            "feature_preprocessor:select_percentile_classification:percentile": 71.18404950957165,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2196250224773775,
        "time": 0.2793872356414795,
        "additional_info": {
            "duration": 0.2621932029724121,
            "num_run": 658,
            "train_loss": 1.1453569524636467,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.8370907848544114e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010339738988662308,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.0010379846334402972,
            "feature_preprocessor:select_percentile_classification:percentile": 95.49055622015092,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2194898299407289,
        "time": 0.27179789543151855,
        "additional_info": {
            "duration": 0.2601039409637451,
            "num_run": 659,
            "train_loss": 1.164260736434459,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00015279710376745514,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008630684825323046,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 472,
            "classifier:CustomMLPClassifier:tol": 0.002467976471504485,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04316816668916976,
            "feature_preprocessor:select_rates_classification:alpha": 0.1468500840738479,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12903690338134766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008862734556598103,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18905966722015588,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 0.004730579197284318,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003895911712372355,
            "feature_preprocessor:select_rates_classification:alpha": 0.2491885355049959,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12318086624145508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.975548790741612e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021339230937018587,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 1.5652936439953743e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1200,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 87.49702857847139,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.209495460018745,
        "time": 0.6337828636169434,
        "additional_info": {
            "duration": 0.6119279861450195,
            "num_run": 662,
            "train_loss": 1.0684661373549105,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0028430699800005197,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014172769232196514,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 136,
            "classifier:CustomMLPClassifier:tol": 1.6172143323248286e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25493881124150874,
            "feature_preprocessor:select_rates_classification:alpha": 0.48189752339688774,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12842798233032227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006459602508774642,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6644379468012181,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.00021264407740028706,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0222328045669427,
            "feature_preprocessor:select_rates_classification:alpha": 0.04265096487320654,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2609288692474365,
        "additional_info": {
            "duration": 0.24242305755615234,
            "num_run": 664,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07169324435726783,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00034348697001419543,
            "classifier:CustomMLPClassifier:max_iter": 348,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.006869793640081791,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8606456587771647,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1521695911663159,
            "feature_preprocessor:select_percentile_classification:percentile": 32.24653921556965,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2291912893164771,
        "time": 0.3024630546569824,
        "additional_info": {
            "duration": 0.2919020652770996,
            "num_run": 665,
            "train_loss": 1.2207779749063024,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004932780514267381,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04999734139222203,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 0.00011470634875143642,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2768636759600964,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.287284152075618,
        "time": 0.35112500190734863,
        "additional_info": {
            "duration": 0.33568406105041504,
            "num_run": 666,
            "train_loss": 1.1244481198036236,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.155117490339379e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06059616118878347,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.00017590335184322555,
            "feature_preprocessor:select_rates_classification:alpha": 0.46722293083477934,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09672284126281738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.329855087657639e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00021437388974364523,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 1.064793879420128e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.30107042568640163,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12431597709655762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001378084464503094,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.26634456063660933,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.0009935044962992663,
            "feature_preprocessor:select_rates_classification:alpha": 0.19100965187729196,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0962681770324707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00928288297750848,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01578788620602045,
            "classifier:CustomMLPClassifier:max_iter": 357,
            "classifier:CustomMLPClassifier:num_units": 387,
            "classifier:CustomMLPClassifier:tol": 0.00013499762376837404,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000944863962088626,
            "feature_preprocessor:select_rates_classification:alpha": 0.10217263740362235,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12622809410095215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.031234636731585084,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9156021484936543,
            "classifier:CustomMLPClassifier:max_iter": 486,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.008246404764609529,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.02955654633857336,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.227808812096977,
        "time": 0.34769630432128906,
        "additional_info": {
            "duration": 0.325747013092041,
            "num_run": 671,
            "train_loss": 1.190935370586101,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005424570444821198,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08333577779386359,
            "classifier:CustomMLPClassifier:max_iter": 495,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.0001476280477690872,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.39868761159582633,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7992821347954505,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.5308312845892662,
        "time": 0.39269399642944336,
        "additional_info": {
            "duration": 0.3795180320739746,
            "num_run": 672,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010318099679533967,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6364704808563392,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.009797803954252376,
            "feature_preprocessor:select_rates_classification:alpha": 0.20016592268308725,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2824012374694007,
        "time": 0.27612805366516113,
        "additional_info": {
            "duration": 0.2576909065246582,
            "num_run": 673,
            "train_loss": 1.1976717392806893,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.947541355954447e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4850857157740682,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 496,
            "classifier:CustomMLPClassifier:tol": 6.19398679399187e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2646608729018217,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09647583961486816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.22382390476455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005182233919433379,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.0006993279136497127,
            "feature_preprocessor:select_rates_classification:alpha": 0.35706280501734594,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2275545294076062,
        "time": 0.5260269641876221,
        "additional_info": {
            "duration": 0.513883113861084,
            "num_run": 675,
            "train_loss": 1.0252670341623586,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005254307535326121,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001098599001828885,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 1.8607238285161845e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.09975366416384981,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.241287526946506,
        "time": 1.0153567790985107,
        "additional_info": {
            "duration": 1.0042431354522705,
            "num_run": 676,
            "train_loss": 1.0551694981263178,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00017301644886900366,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9472833076152318,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 348,
            "classifier:CustomMLPClassifier:tol": 0.005400942940254635,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021869975948455956,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7255088685114,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_rates_classification:alpha": 0.012769181240628516,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.19692230224609375,
        "additional_info": {
            "duration": 0.18434596061706543,
            "num_run": 677,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.1342444968307115e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008282219111525662,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 280,
            "classifier:CustomMLPClassifier:tol": 0.00017294307670854395,
            "feature_preprocessor:select_rates_classification:alpha": 0.43404386341647033,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.2417769432067871,
        "additional_info": {
            "duration": 0.22729706764221191,
            "num_run": 678,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009681130046921147,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12019469236919873,
            "classifier:CustomMLPClassifier:max_iter": 359,
            "classifier:CustomMLPClassifier:num_units": 203,
            "classifier:CustomMLPClassifier:tol": 0.00014912850862999213,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008571616498239393,
            "feature_preprocessor:select_percentile_classification:percentile": 50.58199046404147,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.25526976585388184,
        "additional_info": {
            "duration": 0.23644804954528809,
            "num_run": 679,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0032891010455822515,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06438240353662304,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 0.004117767027964079,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0037058174374151698,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3958534432014943,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.2547290325164795,
        "additional_info": {
            "duration": 0.23880982398986816,
            "num_run": 680,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.05927440516630745,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000563323635852794,
            "classifier:CustomMLPClassifier:max_iter": 123,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 0.008968122593711719,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9075287485081198,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2396105358897065,
        "time": 0.31774306297302246,
        "additional_info": {
            "duration": 0.29907894134521484,
            "num_run": 681,
            "train_loss": 1.2171886541983996,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010719646023571993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013256578789857073,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.003144167481106254,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49788301117114964,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.22783134749467,
        "time": 0.27777814865112305,
        "additional_info": {
            "duration": 0.25992894172668457,
            "num_run": 682,
            "train_loss": 1.2214172679699775,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.058548310870195e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013988025270268104,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 393,
            "classifier:CustomMLPClassifier:tol": 0.0003596737294049105,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002964048806249985,
            "feature_preprocessor:select_rates_classification:alpha": 0.3281471431341464,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2283946331894477,
        "time": 1.14143705368042,
        "additional_info": {
            "duration": 1.1260159015655518,
            "num_run": 683,
            "train_loss": 1.1667504760774596,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0018761601933638666,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013654894262545838,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.009848736413117608,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23948537504942582,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45064518273426113,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.199805273304221,
        "time": 0.32694125175476074,
        "additional_info": {
            "duration": 0.3125162124633789,
            "num_run": 684,
            "train_loss": 1.1901972804167842,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.597346719114035e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008268022877920597,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 0.00013207267871428522,
            "feature_preprocessor:select_rates_classification:alpha": 0.2998530014560245,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09608316421508789,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.021446566439737115,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008612021487024736,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 0.0002465773746400715,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018535265525606578,
            "feature_preprocessor:select_rates_classification:alpha": 0.11664206060078869,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.26401281356811523,
        "additional_info": {
            "duration": 0.2526857852935791,
            "num_run": 686,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00010502333343199695,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16371422743712077,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 308,
            "classifier:CustomMLPClassifier:tol": 0.0004859483538240117,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13748705264145733,
            "feature_preprocessor:select_rates_classification:alpha": 0.2849641289724796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10164880752563477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0597675992407294,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007525248577605952,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.0012515687715992402,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8792185757640664,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2388219259922626,
        "time": 0.3446662425994873,
        "additional_info": {
            "duration": 0.3290901184082031,
            "num_run": 688,
            "train_loss": 1.170396749527256,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003212121687043577,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.023110340295889556,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 0.0005317473857515597,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9458571178922173,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2242906690352693,
        "time": 0.28518104553222656,
        "additional_info": {
            "duration": 0.26662278175354004,
            "num_run": 689,
            "train_loss": 1.1792282433111039,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06228267800533591,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00026538156484783823,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 382,
            "classifier:CustomMLPClassifier:tol": 0.0006435041394109187,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29051190775707253,
            "feature_preprocessor:select_percentile_classification:percentile": 43.18570814878866,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.211207862425526,
        "time": 0.34720325469970703,
        "additional_info": {
            "duration": 0.336594820022583,
            "num_run": 690,
            "train_loss": 1.1961275524615307,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01891650284734714,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003256523161493059,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 1.410049099639606e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002517686308704292,
            "feature_preprocessor:select_rates_classification:alpha": 0.49527510789523643,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10089588165283203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0017821898046166173,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.98156989827033,
            "classifier:CustomMLPClassifier:max_iter": 119,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.0018756826546909827,
            "feature_preprocessor:select_rates_classification:alpha": 0.0920916897502778,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10115194320678711,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.4144822294130664e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.052708721822285,
            "classifier:CustomMLPClassifier:max_iter": 493,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 7.924396740413861e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009665719097391664,
            "feature_preprocessor:select_rates_classification:alpha": 0.0695717374680869,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12395524978637695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.13854732365025e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004207962601968389,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 435,
            "classifier:CustomMLPClassifier:tol": 0.00038053297889986096,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012159625469505092,
            "feature_preprocessor:select_rates_classification:alpha": 0.31265780596635273,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12900114059448242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0010320239424437168,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02483305471422512,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.0005437140689268053,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027518685008829105,
            "feature_preprocessor:select_rates_classification:alpha": 0.07151961074682432,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09591484069824219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0021338176811021453,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.18688474835849192,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 413,
            "classifier:CustomMLPClassifier:tol": 0.0012165451851158706,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039152081096012275,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1298,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 10.100568269857078,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2704079975329223,
        "time": 0.4370267391204834,
        "additional_info": {
            "duration": 0.4194071292877197,
            "num_run": 696,
            "train_loss": 1.2273922912803361,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011002044708304025,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010138163818853592,
            "classifier:CustomMLPClassifier:max_iter": 414,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.007047407294043066,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002809887539118338,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1045,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 13.395271319368844,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.3074676245702173,
        "time": 0.252666711807251,
        "additional_info": {
            "duration": 0.2368180751800537,
            "num_run": 697,
            "train_loss": 1.312062677275494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0014438226347283853,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5819655139916644,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 296,
            "classifier:CustomMLPClassifier:tol": 2.0390511762210137e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.04990902460974036,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2826850414276123,
        "additional_info": {
            "duration": 0.2616279125213623,
            "num_run": 698,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.022877221646884383,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000741122535665766,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 306,
            "classifier:CustomMLPClassifier:tol": 0.00997183144416212,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1729412787333895,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.2721099853515625,
        "additional_info": {
            "duration": 0.25180792808532715,
            "num_run": 699,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00022157645741039544,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09306104425771503,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.00022958332884149229,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013325833912577532,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1996,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1356669121099574,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2000273710752487,
        "time": 0.3940112590789795,
        "additional_info": {
            "duration": 0.38301801681518555,
            "num_run": 700,
            "train_loss": 1.1904791372243881,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03048334825309942,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008674003970617388,
            "classifier:CustomMLPClassifier:max_iter": 210,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 4.7406208529966854e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1651295222763447,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.230507773558717,
        "time": 0.5533978939056396,
        "additional_info": {
            "duration": 0.5323309898376465,
            "num_run": 701,
            "train_loss": 1.1649604630107169,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.597348261534041e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034688041446840684,
            "classifier:CustomMLPClassifier:max_iter": 482,
            "classifier:CustomMLPClassifier:num_units": 285,
            "classifier:CustomMLPClassifier:tol": 0.0036821618726699252,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8354266049348925,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2518966863724201,
        "time": 0.31306886672973633,
        "additional_info": {
            "duration": 0.3003199100494385,
            "num_run": 702,
            "train_loss": 1.1792282433111039,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.8064564015894797e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04004859950133441,
            "classifier:CustomMLPClassifier:max_iter": 416,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 9.559380179891348e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.19211061069299032,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09722089767456055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005953310643109285,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0027219977966118558,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 0.0004596117977188117,
            "feature_preprocessor:select_rates_classification:alpha": 0.22345493604670433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.215422880427596,
        "time": 0.2507922649383545,
        "additional_info": {
            "duration": 0.23848199844360352,
            "num_run": 704,
            "train_loss": 1.1698888033585528,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004898956928348835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006209522233304062,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 390,
            "classifier:CustomMLPClassifier:tol": 0.00166705788876,
            "feature_preprocessor:select_rates_classification:alpha": 0.24474099775644825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12339520454406738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00012840502678369668,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0989072287752771,
            "classifier:CustomMLPClassifier:max_iter": 454,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.00020337119171907412,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0574964994821915,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9780669469424825,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29921734151039053,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.806611992444459,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222938773443048,
        "time": 0.4446110725402832,
        "additional_info": {
            "duration": 0.4267268180847168,
            "num_run": 706,
            "train_loss": 1.1207059561500499,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002946853321741156,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.21843765592289366,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 1.7699501305757384e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19745840530692468,
            "feature_preprocessor:select_rates_classification:alpha": 0.4914359864187786,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.35848093032836914,
        "additional_info": {
            "duration": 0.3462862968444824,
            "num_run": 707,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.003021794278475073,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0050433414513439394,
            "classifier:CustomMLPClassifier:max_iter": 277,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.009850226331588647,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1223,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2153197533861413,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.25469493865966797,
        "additional_info": {
            "duration": 0.24308204650878906,
            "num_run": 708,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.751580687021586e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.348518394098469,
            "classifier:CustomMLPClassifier:max_iter": 261,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 1.0062896175601938e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028491059575908913,
            "feature_preprocessor:select_rates_classification:alpha": 0.28139274919439505,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.19608020782470703,
        "additional_info": {
            "duration": 0.1831822395324707,
            "num_run": 709,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000803819788046534,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005089119862157647,
            "classifier:CustomMLPClassifier:max_iter": 407,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 0.003278731383066826,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7247181820735548,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12230896216519194,
            "feature_preprocessor:select_rates_classification:alpha": 0.36800302731442514,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2128494520570996,
        "time": 0.20398592948913574,
        "additional_info": {
            "duration": 0.18661713600158691,
            "num_run": 710,
            "train_loss": 1.1884276156630906,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08327808194591539,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002558392801274533,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.004019860794689133,
            "feature_preprocessor:select_rates_classification:alpha": 0.21748085314698096,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.25626397132873535,
        "additional_info": {
            "duration": 0.23703312873840332,
            "num_run": 711,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.3801381896374545e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016400052094625987,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 4.861773558478842e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7987817016620727,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09205996377311661,
            "feature_preprocessor:select_percentile_classification:percentile": 55.8993720327799,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2173766895714595,
        "time": 0.8636181354522705,
        "additional_info": {
            "duration": 0.8522157669067383,
            "num_run": 712,
            "train_loss": 1.161457737932174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.023364762720873105,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006463800612366553,
            "classifier:CustomMLPClassifier:max_iter": 411,
            "classifier:CustomMLPClassifier:num_units": 116,
            "classifier:CustomMLPClassifier:tol": 0.00018669699088333803,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003906190322561134,
            "feature_preprocessor:select_percentile_classification:percentile": 17.631605000539878,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2123344437398365,
        "time": 0.21922707557678223,
        "additional_info": {
            "duration": 0.20406198501586914,
            "num_run": 713,
            "train_loss": 1.2005444658699742,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.2018158408793705e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008938557292260466,
            "classifier:CustomMLPClassifier:max_iter": 220,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 0.00044453291676348027,
            "feature_preprocessor:select_rates_classification:alpha": 0.3791084613792544,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.2192533016204834,
        "additional_info": {
            "duration": 0.20050406455993652,
            "num_run": 714,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.142953821995256e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007119567263073678,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 1.3592574137860177e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1055,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2381038445419415,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2075094659565386,
        "time": 0.3447730541229248,
        "additional_info": {
            "duration": 0.32936596870422363,
            "num_run": 715,
            "train_loss": 1.1759172986401158,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.320662437198943e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6251830577310759,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 5.4029795323859926e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00042940212581302943,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 893,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.06935258287754109,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2370451537487959,
        "time": 0.3132648468017578,
        "additional_info": {
            "duration": 0.29925990104675293,
            "num_run": 716,
            "train_loss": 1.177127304418116,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008373333351084254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023365467181149876,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 1.400779015741784e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4982913547059304,
            "feature_preprocessor:select_rates_classification:alpha": 0.16394220873546292,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09686398506164551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00015904469133943378,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001487736141179746,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 331,
            "classifier:CustomMLPClassifier:tol": 1.5019247719578926e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000731595389994203,
            "feature_preprocessor:select_rates_classification:alpha": 0.17696627115078023,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12834692001342773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012259775320146117,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.47732884807638043,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 346,
            "classifier:CustomMLPClassifier:tol": 1.0075933861966331e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5322505299112777,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3681490421295166,
        "additional_info": {
            "duration": 0.3510777950286865,
            "num_run": 719,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0338072954672116e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4690335310318384,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 0.008658625885305579,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00036238128032140985,
            "feature_preprocessor:select_percentile_classification:percentile": 88.60252716961558,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.24921703338623047,
        "additional_info": {
            "duration": 0.2332930564880371,
            "num_run": 720,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.751652869393801e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013534576272590916,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 146,
            "classifier:CustomMLPClassifier:tol": 1.8924524850626265e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8198576533678973,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2457359054560726,
        "time": 0.3660402297973633,
        "additional_info": {
            "duration": 0.339000940322876,
            "num_run": 721,
            "train_loss": 1.1734153575208337,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005723376262401623,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17348922417694074,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 2.4791439976783044e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000731534237076284,
            "feature_preprocessor:select_rates_classification:alpha": 0.38201679183695736,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1288137435913086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1665264003646399e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04025735415207494,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.00015742449377232828,
            "feature_preprocessor:select_rates_classification:alpha": 0.229920674085228,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09686398506164551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.408963247404563e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015703325317850122,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 154,
            "classifier:CustomMLPClassifier:tol": 0.000495773540067355,
            "feature_preprocessor:select_rates_classification:alpha": 0.08011432941734122,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.214280206654114,
        "time": 0.3428812026977539,
        "additional_info": {
            "duration": 0.32509589195251465,
            "num_run": 724,
            "train_loss": 1.1646286150025977,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00522519523854048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10825768411829834,
            "classifier:CustomMLPClassifier:max_iter": 213,
            "classifier:CustomMLPClassifier:num_units": 243,
            "classifier:CustomMLPClassifier:tol": 0.0006318921723568215,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005945898264375848,
            "feature_preprocessor:select_rates_classification:alpha": 0.28679814290168704,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10145831108093262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004297995444753114,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003561111425379446,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 400,
            "classifier:CustomMLPClassifier:tol": 0.0009007508318994052,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025779970048497897,
            "feature_preprocessor:select_rates_classification:alpha": 0.07446243952293535,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09735703468322754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0038558185633474217,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0030150962903562504,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.0005610702184965528,
            "feature_preprocessor:select_rates_classification:alpha": 0.14076812162692204,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12433791160583496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00041965276966032464,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003415911681433434,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.005342624474476589,
            "feature_preprocessor:select_rates_classification:alpha": 0.09176767140297866,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2919960021972656,
        "additional_info": {
            "duration": 0.27283477783203125,
            "num_run": 728,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01438488575352753,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.17295720969404257,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.002441434176877629,
            "feature_preprocessor:select_rates_classification:alpha": 0.04565288351949175,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12976384162902832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.005364464182037755,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04609307812914511,
            "classifier:CustomMLPClassifier:max_iter": 434,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.0009216532893813911,
            "feature_preprocessor:select_rates_classification:alpha": 0.2435010096391191,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12586283683776855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2672500372040742e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010753493535912162,
            "classifier:CustomMLPClassifier:max_iter": 277,
            "classifier:CustomMLPClassifier:num_units": 484,
            "classifier:CustomMLPClassifier:tol": 0.0009512858358576423,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009589745226421687,
            "feature_preprocessor:select_rates_classification:alpha": 0.21669722972460959,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2291912893164771,
        "time": 0.3471379280090332,
        "additional_info": {
            "duration": 0.3315589427947998,
            "num_run": 731,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.009169163159109765,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8229570907809579,
            "classifier:CustomMLPClassifier:max_iter": 281,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 1.0557505000097916e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.48131017399134957,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 87,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.23817483380613505,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.445439784357807,
        "time": 0.44924092292785645,
        "additional_info": {
            "duration": 0.4330897331237793,
            "num_run": 732,
            "train_loss": 1.4151358626141395,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07430749776609606,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000185243716986153,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 252,
            "classifier:CustomMLPClassifier:tol": 0.007929127037201153,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02333295180825796,
            "feature_preprocessor:select_rates_classification:alpha": 0.1500353751818506,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2380800001060246,
        "time": 0.3104419708251953,
        "additional_info": {
            "duration": 0.29778003692626953,
            "num_run": 733,
            "train_loss": 1.2164203472727917,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00013613663155200131,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7864800272949035,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 375,
            "classifier:CustomMLPClassifier:tol": 0.0013705458319376634,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47417128843508866,
            "feature_preprocessor:select_rates_classification:alpha": 0.23027211992141047,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12307906150817871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.659346232383164e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28470737484197656,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 0.0014125702756411162,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039527213182848527,
            "feature_preprocessor:select_rates_classification:alpha": 0.49374764177141334,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12393307685852051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.468277953971335e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010803167323974593,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.00044468458631034857,
            "feature_preprocessor:select_percentile_classification:percentile": 17.15068319897015,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.357552121394336,
        "time": 0.29050207138061523,
        "additional_info": {
            "duration": 0.27457308769226074,
            "num_run": 736,
            "train_loss": 1.3429391892131117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00010578580379178251,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005906666090270016,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 135,
            "classifier:CustomMLPClassifier:tol": 0.0024817611568328886,
            "feature_preprocessor:select_rates_classification:alpha": 0.038561746154274296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12894678115844727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.003638297222970504,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012147536283009474,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 80,
            "classifier:CustomMLPClassifier:tol": 0.0016232462000960977,
            "feature_preprocessor:select_rates_classification:alpha": 0.18894404650786242,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10160589218139648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006666390951825116,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02674255576246278,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 205,
            "classifier:CustomMLPClassifier:tol": 0.0027051163230504033,
            "feature_preprocessor:select_rates_classification:alpha": 0.3686969783345835,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10495805740356445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012537899864404953,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3514306008888552,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 9.457156174370193e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9431100670656734,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12009406268330576,
            "feature_preprocessor:select_rates_classification:alpha": 0.1809450711871014,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.27613019943237305,
        "additional_info": {
            "duration": 0.260983943939209,
            "num_run": 740,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0345518584952365e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003993137421512,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.00036404091932882855,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011144360183197706,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8218565903854942,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.018224086645366636,
            "feature_preprocessor:select_percentile_classification:percentile": 20.97006661776898,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2411169329846312,
        "time": 0.40735411643981934,
        "additional_info": {
            "duration": 0.39580798149108887,
            "num_run": 741,
            "train_loss": 1.2408156113378224,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.018874957657397447,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10002723085135574,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.00013760707259396595,
            "feature_preprocessor:select_rates_classification:alpha": 0.38302813448642387,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09570598602294922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011686976037342298,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28949261691426914,
            "classifier:CustomMLPClassifier:max_iter": 459,
            "classifier:CustomMLPClassifier:num_units": 471,
            "classifier:CustomMLPClassifier:tol": 0.009958536231641035,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03628988705389542,
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1014711856842041,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.030780870661488012,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00037989311852794475,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.004734264591870975,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 708,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.04738856152538002,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2874259948730469,
        "additional_info": {
            "duration": 0.2662322521209717,
            "num_run": 744,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.05418691533427958,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018660222615180384,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 418,
            "classifier:CustomMLPClassifier:tol": 7.057433296665718e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.37304921454629186,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12416601181030273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004222825268724689,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2908989271472853,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.0014055770250656252,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008207381367874645,
            "feature_preprocessor:select_rates_classification:alpha": 0.08292012028244003,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12795591354370117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.07489765976145332,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12648571942858994,
            "classifier:CustomMLPClassifier:max_iter": 239,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.0009809544769297106,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 17,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.38493489140009496,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.203638862309857,
        "time": 0.3157918453216553,
        "additional_info": {
            "duration": 0.29312896728515625,
            "num_run": 747,
            "train_loss": 1.1409882710915042,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0016759846004397495,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12187800439483151,
            "classifier:CustomMLPClassifier:max_iter": 193,
            "classifier:CustomMLPClassifier:num_units": 431,
            "classifier:CustomMLPClassifier:tol": 0.004462793026225421,
            "feature_preprocessor:select_rates_classification:alpha": 0.4021623851467037,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09668087959289551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008571509345701705,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.040930489841187315,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 187,
            "classifier:CustomMLPClassifier:tol": 2.6282558918325027e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.46597784788008273,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2554450035095215,
        "additional_info": {
            "duration": 0.24288296699523926,
            "num_run": 749,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006690724134116833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.041885179621741736,
            "classifier:CustomMLPClassifier:max_iter": 142,
            "classifier:CustomMLPClassifier:num_units": 176,
            "classifier:CustomMLPClassifier:tol": 0.009194227357305663,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.827824012731284,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12430837470814865,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.32644511088650063,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2011571688964424,
        "time": 0.2823820114135742,
        "additional_info": {
            "duration": 0.2698240280151367,
            "num_run": 750,
            "train_loss": 1.195472577150885,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011569966999445881,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011990201210110752,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 7.417690560077334e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 84.26668145221359,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2359475408459453,
        "time": 0.7790791988372803,
        "additional_info": {
            "duration": 0.761995792388916,
            "num_run": 751,
            "train_loss": 1.1656445073400041,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004757761847909234,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007100457349635391,
            "classifier:CustomMLPClassifier:max_iter": 131,
            "classifier:CustomMLPClassifier:num_units": 295,
            "classifier:CustomMLPClassifier:tol": 0.009632176666674763,
            "feature_preprocessor:select_rates_classification:alpha": 0.3090497383478107,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09579801559448242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005191775976426612,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 187,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.0025123012946705664,
            "feature_preprocessor:select_rates_classification:alpha": 0.037523734614145765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1019601821899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0324581005943816e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.31856038983511314,
            "classifier:CustomMLPClassifier:max_iter": 166,
            "classifier:CustomMLPClassifier:num_units": 377,
            "classifier:CustomMLPClassifier:tol": 9.851732250379321e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 85.11521573567799,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.5308312845892662,
        "time": 0.2937793731689453,
        "additional_info": {
            "duration": 0.27609896659851074,
            "num_run": 754,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00023886192509611025,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0075628740766246465,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.001582536330718476,
            "feature_preprocessor:select_rates_classification:alpha": 0.20067728160613885,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10484600067138672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.003433078442206e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014336936446775108,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 2.2413526535990746e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02473509272311721,
            "feature_preprocessor:select_rates_classification:alpha": 0.45292715807694395,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09955096244812012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00401061434241876,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002608576977934086,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 308,
            "classifier:CustomMLPClassifier:tol": 0.00045980764232264463,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012463596575576722,
            "feature_preprocessor:select_rates_classification:alpha": 0.3018024820865999,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2054204642760264,
        "time": 0.4774470329284668,
        "additional_info": {
            "duration": 0.4595611095428467,
            "num_run": 757,
            "train_loss": 1.1618192288277596,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.0065728498484594e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007891619833231932,
            "classifier:CustomMLPClassifier:max_iter": 226,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 8.604225825930857e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9353685231201118,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.225314242731274,
        "time": 0.5558316707611084,
        "additional_info": {
            "duration": 0.5400948524475098,
            "num_run": 758,
            "train_loss": 1.1599838906265798,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.1891089583737664e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.512925895677264,
            "classifier:CustomMLPClassifier:max_iter": 238,
            "classifier:CustomMLPClassifier:num_units": 155,
            "classifier:CustomMLPClassifier:tol": 2.3486227921622485e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 84.69335386698579,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.4369370937347412,
        "additional_info": {
            "duration": 0.4195280075073242,
            "num_run": 759,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.8618394639026972e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1150286056337721,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.00015091116627474643,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 473,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 86.07299045025708,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.5248181819915771,
        "additional_info": {
            "duration": 0.5106408596038818,
            "num_run": 760,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.7004534435698674e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000127953132144744,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.00022916459324467234,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09849788480725097,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3142876625061035,
        "additional_info": {
            "duration": 0.30234503746032715,
            "num_run": 761,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0037921335374009528,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00031670878965405364,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 260,
            "classifier:CustomMLPClassifier:tol": 0.0007748625463631056,
            "feature_preprocessor:select_rates_classification:alpha": 0.25351256266448946,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12302112579345703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.065463061409478e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.40960958945379533,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 447,
            "classifier:CustomMLPClassifier:tol": 1.6261089519135356e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.832950003388365,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2388331986534868,
        "time": 0.41082096099853516,
        "additional_info": {
            "duration": 0.3977673053741455,
            "num_run": 763,
            "train_loss": 1.2189844810688706,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.824343205832356e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027813268844120786,
            "classifier:CustomMLPClassifier:max_iter": 117,
            "classifier:CustomMLPClassifier:num_units": 394,
            "classifier:CustomMLPClassifier:tol": 4.823471334518002e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11564938295459067,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10170412063598633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0484392387709893e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3360526548786096,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 3.573538196630479e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03445129802299428,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8324029755803437,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.250322693009171,
        "time": 0.3172190189361572,
        "additional_info": {
            "duration": 0.3015420436859131,
            "num_run": 765,
            "train_loss": 1.177459152426235,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.021683562614293956,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004186149844577846,
            "classifier:CustomMLPClassifier:max_iter": 127,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 0.00014104416947479086,
            "feature_preprocessor:select_rates_classification:alpha": 0.16133276247192913,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09611177444458008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003163718765359236,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020370238995923412,
            "classifier:CustomMLPClassifier:max_iter": 130,
            "classifier:CustomMLPClassifier:num_units": 446,
            "classifier:CustomMLPClassifier:tol": 0.006034063292332786,
            "feature_preprocessor:select_rates_classification:alpha": 0.12004624361676423,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12412905693054199,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1301891327114547e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015183920940833082,
            "classifier:CustomMLPClassifier:max_iter": 367,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 0.002200983674166379,
            "feature_preprocessor:select_rates_classification:alpha": 0.4000892347505037,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.26059508323669434,
        "additional_info": {
            "duration": 0.24430513381958008,
            "num_run": 768,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011872088004536053,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002566676535835646,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 360,
            "classifier:CustomMLPClassifier:tol": 0.00031073723110099593,
            "feature_preprocessor:select_percentile_classification:percentile": 35.45357223328149,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.2709219455718994,
        "additional_info": {
            "duration": 0.25783872604370117,
            "num_run": 769,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.09839474573285072,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010378074995441267,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 198,
            "classifier:CustomMLPClassifier:tol": 1.191708081666645e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002046903084436676,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1788,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.3860415150766957,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.208487978781912,
        "time": 0.6906812191009521,
        "additional_info": {
            "duration": 0.6791479587554932,
            "num_run": 770,
            "train_loss": 1.032592130851282,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0017251061398248e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036041044982482225,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 276,
            "classifier:CustomMLPClassifier:tol": 3.09937878895081e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.40528538732982294,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12305569648742676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003929635423274937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002621760240175401,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 6.0147392748782415e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.24951645324833316,
            "feature_preprocessor:select_rates_classification:alpha": 0.42551416781156703,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09733295440673828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0015126323281453528,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020820868198860373,
            "classifier:CustomMLPClassifier:max_iter": 169,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.0034210224869036547,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5277551637810337,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2390247147972357,
        "time": 0.3998229503631592,
        "additional_info": {
            "duration": 0.37935614585876465,
            "num_run": 773,
            "train_loss": 1.2084193530913487,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.5704220932344926e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020903612010474,
            "classifier:CustomMLPClassifier:max_iter": 135,
            "classifier:CustomMLPClassifier:num_units": 320,
            "classifier:CustomMLPClassifier:tol": 0.001833633220324289,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8007476927078674,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07397487843018077,
            "feature_preprocessor:select_rates_classification:alpha": 0.4224455649571866,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2374619841704555,
        "time": 1.247591257095337,
        "additional_info": {
            "duration": 1.2363030910491943,
            "num_run": 774,
            "train_loss": 1.0037869149191858,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.765365427463825e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023369981460188814,
            "classifier:CustomMLPClassifier:max_iter": 356,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 6.662822549312278e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3731579087058271,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8075018118869106,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2140629386057888,
        "time": 0.4923219680786133,
        "additional_info": {
            "duration": 0.4791910648345947,
            "num_run": 775,
            "train_loss": 1.1727069102389833,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.125279749315014e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002361336670398946,
            "classifier:CustomMLPClassifier:max_iter": 229,
            "classifier:CustomMLPClassifier:num_units": 143,
            "classifier:CustomMLPClassifier:tol": 0.0007262564734484915,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14437539404526398,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49930345767486073,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2264955443616203,
        "time": 0.4618082046508789,
        "additional_info": {
            "duration": 0.441082239151001,
            "num_run": 776,
            "train_loss": 1.2072029596407952,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.056088326685264735,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011726014823595987,
            "classifier:CustomMLPClassifier:max_iter": 307,
            "classifier:CustomMLPClassifier:num_units": 97,
            "classifier:CustomMLPClassifier:tol": 0.0006426155255562998,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012935697414180128,
            "feature_preprocessor:select_rates_classification:alpha": 0.33099408763355576,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12797904014587402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09045470332599775,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00925599693850586,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 401,
            "classifier:CustomMLPClassifier:tol": 0.0034497941613396113,
            "feature_preprocessor:select_rates_classification:alpha": 0.4808569452663399,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09731221199035645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.04926961172614144,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.357481257164887,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 2.3885341595978123e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016720642272202433,
            "feature_preprocessor:select_rates_classification:alpha": 0.25131859403832396,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10133099555969238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0004378081828220052,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001951123870123289,
            "classifier:CustomMLPClassifier:max_iter": 299,
            "classifier:CustomMLPClassifier:num_units": 97,
            "classifier:CustomMLPClassifier:tol": 4.395470679400204e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2329543507833356,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.32864904403686523,
        "additional_info": {
            "duration": 0.3157670497894287,
            "num_run": 780,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0521981685303218e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005681630824262345,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 2.6054610715742105e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.394205512409,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.651824118916047,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2219715233541437,
        "time": 1.0174651145935059,
        "additional_info": {
            "duration": 1.0057251453399658,
            "num_run": 781,
            "train_loss": 1.1569862048148762,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008121938295598211,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9672950940769187,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 7.43102693119445e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013399999015142078,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 623,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 87.56665173247148,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.2870211601257324,
        "additional_info": {
            "duration": 0.2764739990234375,
            "num_run": 782,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003195351094818909,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006924821503789474,
            "classifier:CustomMLPClassifier:max_iter": 240,
            "classifier:CustomMLPClassifier:num_units": 77,
            "classifier:CustomMLPClassifier:tol": 0.008448609977235816,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12851170261664854,
            "feature_preprocessor:select_percentile_classification:percentile": 20.75480783519094,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.21418976783752441,
        "additional_info": {
            "duration": 0.20399785041809082,
            "num_run": 783,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08933104392575518,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004346707917124973,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 328,
            "classifier:CustomMLPClassifier:tol": 0.005440769737883738,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.028449443191039345,
            "feature_preprocessor:select_rates_classification:alpha": 0.3798895656227273,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12256908416748047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.003884975332628819,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4093432576755961,
            "classifier:CustomMLPClassifier:max_iter": 126,
            "classifier:CustomMLPClassifier:num_units": 63,
            "classifier:CustomMLPClassifier:tol": 0.0001620893366095616,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16530829340620862,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7183811493402799,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04925285193171196,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.682182896647865,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2608690858894633,
        "time": 0.2947051525115967,
        "additional_info": {
            "duration": 0.2765781879425049,
            "num_run": 785,
            "train_loss": 1.2786098300655158,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0016581346759362726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4633467405111142,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.0005177693826899097,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9646716894615169,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.41147613525390625,
        "additional_info": {
            "duration": 0.39875078201293945,
            "num_run": 786,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0011138654267410012,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00039098760374536704,
            "classifier:CustomMLPClassifier:max_iter": 287,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.0006185006263361581,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7935620670749003,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10054754283946049,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2501306305528861,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1941723766574248,
        "time": 0.2999868392944336,
        "additional_info": {
            "duration": 0.28595900535583496,
            "num_run": 787,
            "train_loss": 1.1841897073170953,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.9383963113748662e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010682514443948008,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.001237655233822606,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00030473280347942876,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8975016142195844,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2488082496846606,
        "time": 0.35866594314575195,
        "additional_info": {
            "duration": 0.3369929790496826,
            "num_run": 788,
            "train_loss": 1.1841926142189594,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.0188727611763585e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008255276313379612,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 303,
            "classifier:CustomMLPClassifier:tol": 0.005271042830392656,
            "feature_preprocessor:select_percentile_classification:percentile": 63.198911272341,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2277717974559315,
        "time": 0.3216252326965332,
        "additional_info": {
            "duration": 0.3043022155761719,
            "num_run": 789,
            "train_loss": 1.1808247168060777,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 789,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02580382929222729,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003415850131897867,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.004624007143045801,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006276279711303755,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1093,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.30232270409446116,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2318677153805242,
        "time": 0.3222799301147461,
        "additional_info": {
            "duration": 0.3004007339477539,
            "num_run": 790,
            "train_loss": 1.1601065168159594,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 790,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3306046022564043e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08670981308926604,
            "classifier:CustomMLPClassifier:max_iter": 196,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 0.00016659205482241377,
            "feature_preprocessor:select_rates_classification:alpha": 0.2875453028496475,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12859201431274414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 791,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3895134509092099e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020012890340461272,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 0.00021761939290501593,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08719220528559785,
            "feature_preprocessor:select_rates_classification:alpha": 0.4167804084201473,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2235777016357356,
        "time": 0.3564300537109375,
        "additional_info": {
            "duration": 0.34577298164367676,
            "num_run": 792,
            "train_loss": 1.1566903873667767,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 792,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.02462119480319788,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035189036234197337,
            "classifier:CustomMLPClassifier:max_iter": 484,
            "classifier:CustomMLPClassifier:num_units": 251,
            "classifier:CustomMLPClassifier:tol": 0.000808548252996002,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013581567223144267,
            "feature_preprocessor:select_percentile_classification:percentile": 53.880313413875484,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.430631160736084,
        "additional_info": {
            "duration": 0.41686296463012695,
            "num_run": 793,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 793,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003070896913223971,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05863437665378422,
            "classifier:CustomMLPClassifier:max_iter": 315,
            "classifier:CustomMLPClassifier:num_units": 255,
            "classifier:CustomMLPClassifier:tol": 5.730032405036936e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.036745387136038345,
            "feature_preprocessor:select_rates_classification:alpha": 0.401209126714443,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.7132508754730225,
        "additional_info": {
            "duration": 0.7029688358306885,
            "num_run": 794,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 794,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.8891632350584675e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02132446176554981,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 208,
            "classifier:CustomMLPClassifier:tol": 0.00025618800815307687,
            "feature_preprocessor:select_rates_classification:alpha": 0.41874825035893787,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12963199615478516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 795,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.8965761885328733e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06089999818376175,
            "classifier:CustomMLPClassifier:max_iter": 255,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 9.715051014051836e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08397406166826638,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 925,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 67.1529133518797,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2385435046141346,
        "time": 0.579272985458374,
        "additional_info": {
            "duration": 0.5662219524383545,
            "num_run": 796,
            "train_loss": 1.0435640748588264,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 796,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002442192922132886,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4800350393037816,
            "classifier:CustomMLPClassifier:max_iter": 143,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 2.0962951521334574e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.20897444017382322,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10164403915405273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 797,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011400842622357014,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07073588423275337,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 3.95908154266468e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020501613808908605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1290,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3954076123433583,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2374507214339867,
        "time": 1.5114021301269531,
        "additional_info": {
            "duration": 1.4949090480804443,
            "num_run": 798,
            "train_loss": 1.1369915604847538,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 798,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004512009226549775,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005767895343917054,
            "classifier:CustomMLPClassifier:max_iter": 366,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 0.00023159164337223115,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00225332181072125,
            "feature_preprocessor:select_percentile_classification:percentile": 61.14143777077235,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.36611413955688477,
        "additional_info": {
            "duration": 0.35472989082336426,
            "num_run": 799,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 799,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.007237664968432205,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4584491398221939,
            "classifier:CustomMLPClassifier:max_iter": 369,
            "classifier:CustomMLPClassifier:num_units": 238,
            "classifier:CustomMLPClassifier:tol": 1.0947511755545608e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 71.942673666734,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2598326362411705,
        "time": 1.202422857284546,
        "additional_info": {
            "duration": 1.1843338012695312,
            "num_run": 800,
            "train_loss": 1.2370037195972488,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 800,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.166239708766625e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014697194701115768,
            "classifier:CustomMLPClassifier:max_iter": 412,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 0.0016584809533554251,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014262424945488052,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7785915632449382,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2208336793033645,
        "time": 0.4678380489349365,
        "additional_info": {
            "duration": 0.45185303688049316,
            "num_run": 801,
            "train_loss": 1.1713469684171762,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 801,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.9461472990215483e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9670163465780989,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.0004332824531993436,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6388709792979391,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2308441416845195,
        "time": 0.7265737056732178,
        "additional_info": {
            "duration": 0.7144339084625244,
            "num_run": 802,
            "train_loss": 1.1059924223577566,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 802,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.207009881771751e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09840574004816079,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 494,
            "classifier:CustomMLPClassifier:tol": 0.00034846004076358254,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38728267007138206,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.75,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2475032216922103,
            "feature_preprocessor:select_rates_classification:alpha": 0.2628053587206886,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2826651796041764,
        "time": 0.3847939968109131,
        "additional_info": {
            "duration": 0.37391090393066406,
            "num_run": 803,
            "train_loss": 1.2535909551837805,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 803,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.078286600249187e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014007819228731362,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 0.0012434033797201671,
            "feature_preprocessor:select_rates_classification:alpha": 0.34815308698362635,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15839099884033203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 804,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06619944056911381,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004529965963232939,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 0.001974028951596724,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04733172987926862,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 888,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6964934503604255,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2177613350747762,
        "time": 0.5342161655426025,
        "additional_info": {
            "duration": 0.5168838500976562,
            "num_run": 805,
            "train_loss": 1.1727847851627509,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 805,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0018823676063438655,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5785958681975556,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 71,
            "classifier:CustomMLPClassifier:tol": 0.0003445313187658451,
            "feature_preprocessor:select_rates_classification:alpha": 0.4788685286595546,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1244511604309082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 806,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002007295615172427,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10627966452567517,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 0.007297126139053251,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2127391083768681,
            "feature_preprocessor:select_rates_classification:alpha": 0.29627184671725104,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.16429901123046875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 807,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0005507968820617853,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03618522339312459,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.00031598987558546565,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015423473919755346,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45003742695325255,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2779045716575645,
        "time": 0.7983379364013672,
        "additional_info": {
            "duration": 0.7823851108551025,
            "num_run": 808,
            "train_loss": 1.0472969439379827,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 808,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.275229175982224e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0026355635143168687,
            "classifier:CustomMLPClassifier:max_iter": 206,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.00010028345827912842,
            "feature_preprocessor:select_percentile_classification:percentile": 42.57333277571822,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2309197841824295,
        "time": 0.4657871723175049,
        "additional_info": {
            "duration": 0.45525026321411133,
            "num_run": 809,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 809,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.029788079567186e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017368811813848358,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 437,
            "classifier:CustomMLPClassifier:tol": 0.00010384764035502615,
            "feature_preprocessor:select_percentile_classification:percentile": 61.07655505436139,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2285459181852678,
        "time": 0.7086069583892822,
        "additional_info": {
            "duration": 0.6946890354156494,
            "num_run": 810,
            "train_loss": 1.1585791975391608,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 810,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005191775976426612,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 164,
            "classifier:CustomMLPClassifier:num_units": 318,
            "classifier:CustomMLPClassifier:tol": 0.001671023922208165,
            "feature_preprocessor:select_rates_classification:alpha": 0.015877072920486197,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13331985473632812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 811,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.2473486452717915e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013319883823299675,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 0.0012005454687140887,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09732738363026909,
            "feature_preprocessor:select_rates_classification:alpha": 0.04043594321140078,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12565088272094727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 812,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.652953597880441e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013157314782914007,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.0086618244711493,
            "feature_preprocessor:select_rates_classification:alpha": 0.31590968693594185,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12871694564819336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 813,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001921519570270432,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0476434023795576,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 59,
            "classifier:CustomMLPClassifier:tol": 9.04262413249652e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12447449421162637,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12366509437561035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 814,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00417584492143633,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002567139363966325,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.007482589545616252,
            "feature_preprocessor:select_rates_classification:alpha": 0.3618086944966461,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10193109512329102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 815,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1913653413424736e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008584990959291219,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 0.003174817555031578,
            "feature_preprocessor:select_rates_classification:alpha": 0.17426237696967234,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12879610061645508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 816,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.034611102115773014,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009565164051130231,
            "classifier:CustomMLPClassifier:max_iter": 207,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 5.26000339082125e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.414230807951497,
            "feature_preprocessor:select_rates_classification:alpha": 0.4746949776301368,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09711599349975586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 817,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00011487352461751784,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001216545127747151,
            "classifier:CustomMLPClassifier:max_iter": 286,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 0.0008441233139599578,
            "feature_preprocessor:select_percentile_classification:percentile": 63.550516568823376,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2142882528837,
        "time": 0.2462019920349121,
        "additional_info": {
            "duration": 0.2337958812713623,
            "num_run": 818,
            "train_loss": 1.1825612579016158,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 818,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00015112958202485755,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12794170814370845,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 0.0007312071320338897,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21994849880444967,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.204408153316491,
        "time": 0.288161039352417,
        "additional_info": {
            "duration": 0.2715420722961426,
            "num_run": 819,
            "train_loss": 1.1788876745973922,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 819,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.5814596733972166e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08219636128809772,
            "classifier:CustomMLPClassifier:max_iter": 107,
            "classifier:CustomMLPClassifier:num_units": 81,
            "classifier:CustomMLPClassifier:tol": 0.00041424463966078216,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022064164824613923,
            "feature_preprocessor:select_percentile_classification:percentile": 25.996885013815174,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2445497840277788,
        "time": 0.2987968921661377,
        "additional_info": {
            "duration": 0.28279995918273926,
            "num_run": 820,
            "train_loss": 1.1602773750416402,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 820,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.01398646349955217,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00038741671809188984,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 0.000789696251141359,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.05268279542046461,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2127190892431532,
        "time": 0.3143768310546875,
        "additional_info": {
            "duration": 0.29598426818847656,
            "num_run": 821,
            "train_loss": 1.1726412367914973,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 821,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1266081877329879e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14630320859081475,
            "classifier:CustomMLPClassifier:max_iter": 190,
            "classifier:CustomMLPClassifier:num_units": 72,
            "classifier:CustomMLPClassifier:tol": 4.818434064243163e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013598358494867804,
            "feature_preprocessor:select_percentile_classification:percentile": 15.89306959079332,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.19420099258422852,
        "additional_info": {
            "duration": 0.17899394035339355,
            "num_run": 822,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 822,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00039157142555544826,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05407114724449775,
            "classifier:CustomMLPClassifier:max_iter": 325,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 9.497102760230828e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4788992797800799,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10143208503723145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 823,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.214688333432791e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00043097872335036506,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 132,
            "classifier:CustomMLPClassifier:tol": 2.356049361727289e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1913795139982421,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2075094659565386,
        "time": 0.6182982921600342,
        "additional_info": {
            "duration": 0.6022918224334717,
            "num_run": 824,
            "train_loss": 1.1248578427355103,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 824,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.514773845722609e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006215124695154667,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 368,
            "classifier:CustomMLPClassifier:tol": 0.00013030410849708215,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0044579929242927075,
            "feature_preprocessor:select_rates_classification:alpha": 0.056599940784506864,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3020501136779785,
        "additional_info": {
            "duration": 0.28947901725769043,
            "num_run": 825,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 825,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0010685961825545316,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6264146741522355,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 0.0006985637319467836,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06569509290497982,
            "feature_preprocessor:select_rates_classification:alpha": 0.1592016001881882,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09645795822143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 826,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0006310812447147704,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14409899663622658,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 437,
            "classifier:CustomMLPClassifier:tol": 0.003063031777639144,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029608329989993316,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1631,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 29.669166142770774,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2589329824205904,
        "time": 0.36580801010131836,
        "additional_info": {
            "duration": 0.34500789642333984,
            "num_run": 827,
            "train_loss": 1.1512029619120723,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 827,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007891413438302395,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8413360886709174,
            "classifier:CustomMLPClassifier:max_iter": 362,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 2.5956669158757156e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009102933858986817,
            "feature_preprocessor:select_rates_classification:alpha": 0.20848964996694536,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10194897651672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 828,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.193721135172013e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08285663611294394,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 373,
            "classifier:CustomMLPClassifier:tol": 9.329341023707841e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018441898794430093,
            "feature_preprocessor:select_rates_classification:alpha": 0.27860975535028587,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3119821548461914,
        "additional_info": {
            "duration": 0.2976970672607422,
            "num_run": 829,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 829,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003953497307357391,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003827271537401296,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 65,
            "classifier:CustomMLPClassifier:tol": 0.0042281437485208245,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003054284386135239,
            "feature_preprocessor:select_rates_classification:alpha": 0.12438808468196628,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09670591354370117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 830,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.043822998671935e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005901086102913744,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 293,
            "classifier:CustomMLPClassifier:tol": 0.0010390041709443909,
            "feature_preprocessor:select_rates_classification:alpha": 0.41028051838181573,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12289118766784668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 831,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016348330693318976,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4292442978650583,
            "classifier:CustomMLPClassifier:max_iter": 221,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.00037772701384354524,
            "feature_preprocessor:select_rates_classification:alpha": 0.3052660793110348,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12860989570617676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 832,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.85488004860195e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017814932423433783,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 131,
            "classifier:CustomMLPClassifier:tol": 3.3674512844661015e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00043505105849728036,
            "feature_preprocessor:select_rates_classification:alpha": 0.11784794910666156,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10208797454833984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 833,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.28785908708779e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006926937289436172,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.0010160203457667669,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002899444871095358,
            "feature_preprocessor:select_rates_classification:alpha": 0.16915250983152066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1234140396118164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 834,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.08981972733768434,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.030623980476623385,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 0.0002022672571200549,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003639151568485607,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8711833596153268,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.033221238879384225,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.08281774655080754,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2541482357852214,
        "time": 0.5862319469451904,
        "additional_info": {
            "duration": 0.5740268230438232,
            "num_run": 835,
            "train_loss": 1.1145472617111647,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 835,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.4973632082129912e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003969097857710787,
            "classifier:CustomMLPClassifier:max_iter": 113,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 0.0005448841167416315,
            "feature_preprocessor:select_rates_classification:alpha": 0.25039566436307004,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12423396110534668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 836,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006431799251592781,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12478599724928535,
            "classifier:CustomMLPClassifier:max_iter": 444,
            "classifier:CustomMLPClassifier:num_units": 113,
            "classifier:CustomMLPClassifier:tol": 0.0022425508686773664,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00042887094399439137,
            "feature_preprocessor:select_percentile_classification:percentile": 16.883632869282707,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2555596814161814,
        "time": 0.24336695671081543,
        "additional_info": {
            "duration": 0.23322391510009766,
            "num_run": 837,
            "train_loss": 1.2062201909615442,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 837,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012347797818815297,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001083255844714382,
            "classifier:CustomMLPClassifier:max_iter": 359,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 1.5223525201290254e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9205088837725645,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15324832269084335,
            "feature_preprocessor:select_rates_classification:alpha": 0.1994584900730918,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2244580464902608,
        "time": 0.31757211685180664,
        "additional_info": {
            "duration": 0.3067481517791748,
            "num_run": 838,
            "train_loss": 1.1742464309920635,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 838,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.010756994576552334,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002827612756596907,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 3.604396691783401e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.26711121332221366,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2229629121318053,
        "time": 0.9792180061340332,
        "additional_info": {
            "duration": 0.9561607837677002,
            "num_run": 839,
            "train_loss": 1.173992457907712,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 839,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000192854568410054,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0016195952489310506,
            "classifier:CustomMLPClassifier:max_iter": 376,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 7.205857555886379e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.44756234544253015,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12350273132324219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 840,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03514386894497132,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028419161805615767,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0005526733959210894,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012015165766854883,
            "feature_preprocessor:select_rates_classification:alpha": 0.4141694122886702,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12441897392272949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 841,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.08081866842131334,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4889866351793322,
            "classifier:CustomMLPClassifier:max_iter": 360,
            "classifier:CustomMLPClassifier:num_units": 214,
            "classifier:CustomMLPClassifier:tol": 0.0013525181558563988,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002797960290959304,
            "feature_preprocessor:select_rates_classification:alpha": 0.3631938478875124,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.3019881248474121,
        "additional_info": {
            "duration": 0.2848470211029053,
            "num_run": 842,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 842,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06033362560135757,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000239147857835973,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.00031445209057267827,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014153268095920268,
            "feature_preprocessor:select_rates_classification:alpha": 0.016169622036681822,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.16634392738342285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 843,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6856393524285517e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022710138410351604,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 410,
            "classifier:CustomMLPClassifier:tol": 0.0016083419808209526,
            "feature_preprocessor:select_rates_classification:alpha": 0.45273076470507656,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09652423858642578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 844,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00033189173877263726,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3958843966846596,
            "classifier:CustomMLPClassifier:max_iter": 174,
            "classifier:CustomMLPClassifier:num_units": 495,
            "classifier:CustomMLPClassifier:tol": 2.406283162481042e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16736535848173711,
            "feature_preprocessor:select_rates_classification:alpha": 0.3559563521264599,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09720087051391602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 845,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.000363153657832814,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006533327212998081,
            "classifier:CustomMLPClassifier:max_iter": 133,
            "classifier:CustomMLPClassifier:num_units": 334,
            "classifier:CustomMLPClassifier:tol": 0.002251201473772478,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017463004251053163,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7292953705470042,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2320109541467585,
        "time": 0.4519350528717041,
        "additional_info": {
            "duration": 0.4290030002593994,
            "num_run": 846,
            "train_loss": 1.195104698582746,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 846,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.742760531505854e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16939954748961217,
            "classifier:CustomMLPClassifier:max_iter": 228,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.006774019104395099,
            "feature_preprocessor:select_rates_classification:alpha": 0.08352533763584702,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12909984588623047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 847,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5464270341087158e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011517107160499624,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.00023144064213060554,
            "feature_preprocessor:select_rates_classification:alpha": 0.46046848277478974,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1588270664215088,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 848,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.860817209364954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001434022368957498,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.00022929614794586976,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.38344584312716357,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1951637654350864,
        "time": 1.9758949279785156,
        "additional_info": {
            "duration": 1.8402507305145264,
            "num_run": 849,
            "train_loss": 1.1759916927931942,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 849,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005232484477605321,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6018535604261973,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 6.931482000935676e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014212791993344546,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.967787186999556,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.00971249759352499,
            "feature_preprocessor:select_rates_classification:alpha": 0.3589077783677063,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.35799670219421387,
        "additional_info": {
            "duration": 0.34454989433288574,
            "num_run": 850,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 850,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00012111827224485338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6322063406069078,
            "classifier:CustomMLPClassifier:max_iter": 342,
            "classifier:CustomMLPClassifier:num_units": 140,
            "classifier:CustomMLPClassifier:tol": 0.0002890922784575048,
            "feature_preprocessor:select_rates_classification:alpha": 0.06690099009011781,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2382264553791422,
        "time": 0.19165706634521484,
        "additional_info": {
            "duration": 0.16754722595214844,
            "num_run": 851,
            "train_loss": 1.2153382076190744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 851,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.06946063659847672,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.039097493731720945,
            "classifier:CustomMLPClassifier:max_iter": 374,
            "classifier:CustomMLPClassifier:num_units": 445,
            "classifier:CustomMLPClassifier:tol": 0.00015198371954807836,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4709530425083952,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2218089756218544,
        "time": 0.46324706077575684,
        "additional_info": {
            "duration": 0.4501349925994873,
            "num_run": 852,
            "train_loss": 1.1989543800475537,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 852,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007130769902341493,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0007544585222819958,
            "classifier:CustomMLPClassifier:max_iter": 382,
            "classifier:CustomMLPClassifier:num_units": 102,
            "classifier:CustomMLPClassifier:tol": 0.00020393337562879285,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7529866570757463,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04962097458626292,
            "feature_preprocessor:select_percentile_classification:percentile": 91.38472808088507,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.1950285728984378,
        "time": 0.7374057769775391,
        "additional_info": {
            "duration": 0.7247312068939209,
            "num_run": 853,
            "train_loss": 1.0524496144827038,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 853,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06501151907702846,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010458682541860792,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 142,
            "classifier:CustomMLPClassifier:tol": 0.002611661827967872,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07925019928849895,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9974969576340541,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08544952946808897,
            "feature_preprocessor:select_percentile_classification:percentile": 34.92273422122698,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.22330212593078613,
        "additional_info": {
            "duration": 0.20030689239501953,
            "num_run": 854,
            "train_loss": 1.2242028250610777,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 854,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.260908598529488e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005162292844586331,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 1.2712027845262438e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.31124880681510686,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1328740119934082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 855,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.019309293212729818,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014732739789338313,
            "classifier:CustomMLPClassifier:max_iter": 474,
            "classifier:CustomMLPClassifier:num_units": 269,
            "classifier:CustomMLPClassifier:tol": 0.0007108634227830349,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022220460264254453,
            "feature_preprocessor:select_percentile_classification:percentile": 78.39654849289906,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.2786238193511963,
        "additional_info": {
            "duration": 0.2642629146575928,
            "num_run": 856,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 856,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3349086585196685e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.054975447352536184,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 262,
            "classifier:CustomMLPClassifier:tol": 1.2835720977249341e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015183399106348818,
            "feature_preprocessor:select_rates_classification:alpha": 0.41369555037349137,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09627008438110352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 857,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0038386463230923903,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01963976110709232,
            "classifier:CustomMLPClassifier:max_iter": 336,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.0028187955034323937,
            "feature_preprocessor:select_rates_classification:alpha": 0.26157584003318696,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09667372703552246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 858,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07193912473516746,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01734955819815481,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.00027638011757406903,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8795409430005564,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22008998631588042,
            "feature_preprocessor:select_rates_classification:alpha": 0.22854494065961645,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2249811010371099,
        "time": 0.4111647605895996,
        "additional_info": {
            "duration": 0.3937079906463623,
            "num_run": 859,
            "train_loss": 1.213446490544826,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 859,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.010891930517840357,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06792416708392152,
            "classifier:CustomMLPClassifier:max_iter": 375,
            "classifier:CustomMLPClassifier:num_units": 342,
            "classifier:CustomMLPClassifier:tol": 0.0021799145322469933,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20375043795206535,
            "feature_preprocessor:select_rates_classification:alpha": 0.32029428938768906,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10149502754211426,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 860,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001138390389628816,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017443143934483456,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 298,
            "classifier:CustomMLPClassifier:tol": 0.0001706939754175903,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002023624489835061,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1707,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 12.347035591509682,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.211204645918643,
        "time": 0.2859811782836914,
        "additional_info": {
            "duration": 0.27150988578796387,
            "num_run": 861,
            "train_loss": 1.2303638149752627,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 861,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00658090986144935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0037905800206188976,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.0006237557187544506,
            "feature_preprocessor:select_rates_classification:alpha": 0.12068603686653041,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12819576263427734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 862,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0487522195829805e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009741417872333416,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 263,
            "classifier:CustomMLPClassifier:tol": 0.0004310469981249434,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005131447928026395,
            "feature_preprocessor:select_rates_classification:alpha": 0.0966818496820118,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09604382514953613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 863,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012805158620598468,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002616240648098678,
            "classifier:CustomMLPClassifier:max_iter": 305,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 2.5790231009282763e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1991049243655996,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12605786323547363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 864,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.7603686347498715e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0037168713866064028,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 388,
            "classifier:CustomMLPClassifier:tol": 0.0001877129254703735,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1761,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 36.891314049604325,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2497835460031508,
        "time": 0.6609082221984863,
        "additional_info": {
            "duration": 0.6486730575561523,
            "num_run": 865,
            "train_loss": 1.1130315700418227,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 865,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.590263840989138e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11602054795710987,
            "classifier:CustomMLPClassifier:max_iter": 373,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.004098954872640541,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03098330234389477,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5219864099825219,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229254055862099,
        "time": 0.400393009185791,
        "additional_info": {
            "duration": 0.38370823860168457,
            "num_run": 866,
            "train_loss": 1.069874311213019,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 866,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006502988284983938,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004825011168842216,
            "classifier:CustomMLPClassifier:max_iter": 148,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 3.0144327840893946e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.19964316950381306,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09545421600341797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 867,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.0188904766509463e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.035229046033087415,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 393,
            "classifier:CustomMLPClassifier:tol": 0.001227129386901969,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4331945816172134,
            "feature_preprocessor:select_percentile_classification:percentile": 31.70592632024087,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.233985685472496,
        "time": 0.2778768539428711,
        "additional_info": {
            "duration": 0.24517464637756348,
            "num_run": 868,
            "train_loss": 1.1905500506067774,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 868,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.9565646695303245e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003073376932235711,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 353,
            "classifier:CustomMLPClassifier:tol": 0.000915251518161161,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41668435286061983,
            "feature_preprocessor:select_rates_classification:alpha": 0.4394950752762522,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12498092651367188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 869,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.1932751910796075e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022587537841837135,
            "classifier:CustomMLPClassifier:max_iter": 480,
            "classifier:CustomMLPClassifier:num_units": 163,
            "classifier:CustomMLPClassifier:tol": 0.0014996324035372076,
            "feature_preprocessor:select_rates_classification:alpha": 0.0958538334085198,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10378217697143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 870,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.3353985833027823e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00041080658084289515,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 488,
            "classifier:CustomMLPClassifier:tol": 0.003434525867473478,
            "feature_preprocessor:select_rates_classification:alpha": 0.17505774263809373,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10259771347045898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 871,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2702126389363314e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008579396277492964,
            "classifier:CustomMLPClassifier:max_iter": 322,
            "classifier:CustomMLPClassifier:num_units": 62,
            "classifier:CustomMLPClassifier:tol": 0.004292261100042899,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28347464837196523,
            "feature_preprocessor:select_rates_classification:alpha": 0.41635980423558283,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09883999824523926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 872,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.6304367686666583e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5728442944293878,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 305,
            "classifier:CustomMLPClassifier:tol": 0.0032809363746764643,
            "feature_preprocessor:select_rates_classification:alpha": 0.2989610014035028,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1237800121307373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 873,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004201586523099393,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.030007673967287145,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.001609602879270869,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17773464245503723,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.2641110420227051,
        "additional_info": {
            "duration": 0.2514510154724121,
            "num_run": 874,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 874,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.001198122865315585,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.017179723721694653,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 343,
            "classifier:CustomMLPClassifier:tol": 1.277801795434831e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.45615104697817627,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10411477088928223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 875,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.007436688022881904,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.08778779189049082,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 0.00015641603100549755,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4721492380754467,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8241450774157049,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.012911888713893566,
            "feature_preprocessor:select_rates_classification:alpha": 0.10279425433432295,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2236211592153028,
        "time": 0.20755577087402344,
        "additional_info": {
            "duration": 0.1881239414215088,
            "num_run": 876,
            "train_loss": 1.226143348040452,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 876,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.780886997459844e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003197037748016959,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.00018146081627975417,
            "feature_preprocessor:select_rates_classification:alpha": 0.2814076007865542,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09725093841552734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 877,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001062165390780415,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03860258789898757,
            "classifier:CustomMLPClassifier:max_iter": 326,
            "classifier:CustomMLPClassifier:num_units": 222,
            "classifier:CustomMLPClassifier:tol": 0.00012530249184347292,
            "feature_preprocessor:select_rates_classification:alpha": 0.1024062089289734,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2378063985258438,
        "time": 0.32624006271362305,
        "additional_info": {
            "duration": 0.3102271556854248,
            "num_run": 878,
            "train_loss": 1.1020003402593455,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 878,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.013850735521492933,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01820631516925114,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 293,
            "classifier:CustomMLPClassifier:tol": 0.0008638346694102495,
            "feature_preprocessor:select_rates_classification:alpha": 0.2742231866647142,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12389206886291504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 879,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1902271969978862e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00660989569460776,
            "classifier:CustomMLPClassifier:max_iter": 427,
            "classifier:CustomMLPClassifier:num_units": 217,
            "classifier:CustomMLPClassifier:tol": 1.948123414117281e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1320414143126887,
            "feature_preprocessor:select_percentile_classification:percentile": 14.961408156759777,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2371996552514992,
        "time": 0.26888179779052734,
        "additional_info": {
            "duration": 0.25383496284484863,
            "num_run": 880,
            "train_loss": 1.1983569313476266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 880,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009321709355894988,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006069103808656797,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 421,
            "classifier:CustomMLPClassifier:tol": 0.00019255795131077898,
            "feature_preprocessor:select_rates_classification:alpha": 0.4866967742817513,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09625005722045898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 881,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.6755199043820706e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013630195660176665,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 7.454405235019678e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001794599265592485,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9893037078361713,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.4517199993133545,
        "additional_info": {
            "duration": 1.4395639896392822,
            "num_run": 882,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 882,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002920647363155254,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002177778665817368,
            "classifier:CustomMLPClassifier:max_iter": 144,
            "classifier:CustomMLPClassifier:num_units": 143,
            "classifier:CustomMLPClassifier:tol": 0.002531802666351951,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.41024193530190023,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.28851809351636915,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3540537357330322,
        "additional_info": {
            "duration": 0.32837414741516113,
            "num_run": 883,
            "train_loss": 1.2258824134147224,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 883,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.27657193898183e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00029668507404560616,
            "classifier:CustomMLPClassifier:max_iter": 496,
            "classifier:CustomMLPClassifier:num_units": 479,
            "classifier:CustomMLPClassifier:tol": 0.004447893758477302,
            "feature_preprocessor:select_rates_classification:alpha": 0.1618737296311069,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10133004188537598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 884,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.014321066275348753,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01571259515627764,
            "classifier:CustomMLPClassifier:max_iter": 344,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 2.5730889942741204e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022335670012636278,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8139956651562945,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2583712727151069,
            "feature_preprocessor:select_rates_classification:alpha": 0.4253962004285995,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2468174258997515,
        "time": 0.8534557819366455,
        "additional_info": {
            "duration": 0.8385329246520996,
            "num_run": 885,
            "train_loss": 1.0942504122603898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 885,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.008452399440172266,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28123474792904335,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 237,
            "classifier:CustomMLPClassifier:tol": 0.0013278626128251068,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8925046092988771,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.017952758162297897,
            "feature_preprocessor:select_percentile_classification:percentile": 61.27512959487926,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2291558779664957,
        "time": 0.27724266052246094,
        "additional_info": {
            "duration": 0.26357078552246094,
            "num_run": 886,
            "train_loss": 1.0975253263713585,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 886,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.153316825734488e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005165998900307249,
            "classifier:CustomMLPClassifier:max_iter": 347,
            "classifier:CustomMLPClassifier:num_units": 404,
            "classifier:CustomMLPClassifier:tol": 0.0005879304580158176,
            "feature_preprocessor:select_rates_classification:alpha": 0.22688076450779682,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2026925344028268,
        "time": 0.31313300132751465,
        "additional_info": {
            "duration": 0.2947120666503906,
            "num_run": 887,
            "train_loss": 1.151746938640795,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 887,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.430386287471217e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04264450269247103,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 104,
            "classifier:CustomMLPClassifier:tol": 0.0011193389447029935,
            "feature_preprocessor:select_rates_classification:alpha": 0.0358238803047455,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10091185569763184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 888,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.939570868086459e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015487973859387927,
            "classifier:CustomMLPClassifier:max_iter": 462,
            "classifier:CustomMLPClassifier:num_units": 197,
            "classifier:CustomMLPClassifier:tol": 1.3411160724744516e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00027090709608014636,
            "feature_preprocessor:select_rates_classification:alpha": 0.39121634583051546,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09628486633300781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 889,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001487592973073703,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1444111543434805,
            "classifier:CustomMLPClassifier:max_iter": 199,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.000844220829218984,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 244,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6504566434585923,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.251928871290763,
        "time": 0.3474159240722656,
        "additional_info": {
            "duration": 0.32938504219055176,
            "num_run": 890,
            "train_loss": 1.1674885662467762,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 890,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006880532090524211,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.053657932731114036,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 1.7064275162836053e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.09597590245751432,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09578704833984375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 891,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0644798383631767e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0006370379996585373,
            "classifier:CustomMLPClassifier:max_iter": 403,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.00020847509535131626,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0035131341026903296,
            "feature_preprocessor:select_rates_classification:alpha": 0.11059628705506559,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12865304946899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 892,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.6047909965325495e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013873914640819632,
            "classifier:CustomMLPClassifier:max_iter": 123,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 1.1119047178760869e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.13849951564668056,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09694409370422363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 893,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001947799337217314,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018715361000905823,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 499,
            "classifier:CustomMLPClassifier:tol": 0.00012349663667870966,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003112437678872129,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.28835957415195335,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2335881640168909,
        "time": 1.053339958190918,
        "additional_info": {
            "duration": 1.0392701625823975,
            "num_run": 894,
            "train_loss": 1.1598821866190743,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 894,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001062169763807835,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028871421752832836,
            "classifier:CustomMLPClassifier:max_iter": 472,
            "classifier:CustomMLPClassifier:num_units": 279,
            "classifier:CustomMLPClassifier:tol": 0.002354135055565533,
            "feature_preprocessor:select_rates_classification:alpha": 0.277297499470211,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12398791313171387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 895,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.740923823455702e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011382396663216695,
            "classifier:CustomMLPClassifier:max_iter": 301,
            "classifier:CustomMLPClassifier:num_units": 302,
            "classifier:CustomMLPClassifier:tol": 1.780330076976758e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.047522883414317464,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1231999397277832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 896,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01015831686754653,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003641956868735635,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 166,
            "classifier:CustomMLPClassifier:tol": 0.000272988540241904,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4223692109668885,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2501923301952247,
        "time": 0.48502683639526367,
        "additional_info": {
            "duration": 0.4712491035461426,
            "num_run": 897,
            "train_loss": 1.1650261364582029,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 897,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.018445649650126048,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02773451057588245,
            "classifier:CustomMLPClassifier:max_iter": 422,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 6.129805010305856e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040255439573060183,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9660653815550323,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3364098072052002,
        "additional_info": {
            "duration": 0.32393503189086914,
            "num_run": 898,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 898,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2837073261201058e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7272565558029587,
            "classifier:CustomMLPClassifier:max_iter": 178,
            "classifier:CustomMLPClassifier:num_units": 130,
            "classifier:CustomMLPClassifier:tol": 0.001096441766065716,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.693570584959233,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2946632492633574,
        "time": 0.3179209232330322,
        "additional_info": {
            "duration": 0.30326175689697266,
            "num_run": 899,
            "train_loss": 1.2147134490647198,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 899,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004391886529689678,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0046035178235836385,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 1.7807193055993332e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.324952012747868,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2220117545020723,
        "time": 0.5828111171722412,
        "additional_info": {
            "duration": 0.5675690174102783,
            "num_run": 900,
            "train_loss": 1.007014744731503,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 900,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0047029762959441114,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1779725957711401,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 210,
            "classifier:CustomMLPClassifier:tol": 0.001807666712206855,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016757969014750585,
            "feature_preprocessor:select_rates_classification:alpha": 0.25912086532516243,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12381386756896973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 901,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003883171896404902,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010567651853255955,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 8.411305909194871e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4448305205661544,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12338805198669434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 902,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.025650812386523218,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004989037697456037,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 337,
            "classifier:CustomMLPClassifier:tol": 0.0035496827004355418,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01580132929286656,
            "feature_preprocessor:select_rates_classification:alpha": 0.2920358075345796,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09643888473510742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 903,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002894946706528638,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 160,
            "classifier:CustomMLPClassifier:num_units": 319,
            "classifier:CustomMLPClassifier:tol": 0.0035464329946233697,
            "feature_preprocessor:select_rates_classification:alpha": 0.037523734614145765,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12882399559020996,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 904,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.0547913790105104e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02547906544013764,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 385,
            "classifier:CustomMLPClassifier:tol": 0.0002096065602673615,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012072979221531677,
            "feature_preprocessor:select_rates_classification:alpha": 0.2822258982513669,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12340188026428223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 905,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.657907935438592e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014185936752113517,
            "classifier:CustomMLPClassifier:max_iter": 157,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.00012081013450533375,
            "feature_preprocessor:select_rates_classification:alpha": 0.4421838629155374,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0956718921661377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 906,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 9.477226486299846e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00042842310729495974,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.00013830133068601312,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017578350264409101,
            "feature_preprocessor:select_percentile_classification:percentile": 23.88746777030958,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.28770017623901367,
        "additional_info": {
            "duration": 0.2703568935394287,
            "num_run": 907,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 907,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007789939429286609,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3995842567978879,
            "classifier:CustomMLPClassifier:max_iter": 290,
            "classifier:CustomMLPClassifier:num_units": 474,
            "classifier:CustomMLPClassifier:tol": 0.003942227742922514,
            "feature_preprocessor:select_rates_classification:alpha": 0.2602080545191088,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12297606468200684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 908,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00013613490851582127,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015193194341904816,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.00309819922304058,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3277532169832145,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.183769222543367,
        "time": 0.9604058265686035,
        "additional_info": {
            "duration": 0.9483170509338379,
            "num_run": 909,
            "train_loss": 1.1699695851841845,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 909,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0016306698689730478,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.673554424125056,
            "classifier:CustomMLPClassifier:max_iter": 251,
            "classifier:CustomMLPClassifier:num_units": 461,
            "classifier:CustomMLPClassifier:tol": 9.963729939997018e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032667706182420075,
            "feature_preprocessor:select_rates_classification:alpha": 0.1470651407831621,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09671616554260254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 910,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.931029841518453e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.042110205076468135,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.00529409510355234,
            "feature_preprocessor:select_percentile_classification:percentile": 37.286928318459594,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.3132822513580322,
        "additional_info": {
            "duration": 0.30016517639160156,
            "num_run": 911,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 911,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00615568913113469,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014518874930351381,
            "classifier:CustomMLPClassifier:max_iter": 497,
            "classifier:CustomMLPClassifier:num_units": 163,
            "classifier:CustomMLPClassifier:tol": 1.6680027059940503e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023576958406509394,
            "feature_preprocessor:select_rates_classification:alpha": 0.45463782271279496,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12373185157775879,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 912,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.1962861233585777e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03327126013503284,
            "classifier:CustomMLPClassifier:max_iter": 259,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.005115490237234443,
            "feature_preprocessor:select_percentile_classification:percentile": 81.96330460786294,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.37566423416137695,
        "additional_info": {
            "duration": 0.36133790016174316,
            "num_run": 913,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 913,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0017606616471880021,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01058608637559356,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 224,
            "classifier:CustomMLPClassifier:tol": 0.00037613485685059474,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7053040509136562,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19232204385159224,
            "feature_preprocessor:select_rates_classification:alpha": 0.40388210562331217,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2281483967296627,
        "time": 1.1002109050750732,
        "additional_info": {
            "duration": 1.0856618881225586,
            "num_run": 914,
            "train_loss": 1.192448729222404,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 914,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00704662286898066,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001868994559593373,
            "classifier:CustomMLPClassifier:max_iter": 235,
            "classifier:CustomMLPClassifier:num_units": 253,
            "classifier:CustomMLPClassifier:tol": 7.210415141826776e-05,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1362,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 39.93835796645118,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2142882528837,
        "time": 0.7948660850524902,
        "additional_info": {
            "duration": 0.7842350006103516,
            "num_run": 915,
            "train_loss": 1.2030911582548685,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 915,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.859874260202302e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9645168204298656,
            "classifier:CustomMLPClassifier:max_iter": 387,
            "classifier:CustomMLPClassifier:num_units": 339,
            "classifier:CustomMLPClassifier:tol": 5.835759613445377e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.39784452396738296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12314105033874512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 916,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.2622533124172698e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01109191712204306,
            "classifier:CustomMLPClassifier:max_iter": 146,
            "classifier:CustomMLPClassifier:num_units": 314,
            "classifier:CustomMLPClassifier:tol": 1.6360432693851044e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12147754533465936,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12279105186462402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 917,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001865178428795996,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02667738961693353,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 227,
            "classifier:CustomMLPClassifier:tol": 2.0977425091114696e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7597452526479924,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.027659273048675388,
            "feature_preprocessor:select_rates_classification:alpha": 0.18594862342704804,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2102325661070361,
        "time": 3.9508049488067627,
        "additional_info": {
            "duration": 3.937717914581299,
            "num_run": 918,
            "train_loss": 1.0358681926999003,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 918,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.06552530656732343,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.14213744440433673,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 120,
            "classifier:CustomMLPClassifier:tol": 2.3259477966115226e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.14740438489636112,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.222201667354757,
        "time": 0.3619070053100586,
        "additional_info": {
            "duration": 0.3489551544189453,
            "num_run": 919,
            "train_loss": 1.161278159000901,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 919,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002133475827041044,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002573585909399609,
            "classifier:CustomMLPClassifier:max_iter": 355,
            "classifier:CustomMLPClassifier:num_units": 223,
            "classifier:CustomMLPClassifier:tol": 2.1615901761857327e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3865050082502239,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12517094612121582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 920,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.42322876442421e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008985381758607936,
            "classifier:CustomMLPClassifier:max_iter": 170,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.00024555301637013,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27168415673354157,
            "feature_preprocessor:select_rates_classification:alpha": 0.1746790632123191,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1013040542602539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 921,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0612615380434807,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010647329639853442,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 416,
            "classifier:CustomMLPClassifier:tol": 1.0000342046728395e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.048622891335967554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12370920181274414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 922,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008844292768686134,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014358666599319837,
            "classifier:CustomMLPClassifier:max_iter": 214,
            "classifier:CustomMLPClassifier:num_units": 456,
            "classifier:CustomMLPClassifier:tol": 5.1284837304842985e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011598080607156036,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 372,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.041025067255182096,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.203646908539443,
        "time": 4.915017127990723,
        "additional_info": {
            "duration": 4.903223037719727,
            "num_run": 923,
            "train_loss": 1.0235752443324326,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 923,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00019112270900796904,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0024960546035483777,
            "classifier:CustomMLPClassifier:max_iter": 343,
            "classifier:CustomMLPClassifier:num_units": 202,
            "classifier:CustomMLPClassifier:tol": 0.001643493091631399,
            "feature_preprocessor:select_rates_classification:alpha": 0.2934684337746922,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12331175804138184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 924,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007708588344455937,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20853689048861,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 300,
            "classifier:CustomMLPClassifier:tol": 0.00039693884868616155,
            "feature_preprocessor:select_percentile_classification:percentile": 68.19255942788813,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2896113439863293,
        "time": 3.107057809829712,
        "additional_info": {
            "duration": 3.0956649780273438,
            "num_run": 925,
            "train_loss": 1.0216056523344166,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 925,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3087439560295172e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00024516327121795343,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 287,
            "classifier:CustomMLPClassifier:tol": 0.006685736494066932,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020528017930501405,
            "feature_preprocessor:select_rates_classification:alpha": 0.22408164008739256,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12939214706420898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 926,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003728261432870766,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012630097150118173,
            "classifier:CustomMLPClassifier:max_iter": 233,
            "classifier:CustomMLPClassifier:num_units": 498,
            "classifier:CustomMLPClassifier:tol": 0.00017029923415405596,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015738874026346463,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 210,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.04439684723684597,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2274273831005433,
        "time": 0.6865620613098145,
        "additional_info": {
            "duration": 0.6746199131011963,
            "num_run": 927,
            "train_loss": 1.1487074084653435,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 927,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03176316925854042,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005514953762022394,
            "classifier:CustomMLPClassifier:max_iter": 265,
            "classifier:CustomMLPClassifier:num_units": 304,
            "classifier:CustomMLPClassifier:tol": 4.892079857976689e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1774745575909066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1638331413269043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 928,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.274065243798876e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10769162097433153,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 173,
            "classifier:CustomMLPClassifier:tol": 0.0003389393766552493,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7048729517257922,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.036601062006096675,
            "feature_preprocessor:select_rates_classification:alpha": 0.2207049745460897,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2347099156084986,
        "time": 1.8542859554290771,
        "additional_info": {
            "duration": 1.8443999290466309,
            "num_run": 929,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 929,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.002514109111520148,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003362640400304292,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 6.0822045441510704e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1691948832476713,
            "feature_preprocessor:select_percentile_classification:percentile": 28.474886936874316,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.361328125,
        "additional_info": {
            "duration": 0.34775662422180176,
            "num_run": 930,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 930,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0695857608106718e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018359534761737937,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 433,
            "classifier:CustomMLPClassifier:tol": 0.008465837617012075,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024341744043683252,
            "feature_preprocessor:select_rates_classification:alpha": 0.3182735394216109,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1290440559387207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 931,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.1800093718274323e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5572239858387954,
            "classifier:CustomMLPClassifier:max_iter": 363,
            "classifier:CustomMLPClassifier:num_units": 177,
            "classifier:CustomMLPClassifier:tol": 0.003695707941561978,
            "feature_preprocessor:select_rates_classification:alpha": 0.20942513301371746,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12333893775939941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 932,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0026823790557502832,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10966972737270067,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.006543768000702652,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030883380551027383,
            "feature_preprocessor:select_percentile_classification:percentile": 40.79383024117672,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.29612183570861816,
        "additional_info": {
            "duration": 0.2845597267150879,
            "num_run": 933,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 933,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0010372842610905525,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013279430772558033,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 441,
            "classifier:CustomMLPClassifier:tol": 0.0004334789178622029,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011787609973168234,
            "feature_preprocessor:select_rates_classification:alpha": 0.44419578872018006,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12389183044433594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 934,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0014099786529815522,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002211556430621022,
            "classifier:CustomMLPClassifier:max_iter": 279,
            "classifier:CustomMLPClassifier:num_units": 265,
            "classifier:CustomMLPClassifier:tol": 0.002426120780227209,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3560643740144197,
            "feature_preprocessor:select_rates_classification:alpha": 0.4441685465531773,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12985587120056152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 935,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000890130882715022,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003096496193613153,
            "classifier:CustomMLPClassifier:max_iter": 424,
            "classifier:CustomMLPClassifier:num_units": 489,
            "classifier:CustomMLPClassifier:tol": 0.000999633617693818,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04177111851191721,
            "feature_preprocessor:select_rates_classification:alpha": 0.3059984918108883,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12856125831604004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 936,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.465935069213367e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018709021879749418,
            "classifier:CustomMLPClassifier:max_iter": 465,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 1.8211816906794318e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015344118184334314,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8218141798258589,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1008581937599991,
            "feature_preprocessor:select_rates_classification:alpha": 0.3401387272034931,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.1998535506817354,
        "time": 13.388889074325562,
        "additional_info": {
            "duration": 13.376776933670044,
            "num_run": 937,
            "train_loss": 1.086407500959521,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 937,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.1162907821439247e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5520823249169015,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 5.360664193432567e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008600621905518694,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9001428876929598,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20997009338714515,
            "feature_preprocessor:select_rates_classification:alpha": 0.2572141480473757,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4275367259979248,
        "additional_info": {
            "duration": 0.4172489643096924,
            "num_run": 938,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 938,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 6.388886011043324e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5932381020570118,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 95,
            "classifier:CustomMLPClassifier:tol": 1.0097303721191e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3352248591263041,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12381291389465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 939,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.030119932960388583,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028138056915432853,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 483,
            "classifier:CustomMLPClassifier:tol": 0.004410508110913273,
            "feature_preprocessor:select_rates_classification:alpha": 0.23540394555944041,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09581685066223145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 940,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010091703079431368,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002033800107216821,
            "classifier:CustomMLPClassifier:max_iter": 110,
            "classifier:CustomMLPClassifier:num_units": 314,
            "classifier:CustomMLPClassifier:tol": 0.003785192655852355,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002626169918358805,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1269,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9504835546331242,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3714268207550049,
        "additional_info": {
            "duration": 0.3584163188934326,
            "num_run": 941,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 941,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.042245902986082544,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010199481401289108,
            "classifier:CustomMLPClassifier:max_iter": 467,
            "classifier:CustomMLPClassifier:num_units": 254,
            "classifier:CustomMLPClassifier:tol": 0.009445730513412225,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.07128626893171719,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.28688597679138184,
        "additional_info": {
            "duration": 0.2715320587158203,
            "num_run": 942,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 942,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0004588379841946828,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04637893984141769,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 52,
            "classifier:CustomMLPClassifier:tol": 1.6200545053913293e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.49708652778103973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12379693984985352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 943,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.73439665521719e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00027784868800734904,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.00010002776670767303,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001046321813950546,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.80739443754979,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13429489316799825,
            "feature_preprocessor:select_percentile_classification:percentile": 52.403967130655936,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1918999050627495,
        "time": 8.61340594291687,
        "additional_info": {
            "duration": 8.600891351699829,
            "num_run": 944,
            "train_loss": 1.133596353217445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 944,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.008519861167758172,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00268402484152427,
            "classifier:CustomMLPClassifier:max_iter": 350,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 4.4944551048713016e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15287414989869844,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9403323507000771,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.276536583606172,
        "time": 4.528613090515137,
        "additional_info": {
            "duration": 4.51557993888855,
            "num_run": 945,
            "train_loss": 1.0729312827996553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 945,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0768148076593237e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02564047570364038,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 6.830172202875136e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05597194000413958,
            "feature_preprocessor:select_rates_classification:alpha": 0.2916912357534266,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09712100028991699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 946,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 7.392339847779033e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6001509373631773,
            "classifier:CustomMLPClassifier:max_iter": 163,
            "classifier:CustomMLPClassifier:num_units": 369,
            "classifier:CustomMLPClassifier:tol": 0.0001698575211770211,
            "feature_preprocessor:select_rates_classification:alpha": 0.30743838011575336,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.5308312845892662,
        "time": 0.34447622299194336,
        "additional_info": {
            "duration": 0.3303041458129883,
            "num_run": 947,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 947,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01649973084538733,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0046576439382844115,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 277,
            "classifier:CustomMLPClassifier:tol": 1.6311335262245883e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7197562554248922,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2509455287426872,
        "time": 0.7453711032867432,
        "additional_info": {
            "duration": 0.7224969863891602,
            "num_run": 948,
            "train_loss": 1.1852119873270548,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 948,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.005597919389123122,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009079842832435696,
            "classifier:CustomMLPClassifier:max_iter": 332,
            "classifier:CustomMLPClassifier:num_units": 347,
            "classifier:CustomMLPClassifier:tol": 3.8607514221897415e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1781293602623454,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12877702713012695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 949,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.000569691248033332,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2845897734822985,
            "classifier:CustomMLPClassifier:max_iter": 408,
            "classifier:CustomMLPClassifier:num_units": 267,
            "classifier:CustomMLPClassifier:tol": 0.0006903128895859206,
            "feature_preprocessor:select_rates_classification:alpha": 0.4795599705006611,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12478804588317871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 950,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03075456435335146,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011079288404329842,
            "classifier:CustomMLPClassifier:max_iter": 333,
            "classifier:CustomMLPClassifier:num_units": 478,
            "classifier:CustomMLPClassifier:tol": 0.004415461812952404,
            "feature_preprocessor:select_rates_classification:alpha": 0.42876183150986286,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09752988815307617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 951,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.911439185722625e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25194260111027966,
            "classifier:CustomMLPClassifier:max_iter": 443,
            "classifier:CustomMLPClassifier:num_units": 153,
            "classifier:CustomMLPClassifier:tol": 0.003519341703942753,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015669156516524732,
            "feature_preprocessor:select_rates_classification:alpha": 0.19351030157211185,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.33001708984375,
        "additional_info": {
            "duration": 0.31517696380615234,
            "num_run": 952,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 952,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.965140776873198e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010650873090182774,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.0023031479985715394,
            "feature_preprocessor:select_rates_classification:alpha": 0.3448771556491341,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1234898567199707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 953,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0019890520700855748,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4455774957145368,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 365,
            "classifier:CustomMLPClassifier:tol": 4.193209344183887e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.49714775361418867,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0971531867980957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 954,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.214022838744413e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00030154180288795106,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 411,
            "classifier:CustomMLPClassifier:tol": 0.0002551586961364596,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04028149133914888,
            "feature_preprocessor:select_rates_classification:alpha": 0.318652585151948,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1316981315612793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 955,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006310611726314951,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04187738960810194,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 493,
            "classifier:CustomMLPClassifier:tol": 0.004723426543360447,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0029886846532745375,
            "feature_preprocessor:select_rates_classification:alpha": 0.0380425168896833,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3508758544921875,
        "additional_info": {
            "duration": 0.3363349437713623,
            "num_run": 956,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 956,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00045010315714104126,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06060189243538353,
            "classifier:CustomMLPClassifier:max_iter": 364,
            "classifier:CustomMLPClassifier:num_units": 398,
            "classifier:CustomMLPClassifier:tol": 9.797441544975098e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022826099466337513,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.47788056961936176,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.241030027750252,
        "time": 3.4090590476989746,
        "additional_info": {
            "duration": 3.325685977935791,
            "num_run": 957,
            "train_loss": 1.0616216769802633,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 957,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021826664613281587,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024747921052011325,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 92,
            "classifier:CustomMLPClassifier:tol": 0.007942489921763727,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003681986702983822,
            "feature_preprocessor:select_rates_classification:alpha": 0.04679096795650994,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12399697303771973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 958,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004185666206776857,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028316295368515675,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 386,
            "classifier:CustomMLPClassifier:tol": 6.508019668049892e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3436565529735602,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12452507019042969,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 959,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0499838594980532,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04537443652773511,
            "classifier:CustomMLPClassifier:max_iter": 330,
            "classifier:CustomMLPClassifier:num_units": 359,
            "classifier:CustomMLPClassifier:tol": 0.00010584685639953002,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 77.1797671294654,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2171384993412602,
        "time": 1.2406659126281738,
        "additional_info": {
            "duration": 1.2270312309265137,
            "num_run": 960,
            "train_loss": 1.0304731766782842,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 960,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7267089679875016e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002039007002242314,
            "classifier:CustomMLPClassifier:max_iter": 249,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 5.8326610913594496e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.28539381065614255,
            "feature_preprocessor:select_rates_classification:alpha": 0.09417004331467871,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10201883316040039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 961,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 8.38010206068752e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022748397444013975,
            "classifier:CustomMLPClassifier:max_iter": 423,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 9.319108440189534e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010146358511217936,
            "feature_preprocessor:select_rates_classification:alpha": 0.1407623150465578,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.33109116554260254,
        "additional_info": {
            "duration": 0.3202860355377197,
            "num_run": 962,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 962,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0024060699723214753,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04947255835185138,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 432,
            "classifier:CustomMLPClassifier:tol": 0.005872541980951343,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015088968115945433,
            "feature_preprocessor:select_percentile_classification:percentile": 10.05953165898452,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2704079975329223,
        "time": 0.2932751178741455,
        "additional_info": {
            "duration": 0.2804901599884033,
            "num_run": 963,
            "train_loss": 1.2273922912803361,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 963,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.089733366153038e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06140984971269591,
            "classifier:CustomMLPClassifier:max_iter": 172,
            "classifier:CustomMLPClassifier:num_units": 275,
            "classifier:CustomMLPClassifier:tol": 1.192415845519068e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.476280235476955,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09781002998352051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 964,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.006914579771396648,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2507599037438217,
            "classifier:CustomMLPClassifier:max_iter": 430,
            "classifier:CustomMLPClassifier:num_units": 189,
            "classifier:CustomMLPClassifier:tol": 0.00022161871528328747,
            "feature_preprocessor:select_percentile_classification:percentile": 93.28376347822459,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.222586312858074,
        "time": 0.8613259792327881,
        "additional_info": {
            "duration": 0.8497312068939209,
            "num_run": 965,
            "train_loss": 1.1503869968189882,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 965,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00015561619615198015,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028267341358030103,
            "classifier:CustomMLPClassifier:max_iter": 321,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.0002823791064717359,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1650,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.41162324690649355,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.5011579990386963,
        "additional_info": {
            "duration": 0.48537778854370117,
            "num_run": 966,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 966,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.9146553764058334e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007839637788640762,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 161,
            "classifier:CustomMLPClassifier:tol": 0.00017489942567294067,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03366107639435264,
            "feature_preprocessor:select_rates_classification:alpha": 0.04730966757954319,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10168218612670898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 967,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.005205213405519831,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002353183013773159,
            "classifier:CustomMLPClassifier:max_iter": 202,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.0029619279573577842,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08097072384092194,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8363282346839803,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07804240627151798,
            "feature_preprocessor:select_percentile_classification:percentile": 51.55763238962774,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2336477140556295,
        "time": 0.4452359676361084,
        "additional_info": {
            "duration": 0.4325571060180664,
            "num_run": 968,
            "train_loss": 1.2204100963381637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 968,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0003433217783406944,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06808209023186135,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 0.0001285467799481704,
            "feature_preprocessor:select_rates_classification:alpha": 0.08938635211046521,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09686088562011719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 969,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0955600716284573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09490428746168272,
            "classifier:CustomMLPClassifier:max_iter": 197,
            "classifier:CustomMLPClassifier:num_units": 429,
            "classifier:CustomMLPClassifier:tol": 0.00019681424713393787,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037129378937336345,
            "feature_preprocessor:select_rates_classification:alpha": 0.2682738072529218,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2279391749109232,
        "time": 1.360461950302124,
        "additional_info": {
            "duration": 1.3494699001312256,
            "num_run": 970,
            "train_loss": 1.1413497619870896,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 970,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.08837833150832516,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34529422313470365,
            "classifier:CustomMLPClassifier:max_iter": 231,
            "classifier:CustomMLPClassifier:num_units": 76,
            "classifier:CustomMLPClassifier:tol": 0.0036118449843303225,
            "feature_preprocessor:select_rates_classification:alpha": 0.10158596027654665,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10236287117004395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 971,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.000813251484713811,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014118590002391915,
            "classifier:CustomMLPClassifier:max_iter": 295,
            "classifier:CustomMLPClassifier:num_units": 405,
            "classifier:CustomMLPClassifier:tol": 0.004203645134614835,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06982588297417197,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8195121435787156,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11604364173625245,
            "feature_preprocessor:select_percentile_classification:percentile": 48.94568886075094,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2274032444117862,
        "time": 0.44434189796447754,
        "additional_info": {
            "duration": 0.4332549571990967,
            "num_run": 972,
            "train_loss": 1.1680447444517807,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 972,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0309543555823393e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004505424595455209,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 2.267523901590745e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2931443805743383,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1232151985168457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 973,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.2244062634802557e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.16488523468909713,
            "classifier:CustomMLPClassifier:max_iter": 316,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 0.009140024735879382,
            "feature_preprocessor:select_rates_classification:alpha": 0.4722714205054287,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09628510475158691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 974,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0017385065195888946,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1449694540677077,
            "classifier:CustomMLPClassifier:max_iter": 306,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 0.000433473687541164,
            "feature_preprocessor:select_rates_classification:alpha": 0.36862403689210993,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12475919723510742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 975,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.389403111434329e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4515695998065279,
            "classifier:CustomMLPClassifier:max_iter": 312,
            "classifier:CustomMLPClassifier:num_units": 115,
            "classifier:CustomMLPClassifier:tol": 0.009083951653258288,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022206136121424356,
            "feature_preprocessor:select_percentile_classification:percentile": 58.43676350411258,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.17800498008728027,
        "additional_info": {
            "duration": 0.16745305061340332,
            "num_run": 976,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 976,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.024240632908611462,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003143929284349373,
            "classifier:CustomMLPClassifier:max_iter": 352,
            "classifier:CustomMLPClassifier:num_units": 206,
            "classifier:CustomMLPClassifier:tol": 0.0003174307858828359,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3128303884994595,
            "feature_preprocessor:select_percentile_classification:percentile": 2.1846300473874303,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.7521648406982422,
        "additional_info": {
            "duration": 0.733339786529541,
            "num_run": 977,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 977,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00011814432304451674,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7785919097596444,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.002480565502064557,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016724169114981722,
            "feature_preprocessor:select_rates_classification:alpha": 0.3279911028414255,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12426495552062988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 978,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.2525212896772434e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00871174816815388,
            "classifier:CustomMLPClassifier:max_iter": 409,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 0.0002683391195561657,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006745854110413744,
            "feature_preprocessor:select_rates_classification:alpha": 0.05909324361757276,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12431693077087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 979,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00011316750451216933,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.009845045403116327,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 402,
            "classifier:CustomMLPClassifier:tol": 1.604885501357436e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010571285706854464,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17774090464461845,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.3715288639068604,
        "additional_info": {
            "duration": 1.3586328029632568,
            "num_run": 980,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 980,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.6429171490218375e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4354444012938921,
            "classifier:CustomMLPClassifier:max_iter": 445,
            "classifier:CustomMLPClassifier:num_units": 194,
            "classifier:CustomMLPClassifier:tol": 1.4143012870312922e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.10720603941817974,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.44974803924560547,
        "additional_info": {
            "duration": 0.4300541877746582,
            "num_run": 981,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 981,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.254897781287e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.327920795050955,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 171,
            "classifier:CustomMLPClassifier:tol": 0.0057291536998247536,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012793587563193265,
            "feature_preprocessor:select_rates_classification:alpha": 0.21268009981559186,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12322187423706055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 982,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.03350641439778281,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010056571521510736,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 407,
            "classifier:CustomMLPClassifier:tol": 4.627227121892968e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2048436897841726,
            "feature_preprocessor:select_rates_classification:alpha": 0.3886829560672381,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.128371000289917,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 983,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002617060609745284,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23937474502640976,
            "classifier:CustomMLPClassifier:max_iter": 370,
            "classifier:CustomMLPClassifier:num_units": 107,
            "classifier:CustomMLPClassifier:tol": 0.00032577440771753094,
            "feature_preprocessor:select_rates_classification:alpha": 0.35469596873846176,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12336611747741699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 984,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000388896838833935,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002152436882492994,
            "classifier:CustomMLPClassifier:max_iter": 280,
            "classifier:CustomMLPClassifier:num_units": 293,
            "classifier:CustomMLPClassifier:tol": 0.00016389354318954944,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.035514741563976916,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1498,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 66.69277404509175,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2215949240804125,
        "time": 5.653343915939331,
        "additional_info": {
            "duration": 5.64021372795105,
            "num_run": 985,
            "train_loss": 1.0521781999871673,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 985,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0008260375675230909,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25768128680035157,
            "classifier:CustomMLPClassifier:max_iter": 125,
            "classifier:CustomMLPClassifier:num_units": 330,
            "classifier:CustomMLPClassifier:tol": 0.00959683017630861,
            "feature_preprocessor:select_rates_classification:alpha": 0.36871404424975024,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2115683692400858,
        "time": 1.0989937782287598,
        "additional_info": {
            "duration": 1.0292682647705078,
            "num_run": 986,
            "train_loss": 1.155539667363709,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 986,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001796383560294374,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01420519709541943,
            "classifier:CustomMLPClassifier:max_iter": 426,
            "classifier:CustomMLPClassifier:num_units": 111,
            "classifier:CustomMLPClassifier:tol": 0.00015251612909885124,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002070220853336732,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11235190260950823,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3132288455963135,
        "additional_info": {
            "duration": 0.2973029613494873,
            "num_run": 987,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 987,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0008914088067532856,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012311147750868978,
            "classifier:CustomMLPClassifier:max_iter": 425,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.00010974781197935415,
            "feature_preprocessor:select_rates_classification:alpha": 0.16378345159294871,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0961761474609375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 988,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.004106415786921915,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014020253622246449,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 428,
            "classifier:CustomMLPClassifier:tol": 0.00022008621392450602,
            "feature_preprocessor:select_rates_classification:alpha": 0.2547841177045889,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09605598449707031,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 989,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1251619095691875e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018420522053555117,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 419,
            "classifier:CustomMLPClassifier:tol": 0.002992996685777995,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7523334854065095,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15746156604848735,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06763263248611318,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.209471321329988,
        "time": 0.7247989177703857,
        "additional_info": {
            "duration": 0.7056941986083984,
            "num_run": 990,
            "train_loss": 1.1853293735815311,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 990,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.00013880141929126488,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 182,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.00998062364288188,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008995144625615537,
            "feature_preprocessor:select_rates_classification:alpha": 0.050428303091468625,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1291499137878418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 991,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.32490761535274e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001915327181231707,
            "classifier:CustomMLPClassifier:max_iter": 392,
            "classifier:CustomMLPClassifier:num_units": 323,
            "classifier:CustomMLPClassifier:tol": 0.002145972526507541,
            "feature_preprocessor:select_rates_classification:alpha": 0.13353563145186392,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2113511011917606,
        "time": 1.0756118297576904,
        "additional_info": {
            "duration": 1.0591580867767334,
            "num_run": 992,
            "train_loss": 1.1795874011736502,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 992,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.670067020339731e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8905369811708695,
            "classifier:CustomMLPClassifier:max_iter": 345,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 6.771328023419827e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005341473320273032,
            "feature_preprocessor:select_rates_classification:alpha": 0.28089354621866025,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1322309970855713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 993,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.811644757064948e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005986538325816822,
            "classifier:CustomMLPClassifier:max_iter": 151,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0004517026566050504,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005635524069836125,
            "feature_preprocessor:select_rates_classification:alpha": 0.10667477339026557,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09708404541015625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 994,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0015084285515220355,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3331685242731469,
            "classifier:CustomMLPClassifier:max_iter": 308,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0009514218086829786,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005915867905074268,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9321274708923888,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2743105885894281,
            "feature_preprocessor:select_percentile_classification:percentile": 26.79271850847682,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.239456034387003,
        "time": 0.9097840785980225,
        "additional_info": {
            "duration": 0.8993310928344727,
            "num_run": 995,
            "train_loss": 1.238743741463476,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 995,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0022304375736891748,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8457669705750019,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 317,
            "classifier:CustomMLPClassifier:tol": 8.45195807007305e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 27.280843394285675,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.226094806399132,
        "time": 0.3910257816314697,
        "additional_info": {
            "duration": 0.3795132637023926,
            "num_run": 996,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 996,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012636918702063226,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.019389369388361315,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 462,
            "classifier:CustomMLPClassifier:tol": 0.00018152850855981885,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0405927562717575,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5393337013672166,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5900030136108398,
        "additional_info": {
            "duration": 0.5764598846435547,
            "num_run": 997,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 997,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.03764560274048751,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010637924407210054,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 293,
            "classifier:CustomMLPClassifier:tol": 0.0023975019559550562,
            "feature_preprocessor:select_rates_classification:alpha": 0.40869511545895504,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09673714637756348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 998,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.161845229166937e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.041803883925146154,
            "classifier:CustomMLPClassifier:max_iter": 329,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 0.00015672172589109077,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.836962413509714,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2133097400583266,
        "time": 6.607823133468628,
        "additional_info": {
            "duration": 6.594608306884766,
            "num_run": 999,
            "train_loss": 1.1040379387378865,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 999,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.1994385684441e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.46446148604854587,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 233,
            "classifier:CustomMLPClassifier:tol": 0.002847208627978867,
            "feature_preprocessor:select_percentile_classification:percentile": 5.590662055187139,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.4039018154144287,
        "additional_info": {
            "duration": 0.39376163482666016,
            "num_run": 1000,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1000,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07170787446159349,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19714524544224946,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.00023074498483315772,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021879331423493797,
            "feature_preprocessor:select_percentile_classification:percentile": 80.21146523237014,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2171545918004316,
        "time": 0.5334768295288086,
        "additional_info": {
            "duration": 0.5216269493103027,
            "num_run": 1001,
            "train_loss": 1.1606353851665365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1001,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002629234298003325,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34599811310267775,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 426,
            "classifier:CustomMLPClassifier:tol": 5.136130576094212e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032470693759243845,
            "feature_preprocessor:select_rates_classification:alpha": 0.013002161953101941,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12353205680847168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1002,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006621253366709731,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9034631632978557,
            "classifier:CustomMLPClassifier:max_iter": 324,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.0004794649970032277,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008239766723437719,
            "feature_preprocessor:select_rates_classification:alpha": 0.48812654291815005,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12940192222595215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1003,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00010869621365796833,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001107772291501579,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0009190674784361202,
            "feature_preprocessor:select_rates_classification:alpha": 0.32261111704624007,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12411713600158691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1004,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00039298478360167696,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014400788441553934,
            "classifier:CustomMLPClassifier:max_iter": 349,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.00047023029772054687,
            "feature_preprocessor:select_rates_classification:alpha": 0.23335237407368,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12376713752746582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1005,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008644660495773815,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0010940324034368284,
            "classifier:CustomMLPClassifier:max_iter": 420,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 2.0287823589741508e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7467056401531205,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2206196277619223,
        "time": 2.4994261264801025,
        "additional_info": {
            "duration": 2.4843971729278564,
            "num_run": 1006,
            "train_loss": 1.0912370442017154,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1006,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.003763723555969289,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.327795567316575,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 4.377547199210409e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.014538720474687265,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1234278678894043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1007,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.932926626458842e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.056800434817286465,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 1.0303652974691922e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 78.2441803096339,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2032783554952975,
        "time": 0.6427440643310547,
        "additional_info": {
            "duration": 0.6320531368255615,
            "num_run": 1008,
            "train_loss": 1.1497267815734389,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1008,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.000503544785493952,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003573047819469181,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.0009621005891830262,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26194074480582985,
            "feature_preprocessor:select_rates_classification:alpha": 0.023034326483634116,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12981605529785156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1009,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.5562596004812705e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06974050142963542,
            "classifier:CustomMLPClassifier:max_iter": 357,
            "classifier:CustomMLPClassifier:num_units": 301,
            "classifier:CustomMLPClassifier:tol": 0.0006430398113528138,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010496852488430146,
            "feature_preprocessor:select_rates_classification:alpha": 0.3443520772608166,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12442588806152344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1010,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0012826768798884546,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001753741364005843,
            "classifier:CustomMLPClassifier:max_iter": 156,
            "classifier:CustomMLPClassifier:num_units": 78,
            "classifier:CustomMLPClassifier:tol": 6.305901728032967e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3300155185865832,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2846673546129732,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 1.1920690536499023,
        "additional_info": {
            "duration": 1.1726620197296143,
            "num_run": 1011,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1011,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.6940068975195794e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003293455628463194,
            "classifier:CustomMLPClassifier:max_iter": 438,
            "classifier:CustomMLPClassifier:num_units": 329,
            "classifier:CustomMLPClassifier:tol": 0.0004414687640876631,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016239579081254753,
            "feature_preprocessor:select_rates_classification:alpha": 0.3931129598322012,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09869885444641113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1012,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.865792190992722e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1534363800083096,
            "classifier:CustomMLPClassifier:max_iter": 242,
            "classifier:CustomMLPClassifier:num_units": 101,
            "classifier:CustomMLPClassifier:tol": 0.008683427512282283,
            "feature_preprocessor:select_rates_classification:alpha": 0.4588527757261973,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12346410751342773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1013,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0009881273410695514,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0017681298400199449,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.000778225302102921,
            "feature_preprocessor:select_rates_classification:alpha": 0.42518582532896687,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.3219308853149414,
        "additional_info": {
            "duration": 0.3105349540710449,
            "num_run": 1014,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1014,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06271116601274317,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.48759440297359363,
            "classifier:CustomMLPClassifier:max_iter": 400,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 1.079836295282862e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011777486350842909,
            "feature_preprocessor:select_rates_classification:alpha": 0.49994523638574895,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1289808750152588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1015,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0002900966565707154,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19623584208774472,
            "classifier:CustomMLPClassifier:max_iter": 247,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 0.00010504552366762647,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45951194312841653,
            "feature_preprocessor:select_rates_classification:alpha": 0.24468085720323154,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10147976875305176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1016,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.1844446608070867e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.010088013286859092,
            "classifier:CustomMLPClassifier:max_iter": 274,
            "classifier:CustomMLPClassifier:num_units": 292,
            "classifier:CustomMLPClassifier:tol": 0.00014133192421704062,
            "feature_preprocessor:select_rates_classification:alpha": 0.042636083404977244,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09588408470153809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1017,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.5948650114419554e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00038330592040579164,
            "classifier:CustomMLPClassifier:max_iter": 384,
            "classifier:CustomMLPClassifier:num_units": 354,
            "classifier:CustomMLPClassifier:tol": 1.2634372071624354e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023206981155887976,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7307189062745865,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0681982316262159,
            "feature_preprocessor:select_percentile_classification:percentile": 31.318232099639985,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2546085237864484,
        "time": 8.837438344955444,
        "additional_info": {
            "duration": 8.82174015045166,
            "num_run": 1018,
            "train_loss": 1.2260933568399368,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1018,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005336956170044285,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1983332962891929,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 87,
            "classifier:CustomMLPClassifier:tol": 0.009191464107688618,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19141549706537955,
            "feature_preprocessor:select_rates_classification:alpha": 0.28203679013091165,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.24946904182434082,
        "additional_info": {
            "duration": 0.23803400993347168,
            "num_run": 1019,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1019,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.01112484672608886,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004594466868337692,
            "classifier:CustomMLPClassifier:max_iter": 319,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 5.815105106045341e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006688476894023191,
            "feature_preprocessor:select_rates_classification:alpha": 0.4047157392990815,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12846088409423828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1020,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.001363279078120928,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05452999765319555,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0026064783909288966,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025009005146720945,
            "feature_preprocessor:select_rates_classification:alpha": 0.166057575532776,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12671732902526855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1021,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.631034537525704e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014660281927668046,
            "classifier:CustomMLPClassifier:max_iter": 211,
            "classifier:CustomMLPClassifier:num_units": 271,
            "classifier:CustomMLPClassifier:tol": 6.42318796035113e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010196435647606952,
            "feature_preprocessor:select_rates_classification:alpha": 0.12544757273077958,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10147809982299805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1022,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.009519115685940285,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022497013395121268,
            "classifier:CustomMLPClassifier:max_iter": 296,
            "classifier:CustomMLPClassifier:num_units": 158,
            "classifier:CustomMLPClassifier:tol": 0.000519853043145251,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9070854678756131,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.459104061126709,
        "additional_info": {
            "duration": 0.4455108642578125,
            "num_run": 1023,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1023,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0001288788352827073,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3323908035741554,
            "classifier:CustomMLPClassifier:max_iter": 111,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0020517518227575466,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1320579746185402,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6626906723532333,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.5703530311584473,
        "additional_info": {
            "duration": 0.5582880973815918,
            "num_run": 1024,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1024,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.0058240197559953e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7295612702153184,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 371,
            "classifier:CustomMLPClassifier:tol": 0.004628454190054343,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001763753775225902,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9617538901728055,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.054103519207718574,
            "feature_preprocessor:select_rates_classification:alpha": 0.42388571611919684,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.24172616004943848,
        "additional_info": {
            "duration": 0.2313978672027588,
            "num_run": 1025,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1025,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0019637948215659286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005270755372065292,
            "classifier:CustomMLPClassifier:max_iter": 195,
            "classifier:CustomMLPClassifier:num_units": 352,
            "classifier:CustomMLPClassifier:tol": 4.013385832526756e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020084204463962925,
            "feature_preprocessor:select_rates_classification:alpha": 0.044839987589880684,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09721016883850098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1026,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.0309543555823393e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005618963703641648,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 209,
            "classifier:CustomMLPClassifier:tol": 2.267523901590745e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.2931443805743383,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12387299537658691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1027,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.07377942335310025,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007239255716658071,
            "classifier:CustomMLPClassifier:max_iter": 297,
            "classifier:CustomMLPClassifier:num_units": 79,
            "classifier:CustomMLPClassifier:tol": 0.003077936259224183,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1437619396363529,
            "feature_preprocessor:select_rates_classification:alpha": 0.20121775465350486,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10134482383728027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1028,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004240456744238349,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00923400044055956,
            "classifier:CustomMLPClassifier:max_iter": 450,
            "classifier:CustomMLPClassifier:num_units": 340,
            "classifier:CustomMLPClassifier:tol": 2.88347353809195e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4926962801159569,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10218310356140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1029,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.632411109191754e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12457871499601367,
            "classifier:CustomMLPClassifier:max_iter": 398,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.009155854039230391,
            "feature_preprocessor:select_rates_classification:alpha": 0.4141924957072249,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0967562198638916,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1030,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.01000072190367573,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.008249614389513311,
            "classifier:CustomMLPClassifier:max_iter": 356,
            "classifier:CustomMLPClassifier:num_units": 338,
            "classifier:CustomMLPClassifier:tol": 0.0041829733807272245,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009809294226617384,
            "feature_preprocessor:select_rates_classification:alpha": 0.1273169947310091,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.15945696830749512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1031,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.02220082367710143,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007667039419557063,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 6.612952419634347e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.30101758862472866,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1245870590209961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1032,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.056514478863363714,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014069263575048823,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 193,
            "classifier:CustomMLPClassifier:tol": 1.2146213091104968e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16642514951568965,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8252969643590174,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17200453969421786,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6404865535477113,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2099782834176653,
        "time": 1.9637908935546875,
        "additional_info": {
            "duration": 1.9506518840789795,
            "num_run": 1033,
            "train_loss": 1.1204641845419798,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1033,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0021769359227956577,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000928083920865299,
            "classifier:CustomMLPClassifier:max_iter": 386,
            "classifier:CustomMLPClassifier:num_units": 449,
            "classifier:CustomMLPClassifier:tol": 0.0003272754900998595,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01988565199154533,
            "feature_preprocessor:select_rates_classification:alpha": 0.04190904629101945,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2015418143997592,
        "time": 10.314657926559448,
        "additional_info": {
            "duration": 10.298598766326904,
            "num_run": 1034,
            "train_loss": 1.1070565467314641,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1034,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002340847896694734,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.34894787021552254,
            "classifier:CustomMLPClassifier:max_iter": 120,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.0019822709718096483,
            "feature_preprocessor:select_rates_classification:alpha": 0.38959164562359433,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.19523406028747559,
        "additional_info": {
            "duration": 0.1815319061279297,
            "num_run": 1035,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1035,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 2.2830144891644455e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.028777125573120572,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 475,
            "classifier:CustomMLPClassifier:tol": 0.0013016695571700621,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00102810826139704,
            "feature_preprocessor:select_rates_classification:alpha": 0.4610557736590053,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.6307899951934814,
        "additional_info": {
            "duration": 0.6191859245300293,
            "num_run": 1036,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1036,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0009385464574819839,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09797379132320104,
            "classifier:CustomMLPClassifier:max_iter": 122,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.002401985001681039,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020388073678050288,
            "feature_preprocessor:select_rates_classification:alpha": 0.49968074090115433,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.30084705352783203,
        "additional_info": {
            "duration": 0.2905540466308594,
            "num_run": 1037,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1037,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.08012492297326498,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00583898658344363,
            "classifier:CustomMLPClassifier:max_iter": 492,
            "classifier:CustomMLPClassifier:num_units": 145,
            "classifier:CustomMLPClassifier:tol": 0.0027637915673861518,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0835701926171025,
            "feature_preprocessor:select_rates_classification:alpha": 0.28020534235116085,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10228204727172852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1038,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.207864783459943e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027853501169486594,
            "classifier:CustomMLPClassifier:max_iter": 477,
            "classifier:CustomMLPClassifier:num_units": 236,
            "classifier:CustomMLPClassifier:tol": 0.00013339834842680172,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3372054650339099,
            "feature_preprocessor:select_rates_classification:alpha": 0.07285606413592528,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10230302810668945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1039,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.941270153282374e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009181228737430057,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.00012622487246205204,
            "feature_preprocessor:select_rates_classification:alpha": 0.4030855499499625,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1251051425933838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1040,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011058910189754678,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024344978611708826,
            "classifier:CustomMLPClassifier:max_iter": 112,
            "classifier:CustomMLPClassifier:num_units": 147,
            "classifier:CustomMLPClassifier:tol": 0.00044673464316886616,
            "feature_preprocessor:select_rates_classification:alpha": 0.4013207594180692,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09659409523010254,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1041,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.1862658998709246e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.15542231682449487,
            "classifier:CustomMLPClassifier:max_iter": 418,
            "classifier:CustomMLPClassifier:num_units": 355,
            "classifier:CustomMLPClassifier:tol": 0.0005828092302022324,
            "feature_preprocessor:select_rates_classification:alpha": 0.470205813929161,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12493705749511719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1042,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0600248201163026,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007945158700169038,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 379,
            "classifier:CustomMLPClassifier:tol": 0.0008473983053674632,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 185,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 17.904618478681602,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2517341386401308,
        "time": 1.2896640300750732,
        "additional_info": {
            "duration": 1.269052267074585,
            "num_run": 1043,
            "train_loss": 1.201877671706179,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1043,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0008553948706675919,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03555260431557608,
            "classifier:CustomMLPClassifier:max_iter": 167,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 0.001068581383971039,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06816279609812319,
            "feature_preprocessor:select_rates_classification:alpha": 0.33542170973046664,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2454816227667018,
        "time": 2.5885329246520996,
        "additional_info": {
            "duration": 2.57384991645813,
            "num_run": 1044,
            "train_loss": 1.0904960471305345,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1044,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 9.036177042796318e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0011005057797121801,
            "classifier:CustomMLPClassifier:max_iter": 183,
            "classifier:CustomMLPClassifier:num_units": 282,
            "classifier:CustomMLPClassifier:tol": 0.0006616506436326377,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29481872342953336,
            "feature_preprocessor:select_rates_classification:alpha": 0.022803550444657365,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09760475158691406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1045,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0012980971888056298,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00013071890843495038,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 1.4864421351432086e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.11058300452633733,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 4.688579082489014,
        "additional_info": {
            "duration": 4.672972917556763,
            "num_run": 1046,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1046,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07630278702862245,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8817044825279927,
            "classifier:CustomMLPClassifier:max_iter": 181,
            "classifier:CustomMLPClassifier:num_units": 150,
            "classifier:CustomMLPClassifier:tol": 0.00013397746842396205,
            "feature_preprocessor:select_rates_classification:alpha": 0.09259228822436658,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.5308312845892662,
        "time": 0.2516670227050781,
        "additional_info": {
            "duration": 0.24010610580444336,
            "num_run": 1047,
            "train_loss": 1.5309780041261898,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1047,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3270103519437395e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012286933437425625,
            "classifier:CustomMLPClassifier:max_iter": 208,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 0.002102814163105462,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012739523816835362,
            "feature_preprocessor:select_rates_classification:alpha": 0.15026102454494825,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12378120422363281,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1048,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.03005206938457253,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020185081640367104,
            "classifier:CustomMLPClassifier:max_iter": 498,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.006604529141322914,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000483133414135128,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.048909120537529494,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2113430549621749,
        "time": 1.576606273651123,
        "additional_info": {
            "duration": 1.5651922225952148,
            "num_run": 1049,
            "train_loss": 1.024767808699248,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1049,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0007481347030396283,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.011763183469406956,
            "classifier:CustomMLPClassifier:max_iter": 468,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 9.639751208587572e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16160769427473393,
            "feature_preprocessor:select_rates_classification:alpha": 0.04944966745348911,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4636993408203125,
        "additional_info": {
            "duration": 0.4522397518157959,
            "num_run": 1050,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1050,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09622245064751467,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.027530828669727676,
            "classifier:CustomMLPClassifier:max_iter": 365,
            "classifier:CustomMLPClassifier:num_units": 384,
            "classifier:CustomMLPClassifier:tol": 0.0008117103144149303,
            "feature_preprocessor:select_rates_classification:alpha": 0.4482543132336609,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10602593421936035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1051,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.04986546309682744,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0028878164768218425,
            "classifier:CustomMLPClassifier:max_iter": 289,
            "classifier:CustomMLPClassifier:num_units": 91,
            "classifier:CustomMLPClassifier:tol": 0.002103755547576935,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8240769718518547,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2620445682314813,
            "feature_preprocessor:select_percentile_classification:percentile": 37.54760627440999,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.217737196386019,
        "time": 0.33606576919555664,
        "additional_info": {
            "duration": 0.32346177101135254,
            "num_run": 1052,
            "train_loss": 1.190482044126252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1052,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.478675984429259e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7516006167934415,
            "classifier:CustomMLPClassifier:max_iter": 258,
            "classifier:CustomMLPClassifier:num_units": 110,
            "classifier:CustomMLPClassifier:tol": 0.0001223927438113977,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23242433576338328,
            "feature_preprocessor:select_rates_classification:alpha": 0.3192818528847228,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09681081771850586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1053,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.1936214513654825e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014602856725337603,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 9.066513567374952e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.42519612525145967,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12850189208984375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1054,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.5171725247812523e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010416242469109907,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 414,
            "classifier:CustomMLPClassifier:tol": 6.278527669759126e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012589689834053918,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8596154910618476,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07277920300908368,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6903545486127548,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2245369054950543,
        "time": 3.342351198196411,
        "additional_info": {
            "duration": 3.3292269706726074,
            "num_run": 1055,
            "train_loss": 1.1867393066038534,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1055,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.052914534434470646,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05926398190880382,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 486,
            "classifier:CustomMLPClassifier:tol": 0.004203370468780823,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00033398653163781383,
            "feature_preprocessor:select_rates_classification:alpha": 0.46279120192155254,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10259890556335449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1056,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.120102804139806e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00045496717277561827,
            "classifier:CustomMLPClassifier:max_iter": 483,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.00920189855930638,
            "feature_preprocessor:select_rates_classification:alpha": 0.13811711774183968,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09680938720703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1057,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.6230386547575174e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.38924149389163754,
            "classifier:CustomMLPClassifier:max_iter": 380,
            "classifier:CustomMLPClassifier:num_units": 370,
            "classifier:CustomMLPClassifier:tol": 0.00010834343228652347,
            "feature_preprocessor:select_rates_classification:alpha": 0.43328542717946783,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10273909568786621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1058,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.011903206417241435,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7254910855166954,
            "classifier:CustomMLPClassifier:max_iter": 396,
            "classifier:CustomMLPClassifier:num_units": 85,
            "classifier:CustomMLPClassifier:tol": 1.0748374900296884e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 64.17883875287872,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.31780576705932617,
        "additional_info": {
            "duration": 0.3040649890899658,
            "num_run": 1059,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1059,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0005222052171111213,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.33583162656788135,
            "classifier:CustomMLPClassifier:max_iter": 128,
            "classifier:CustomMLPClassifier:num_units": 383,
            "classifier:CustomMLPClassifier:tol": 0.001956077185471064,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8116547375785389,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.46860289573669434,
        "additional_info": {
            "duration": 0.4546990394592285,
            "num_run": 1060,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1060,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.9911761034360956e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016439489708952655,
            "classifier:CustomMLPClassifier:max_iter": 402,
            "classifier:CustomMLPClassifier:num_units": 54,
            "classifier:CustomMLPClassifier:tol": 0.00013295097001120063,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00935941794749152,
            "feature_preprocessor:select_rates_classification:alpha": 0.17394075262824513,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1291201114654541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1061,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.06849327711620484,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07601003401338834,
            "classifier:CustomMLPClassifier:max_iter": 401,
            "classifier:CustomMLPClassifier:num_units": 156,
            "classifier:CustomMLPClassifier:tol": 2.8162055167724185e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016342490835095737,
            "feature_preprocessor:select_percentile_classification:percentile": 66.4152432022567,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2001818725779523,
        "time": 0.38860487937927246,
        "additional_info": {
            "duration": 0.37598586082458496,
            "num_run": 1062,
            "train_loss": 1.1545685262919148,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1062,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.2681828747496013e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013329205047103289,
            "classifier:CustomMLPClassifier:max_iter": 441,
            "classifier:CustomMLPClassifier:num_units": 89,
            "classifier:CustomMLPClassifier:tol": 0.0078101725941547885,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025167949419147587,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1673,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.023290708368223927,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.31145191192626953,
        "additional_info": {
            "duration": 0.2967560291290283,
            "num_run": 1063,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1063,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0001323684399870528,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.03925697311478953,
            "classifier:CustomMLPClassifier:max_iter": 298,
            "classifier:CustomMLPClassifier:num_units": 434,
            "classifier:CustomMLPClassifier:tol": 2.548190328434372e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 36.45280358658946,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2875384347649885,
        "time": 7.196808099746704,
        "additional_info": {
            "duration": 7.177600145339966,
            "num_run": 1064,
            "train_loss": 1.0086943330851477,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1064,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.024574352475520915,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003085944620975163,
            "classifier:CustomMLPClassifier:max_iter": 263,
            "classifier:CustomMLPClassifier:num_units": 492,
            "classifier:CustomMLPClassifier:tol": 0.00010771545040732306,
            "feature_preprocessor:select_rates_classification:alpha": 0.3970475642370526,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1238563060760498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1065,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.250212436496714e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.045170043881366695,
            "classifier:CustomMLPClassifier:max_iter": 244,
            "classifier:CustomMLPClassifier:num_units": 74,
            "classifier:CustomMLPClassifier:tol": 0.0010226272983156006,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010179348979036582,
            "feature_preprocessor:select_rates_classification:alpha": 0.16835078758515729,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10329389572143555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1066,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.213385987112213e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00517210028407915,
            "classifier:CustomMLPClassifier:max_iter": 354,
            "classifier:CustomMLPClassifier:num_units": 164,
            "classifier:CustomMLPClassifier:tol": 2.4162674437434083e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001077834158616389,
            "feature_preprocessor:select_rates_classification:alpha": 0.11564159475160832,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09653401374816895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1067,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 8.523144525013796e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4287932209631063,
            "classifier:CustomMLPClassifier:max_iter": 232,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 5.8524594577401254e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.45892229720768174,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12880992889404297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1068,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5021334731339343e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6795460619029667,
            "classifier:CustomMLPClassifier:max_iter": 460,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 0.0026551197020914306,
            "feature_preprocessor:select_rates_classification:alpha": 0.14586780768112273,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1246650218963623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1069,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.755193370800864e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002063562810945999,
            "classifier:CustomMLPClassifier:max_iter": 457,
            "classifier:CustomMLPClassifier:num_units": 170,
            "classifier:CustomMLPClassifier:tol": 1.6430250635353916e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.42521240404591915,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1254441738128662,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1070,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.076358588519984e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0029518450902813655,
            "classifier:CustomMLPClassifier:max_iter": 426,
            "classifier:CustomMLPClassifier:num_units": 391,
            "classifier:CustomMLPClassifier:tol": 0.005325870281664839,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4224237049948807,
            "feature_preprocessor:select_rates_classification:alpha": 0.162431712021334,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10199189186096191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1071,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.030918826234068716,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00018617142652563003,
            "classifier:CustomMLPClassifier:max_iter": 456,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 0.0079355441903081,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12242472902581757,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 57,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.2958980949993461,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.4017319679260254,
        "additional_info": {
            "duration": 0.39117980003356934,
            "num_run": 1072,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1072,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.7080706453848564e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.10641066757017799,
            "classifier:CustomMLPClassifier:max_iter": 114,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.009557547140689104,
            "feature_preprocessor:select_percentile_classification:percentile": 72.66852981653223,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.566500186920166,
        "additional_info": {
            "duration": 0.5551168918609619,
            "num_run": 1073,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1073,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.000340235084394133,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.41548393857304444,
            "classifier:CustomMLPClassifier:max_iter": 448,
            "classifier:CustomMLPClassifier:num_units": 56,
            "classifier:CustomMLPClassifier:tol": 0.00010327869233911904,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0022302856241288413,
            "feature_preprocessor:select_percentile_classification:percentile": 84.94221678347267,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.23255014419555664,
        "additional_info": {
            "duration": 0.21868491172790527,
            "num_run": 1074,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1074,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010318976476509477,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0334086983045898,
            "classifier:CustomMLPClassifier:max_iter": 192,
            "classifier:CustomMLPClassifier:num_units": 60,
            "classifier:CustomMLPClassifier:tol": 0.00032595127102283324,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2715653962300919,
            "feature_preprocessor:select_rates_classification:alpha": 0.4084247668275845,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2312770645653508,
        "time": 1.6049227714538574,
        "additional_info": {
            "duration": 1.5929827690124512,
            "num_run": 1075,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1075,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0006732571837180636,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024245091938463668,
            "classifier:CustomMLPClassifier:max_iter": 207,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 0.006348590228490572,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06903556560704248,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 489,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 55.47412074135595,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.1936573683401617,
        "time": 0.5286710262298584,
        "additional_info": {
            "duration": 0.5127699375152588,
            "num_run": 1076,
            "train_loss": 1.179366551747454,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1076,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.001321076811531578,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.09197730229722693,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.0036368805529104135,
            "feature_preprocessor:select_rates_classification:alpha": 0.3421149689936342,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09874606132507324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1077,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0003933153257846841,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 201,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.006887225455476324,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008995144625615537,
            "feature_preprocessor:select_rates_classification:alpha": 0.050428303091468625,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09656715393066406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1078,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.9901245624773065e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.8047775797967055,
            "classifier:CustomMLPClassifier:max_iter": 189,
            "classifier:CustomMLPClassifier:num_units": 190,
            "classifier:CustomMLPClassifier:tol": 3.711544706329091e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3468406113623348,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12990808486938477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1079,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.047497048374687066,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2552162748156665,
            "classifier:CustomMLPClassifier:max_iter": 273,
            "classifier:CustomMLPClassifier:num_units": 186,
            "classifier:CustomMLPClassifier:tol": 6.681389409058142e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4789791034318522,
            "feature_preprocessor:select_rates_classification:alpha": 0.0792186220361781,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10551309585571289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1080,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.116803263240009e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00033341480472786646,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.00015622398133716717,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07307837190956801,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17023597237661547,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.6174032688140869,
        "additional_info": {
            "duration": 0.5973761081695557,
            "num_run": 1081,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1081,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 3.622490233274705e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07899196060073246,
            "classifier:CustomMLPClassifier:max_iter": 260,
            "classifier:CustomMLPClassifier:num_units": 473,
            "classifier:CustomMLPClassifier:tol": 3.811275775736519e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.12037545846058745,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12461996078491211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1082,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002012839551918993,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00019096782638303573,
            "classifier:CustomMLPClassifier:max_iter": 248,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 4.8841433762939536e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 31.51184831249564,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2462943713529029,
        "time": 2.9800078868865967,
        "additional_info": {
            "duration": 2.959925889968872,
            "num_run": 1083,
            "train_loss": 1.2113490324225271,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1083,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.011689129823046606,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023885027160988273,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 0.0003151451642003549,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.718996410397241,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.6981749534606934,
        "additional_info": {
            "duration": 0.6863460540771484,
            "num_run": 1084,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1084,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.006304357519780289,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00020740458118644186,
            "classifier:CustomMLPClassifier:max_iter": 491,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 0.0003735193822652607,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040257770966219055,
            "feature_preprocessor:select_rates_classification:alpha": 0.033076295990111325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10115289688110352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1085,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0035814039202429625,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.11257597481160346,
            "classifier:CustomMLPClassifier:max_iter": 268,
            "classifier:CustomMLPClassifier:num_units": 245,
            "classifier:CustomMLPClassifier:tol": 0.00011237897132042971,
            "feature_preprocessor:select_percentile_classification:percentile": 64.13373471809422,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.2999107837677002,
        "additional_info": {
            "duration": 0.28279709815979004,
            "num_run": 1086,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1086,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0013214324829825216,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.2474696293414978,
            "classifier:CustomMLPClassifier:max_iter": 293,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0006037524793163618,
            "feature_preprocessor:select_rates_classification:alpha": 0.34452956704339527,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09672975540161133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1087,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00019019930196134338,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002698719383783249,
            "classifier:CustomMLPClassifier:max_iter": 106,
            "classifier:CustomMLPClassifier:num_units": 399,
            "classifier:CustomMLPClassifier:tol": 0.00031271636993352304,
            "feature_preprocessor:select_rates_classification:alpha": 0.32128000260849454,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.47294116020202637,
        "additional_info": {
            "duration": 0.4585540294647217,
            "num_run": 1088,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1088,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011804616016547053,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.004168659411137066,
            "classifier:CustomMLPClassifier:max_iter": 309,
            "classifier:CustomMLPClassifier:num_units": 406,
            "classifier:CustomMLPClassifier:tol": 0.00659588931021241,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.35911829913957893,
            "feature_preprocessor:select_rates_classification:alpha": 0.06379108665942111,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1576251983642578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1089,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.6113567130109886e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20231618831286904,
            "classifier:CustomMLPClassifier:max_iter": 282,
            "classifier:CustomMLPClassifier:num_units": 482,
            "classifier:CustomMLPClassifier:tol": 0.0013614644520369514,
            "feature_preprocessor:select_rates_classification:alpha": 0.2663612084083067,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1283702850341797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1090,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.016099291019409795,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024449341378351686,
            "classifier:CustomMLPClassifier:max_iter": 381,
            "classifier:CustomMLPClassifier:num_units": 281,
            "classifier:CustomMLPClassifier:tol": 0.0020082329214081286,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010209197452944819,
            "feature_preprocessor:select_rates_classification:alpha": 0.15903368166394544,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1232759952545166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1091,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.0457381543833937e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.05258353178899012,
            "classifier:CustomMLPClassifier:max_iter": 129,
            "classifier:CustomMLPClassifier:num_units": 188,
            "classifier:CustomMLPClassifier:tol": 0.00012722599777851065,
            "feature_preprocessor:select_rates_classification:alpha": 0.21246275184966745,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12711787223815918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1092,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.040135625461173434,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.020558753174967612,
            "classifier:CustomMLPClassifier:max_iter": 255,
            "classifier:CustomMLPClassifier:num_units": 121,
            "classifier:CustomMLPClassifier:tol": 2.847065113494326e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2102766575769405,
            "feature_preprocessor:select_percentile_classification:percentile": 48.4254667616687,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2025171107182493,
        "time": 2.187459945678711,
        "additional_info": {
            "duration": 2.1769118309020996,
            "num_run": 1093,
            "train_loss": 1.1032550973029578,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1093,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.002207104323408721,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.04485982634649752,
            "classifier:CustomMLPClassifier:max_iter": 317,
            "classifier:CustomMLPClassifier:num_units": 417,
            "classifier:CustomMLPClassifier:tol": 0.0042957429669875,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023347783005129796,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 725,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 15.508070814059243,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.220218889799434,
        "time": 0.49315810203552246,
        "additional_info": {
            "duration": 0.4782741069793701,
            "num_run": 1094,
            "train_loss": 1.190738350243643,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1094,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0002618813179103293,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 205,
            "classifier:CustomMLPClassifier:num_units": 315,
            "classifier:CustomMLPClassifier:tol": 0.0025123012946705664,
            "feature_preprocessor:select_rates_classification:alpha": 0.04649927643707277,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12444376945495605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1095,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.056544431934298804,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024433787845940743,
            "classifier:CustomMLPClassifier:max_iter": 295,
            "classifier:CustomMLPClassifier:num_units": 98,
            "classifier:CustomMLPClassifier:tol": 0.00045218976087394195,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024659903892817678,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 765,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 76.79759493798122,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2051613518639532,
        "time": 0.8075850009918213,
        "additional_info": {
            "duration": 0.7965130805969238,
            "num_run": 1096,
            "train_loss": 1.03877637598038,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1096,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.489461881856775e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0004438611202460183,
            "classifier:CustomMLPClassifier:max_iter": 428,
            "classifier:CustomMLPClassifier:num_units": 229,
            "classifier:CustomMLPClassifier:tol": 0.00039805172063190063,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7228481718012025,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09424074090796236,
            "feature_preprocessor:select_rates_classification:alpha": 0.112290308559231,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2125517117881617,
        "time": 0.6937830448150635,
        "additional_info": {
            "duration": 0.6754109859466553,
            "num_run": 1097,
            "train_loss": 1.1821846586278846,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1097,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.038640920437729286,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.12081683048550809,
            "classifier:CustomMLPClassifier:max_iter": 147,
            "classifier:CustomMLPClassifier:num_units": 356,
            "classifier:CustomMLPClassifier:tol": 0.0020625991322726317,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020715730853359095,
            "feature_preprocessor:select_rates_classification:alpha": 0.03711230903491381,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12869477272033691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1098,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00027486124467061314,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.054578365597985505,
            "classifier:CustomMLPClassifier:max_iter": 207,
            "classifier:CustomMLPClassifier:num_units": 94,
            "classifier:CustomMLPClassifier:tol": 0.0017658250541753985,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019266412248229517,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6917669779254253,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.28035902976989746,
        "additional_info": {
            "duration": 0.26191210746765137,
            "num_run": 1099,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1099,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.7363313461484424e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0018201086532912188,
            "classifier:CustomMLPClassifier:max_iter": 158,
            "classifier:CustomMLPClassifier:num_units": 247,
            "classifier:CustomMLPClassifier:tol": 0.0029280053222161383,
            "feature_preprocessor:select_rates_classification:alpha": 0.2561411954963488,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12363862991333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1100,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0001820150689905774,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00016341435817555773,
            "classifier:CustomMLPClassifier:max_iter": 494,
            "classifier:CustomMLPClassifier:num_units": 73,
            "classifier:CustomMLPClassifier:tol": 2.8389974077681564e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9316759444178829,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10541203974339303,
            "feature_preprocessor:select_rates_classification:alpha": 0.3844909637129721,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.214280206654114,
        "time": 2.013241767883301,
        "additional_info": {
            "duration": 2.002601146697998,
            "num_run": 1101,
            "train_loss": 1.1680447444517807,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1101,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.010713322643346101,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.06618338807460929,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 423,
            "classifier:CustomMLPClassifier:tol": 2.2433690253777743e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009188019001524976,
            "feature_preprocessor:select_rates_classification:alpha": 0.12783126736244363,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12820696830749512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.013051439638164098,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0013628935098899486,
            "classifier:CustomMLPClassifier:max_iter": 223,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 0.00010080544094010278,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4025582644830729,
            "feature_preprocessor:select_percentile_classification:percentile": 18.75123164488995,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2071570053715648,
        "time": 1.176767110824585,
        "additional_info": {
            "duration": 1.1546452045440674,
            "num_run": 1103,
            "train_loss": 1.2035665546342411,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.1197176334513977e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006501149684288111,
            "classifier:CustomMLPClassifier:max_iter": 271,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.004171647051461595,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06855681028912501,
            "feature_preprocessor:select_rates_classification:alpha": 0.059164297221046325,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09591388702392578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.62153104529257e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.005122494923593353,
            "classifier:CustomMLPClassifier:max_iter": 335,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 0.007652239517054369,
            "feature_preprocessor:select_rates_classification:alpha": 0.15405655647804178,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.47761988639831543,
        "additional_info": {
            "duration": 0.46747779846191406,
            "num_run": 1105,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 3.2920523176697294e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014245237865943567,
            "classifier:CustomMLPClassifier:max_iter": 283,
            "classifier:CustomMLPClassifier:num_units": 204,
            "classifier:CustomMLPClassifier:tol": 0.0030220101399516725,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016964238644713565,
            "feature_preprocessor:select_rates_classification:alpha": 0.07089306522472326,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09649801254272461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003056724513322112,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010690435672566578,
            "classifier:CustomMLPClassifier:max_iter": 159,
            "classifier:CustomMLPClassifier:num_units": 497,
            "classifier:CustomMLPClassifier:tol": 3.911939983916591e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006891108313436996,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.745272706273113,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11346863519421028,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3449196908894582,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2539036026165005,
        "time": 3.1130149364471436,
        "additional_info": {
            "duration": 3.0889430046081543,
            "num_run": 1107,
            "train_loss": 1.1830180651321538,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.383434950623855e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00023026937821759704,
            "classifier:CustomMLPClassifier:max_iter": 132,
            "classifier:CustomMLPClassifier:num_units": 183,
            "classifier:CustomMLPClassifier:tol": 0.007068388926224197,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9394353519631367,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2952546297560553,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.026030492142951833,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226094806399132,
        "time": 0.3569002151489258,
        "additional_info": {
            "duration": 0.3431539535522461,
            "num_run": 1108,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0017330392963683296,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07095744061376315,
            "classifier:CustomMLPClassifier:max_iter": 475,
            "classifier:CustomMLPClassifier:num_units": 438,
            "classifier:CustomMLPClassifier:tol": 1.0652347888439467e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030260062009496956,
            "feature_preprocessor:select_percentile_classification:percentile": 83.84120625454335,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2223803075462176,
        "time": 2.7651350498199463,
        "additional_info": {
            "duration": 2.7533769607543945,
            "num_run": 1109,
            "train_loss": 1.0054008298253445,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0009627012215358545,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012822309960576959,
            "classifier:CustomMLPClassifier:max_iter": 224,
            "classifier:CustomMLPClassifier:num_units": 325,
            "classifier:CustomMLPClassifier:tol": 8.997146990332317e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.31912307154677383,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09614181518554688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.004500308601906247,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009748736451038419,
            "classifier:CustomMLPClassifier:max_iter": 184,
            "classifier:CustomMLPClassifier:num_units": 430,
            "classifier:CustomMLPClassifier:tol": 4.396730434877946e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1404487405432611,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12458300590515137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1111,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0015707426246463333,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5067051594032869,
            "classifier:CustomMLPClassifier:max_iter": 295,
            "classifier:CustomMLPClassifier:num_units": 290,
            "classifier:CustomMLPClassifier:tol": 0.0012610546304252124,
            "feature_preprocessor:select_rates_classification:alpha": 0.2608756294643181,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12436103820800781,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1112,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.012407993166098558,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.002240270026986445,
            "classifier:CustomMLPClassifier:max_iter": 485,
            "classifier:CustomMLPClassifier:num_units": 284,
            "classifier:CustomMLPClassifier:tol": 0.0001883479145974727,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005554980069014479,
            "feature_preprocessor:select_rates_classification:alpha": 0.33222566596744274,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12954187393188477,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0002735469762829538,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02959459104791293,
            "classifier:CustomMLPClassifier:max_iter": 176,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.00015442240272215676,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 235,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 30.607749349293986,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2543944722450064,
        "time": 2.813261032104492,
        "additional_info": {
            "duration": 2.790497064590454,
            "num_run": 1114,
            "train_loss": 1.0908552049930809,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1114,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 7.179319336146501e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002974584468286981,
            "classifier:CustomMLPClassifier:max_iter": 215,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 8.445858525025829e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.011498626049077318,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 1.199794054031372,
        "additional_info": {
            "duration": 1.1893928050994873,
            "num_run": 1115,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1115,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0060377336612845445,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.003483685201682574,
            "classifier:CustomMLPClassifier:max_iter": 230,
            "classifier:CustomMLPClassifier:num_units": 213,
            "classifier:CustomMLPClassifier:tol": 0.003253659505432005,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.35965357948685994,
            "feature_preprocessor:select_rates_classification:alpha": 0.12173467432793479,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09615898132324219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.5683928591210036e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021345480732550682,
            "classifier:CustomMLPClassifier:max_iter": 171,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.0003901396837361141,
            "feature_preprocessor:select_rates_classification:alpha": 0.06445589742776138,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.226094806399132,
        "time": 0.21481585502624512,
        "additional_info": {
            "duration": 0.20436930656433105,
            "num_run": 1117,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.011647724754396351,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013582623092366118,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 286,
            "classifier:CustomMLPClassifier:tol": 1.6801648284669616e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.19641044724876458,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12346982955932617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.013880522756461365,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07294997728698388,
            "classifier:CustomMLPClassifier:max_iter": 219,
            "classifier:CustomMLPClassifier:num_units": 167,
            "classifier:CustomMLPClassifier:tol": 1.7560056029524053e-05,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.591544334224014,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2472020714030685,
        "time": 1.9197359085083008,
        "additional_info": {
            "duration": 1.9075887203216553,
            "num_run": 1119,
            "train_loss": 1.053130751910127,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 5.1181352785131635e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001068201349839929,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 376,
            "classifier:CustomMLPClassifier:tol": 5.645489218734078e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3087444675556174,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1013038158416748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 2.677082341022157e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016433159218482745,
            "classifier:CustomMLPClassifier:max_iter": 490,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 0.0006114854281698125,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002899467541739686,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1492045249738787,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2392725644728397,
        "time": 3.1674909591674805,
        "additional_info": {
            "duration": 3.1550490856170654,
            "num_run": 1121,
            "train_loss": 1.0294869272283442,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1121,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.765554295063063e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.022495554178519787,
            "classifier:CustomMLPClassifier:max_iter": 323,
            "classifier:CustomMLPClassifier:num_units": 451,
            "classifier:CustomMLPClassifier:tol": 7.066533161558509e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9363295331824559,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21213943460566506,
            "feature_preprocessor:select_percentile_classification:percentile": 96.68827742009903,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2422789157241676,
        "time": 4.601975917816162,
        "additional_info": {
            "duration": 4.584918737411499,
            "num_run": 1122,
            "train_loss": 1.0086943330851477,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1122,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0008360373176636807,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0003420873986682737,
            "classifier:CustomMLPClassifier:max_iter": 104,
            "classifier:CustomMLPClassifier:num_units": 464,
            "classifier:CustomMLPClassifier:tol": 0.0004665264255802638,
            "feature_preprocessor:select_rates_classification:alpha": 0.4364292525848848,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1040489673614502,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.3700579338496224e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001184485505693441,
            "classifier:CustomMLPClassifier:max_iter": 304,
            "classifier:CustomMLPClassifier:num_units": 168,
            "classifier:CustomMLPClassifier:tol": 0.006517041333317507,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00036435770185979906,
            "feature_preprocessor:select_rates_classification:alpha": 0.34903394879529476,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10314583778381348,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.7977237708330459e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0012436035728008834,
            "classifier:CustomMLPClassifier:max_iter": 451,
            "classifier:CustomMLPClassifier:num_units": 248,
            "classifier:CustomMLPClassifier:tol": 0.0073923754023010844,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9332424709610572,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11833823154146729,
            "feature_preprocessor:select_percentile_classification:percentile": 40.70805519354154,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2068109877251123,
        "time": 0.31275224685668945,
        "additional_info": {
            "duration": 0.3008460998535156,
            "num_run": 1125,
            "train_loss": 1.217436239610198,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0030868610906215903,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006341470849237413,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 259,
            "classifier:CustomMLPClassifier:tol": 1.330654207886856e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.1662272010068916,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.22929911673273,
        "time": 0.7352790832519531,
        "additional_info": {
            "duration": 0.7206010818481445,
            "num_run": 1126,
            "train_loss": 1.1645716622607043,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.622477899017156e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0569156362293876,
            "classifier:CustomMLPClassifier:max_iter": 356,
            "classifier:CustomMLPClassifier:num_units": 219,
            "classifier:CustomMLPClassifier:tol": 0.00012949509527236645,
            "feature_preprocessor:select_rates_classification:alpha": 0.49102449915513857,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.226094806399132,
        "time": 0.40770697593688965,
        "additional_info": {
            "duration": 0.39349818229675293,
            "num_run": 1127,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1127,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.007126033324150953,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9647002730478565,
            "classifier:CustomMLPClassifier:max_iter": 138,
            "classifier:CustomMLPClassifier:num_units": 307,
            "classifier:CustomMLPClassifier:tol": 0.002297213851813815,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22198456275175957,
            "feature_preprocessor:select_rates_classification:alpha": 0.41021078837310443,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1242680549621582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.018398124080211e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0035093456820309695,
            "classifier:CustomMLPClassifier:max_iter": 227,
            "classifier:CustomMLPClassifier:num_units": 460,
            "classifier:CustomMLPClassifier:tol": 0.00785887375792297,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.476997763215981,
            "feature_preprocessor:select_rates_classification:alpha": 0.1495654522123803,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13568711280822754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 2.731029490035017e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0021637815089240995,
            "classifier:CustomMLPClassifier:max_iter": 217,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0001331259007647861,
            "feature_preprocessor:select_rates_classification:alpha": 0.39927792461838185,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09746098518371582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1130,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0011750472729482077,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.042711519143828404,
            "classifier:CustomMLPClassifier:max_iter": 359,
            "classifier:CustomMLPClassifier:num_units": 61,
            "classifier:CustomMLPClassifier:tol": 0.00022542244798386612,
            "feature_preprocessor:select_rates_classification:alpha": 0.061291336386361354,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1020200252532959,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 1.0452386122018279e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.006632503332399926,
            "classifier:CustomMLPClassifier:max_iter": 185,
            "classifier:CustomMLPClassifier:num_units": 463,
            "classifier:CustomMLPClassifier:tol": 0.00013299397066405486,
            "feature_preprocessor:select_percentile_classification:percentile": 75.12876041043472,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2112400473438691,
        "time": 5.2685699462890625,
        "additional_info": {
            "duration": 5.256063938140869,
            "num_run": 1132,
            "train_loss": 1.0152726188991619,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.3599826624556033e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6340921707556099,
            "classifier:CustomMLPClassifier:max_iter": 436,
            "classifier:CustomMLPClassifier:num_units": 490,
            "classifier:CustomMLPClassifier:tol": 0.005282913925489684,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.45455835269806427,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.6486599445343018,
        "additional_info": {
            "duration": 0.6364591121673584,
            "num_run": 1133,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.896989045327558e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014153291080761052,
            "classifier:CustomMLPClassifier:max_iter": 479,
            "classifier:CustomMLPClassifier:num_units": 291,
            "classifier:CustomMLPClassifier:tol": 0.002218760849592705,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1058156955199414,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9452495346473598,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2164349998847604,
            "feature_preprocessor:select_percentile_classification:percentile": 37.33506349120083,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2189587291642943,
        "time": 0.5461125373840332,
        "additional_info": {
            "duration": 0.5349431037902832,
            "num_run": 1134,
            "train_loss": 1.200780423674316,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.004511830886999198,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.28863871824986187,
            "classifier:CustomMLPClassifier:max_iter": 370,
            "classifier:CustomMLPClassifier:num_units": 372,
            "classifier:CustomMLPClassifier:tol": 3.5439534452522356e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003393463190299668,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.040705560767479665,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2760360644570161,
        "time": 0.5935149192810059,
        "additional_info": {
            "duration": 0.5776948928833008,
            "num_run": 1135,
            "train_loss": 1.2555187028180486,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1135,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.006107927915532829,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014404230621237958,
            "classifier:CustomMLPClassifier:max_iter": 314,
            "classifier:CustomMLPClassifier:num_units": 491,
            "classifier:CustomMLPClassifier:tol": 0.0007091833140090714,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9285315383651827,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2304836348699597,
        "time": 2.512042999267578,
        "additional_info": {
            "duration": 2.4861319065093994,
            "num_run": 1136,
            "train_loss": 1.1794165429479695,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1136,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 8.38005507857837e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.4907415047819791,
            "classifier:CustomMLPClassifier:max_iter": 212,
            "classifier:CustomMLPClassifier:num_units": 261,
            "classifier:CustomMLPClassifier:tol": 1.3903581764045694e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3110733574527347,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09887099266052246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 7.534527941595602e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0001474956952551628,
            "classifier:CustomMLPClassifier:max_iter": 101,
            "classifier:CustomMLPClassifier:num_units": 360,
            "classifier:CustomMLPClassifier:tol": 0.0031301949639869035,
            "feature_preprocessor:select_rates_classification:alpha": 0.2438267696724408,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1303389072418213,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 7.645296375696202e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01886828053285053,
            "classifier:CustomMLPClassifier:max_iter": 405,
            "classifier:CustomMLPClassifier:num_units": 70,
            "classifier:CustomMLPClassifier:tol": 0.006288171840672786,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06160400469850867,
            "feature_preprocessor:select_percentile_classification:percentile": 70.88717343974477,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2133129565652099,
        "time": 0.2864060401916504,
        "additional_info": {
            "duration": 0.2760648727416992,
            "num_run": 1139,
            "train_loss": 1.1641206688338945,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1139,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003302179103378204,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0020744674582218914,
            "classifier:CustomMLPClassifier:max_iter": 180,
            "classifier:CustomMLPClassifier:num_units": 485,
            "classifier:CustomMLPClassifier:tol": 2.7426608211333414e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.4446199472091152,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.09688019752502441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 5.0052949783646345e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00010464603775512063,
            "classifier:CustomMLPClassifier:max_iter": 272,
            "classifier:CustomMLPClassifier:num_units": 148,
            "classifier:CustomMLPClassifier:tol": 0.00363400316812362,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.036522025257560445,
            "feature_preprocessor:select_rates_classification:alpha": 0.36299005118444033,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12412214279174805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1141,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.306951600575345e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024685181882231268,
            "classifier:CustomMLPClassifier:max_iter": 361,
            "classifier:CustomMLPClassifier:num_units": 466,
            "classifier:CustomMLPClassifier:tol": 0.0010861573583184684,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016207623744461625,
            "feature_preprocessor:select_rates_classification:alpha": 0.1451431624177121,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12410879135131836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1142,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0021775488737720045,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0002365046270410564,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 453,
            "classifier:CustomMLPClassifier:tol": 0.00010212858164741287,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010948913736224455,
            "feature_preprocessor:select_rates_classification:alpha": 0.22146241436445022,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09692597389221191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0007680842179087737,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.001125624002699355,
            "classifier:CustomMLPClassifier:max_iter": 453,
            "classifier:CustomMLPClassifier:num_units": 221,
            "classifier:CustomMLPClassifier:tol": 0.0006257103530680585,
            "feature_preprocessor:select_rates_classification:alpha": 0.48167609871685063,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.226094806399132,
        "time": 0.3104226589202881,
        "additional_info": {
            "duration": 0.2986419200897217,
            "num_run": 1144,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0019725054959464244,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.015477534566479594,
            "classifier:CustomMLPClassifier:max_iter": 488,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 8.972242244535914e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9082108050558249,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.272293200261079,
            "feature_preprocessor:select_percentile_classification:percentile": 90.13844448933095,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2160328402088239,
        "time": 4.124927997589111,
        "additional_info": {
            "duration": 4.111979007720947,
            "num_run": 1145,
            "train_loss": 1.0101769010963344,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.537704376962758e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07469757463808084,
            "classifier:CustomMLPClassifier:max_iter": 388,
            "classifier:CustomMLPClassifier:num_units": 112,
            "classifier:CustomMLPClassifier:tol": 8.643739377147384e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010686354240851824,
            "feature_preprocessor:select_percentile_classification:percentile": 28.71716967093066,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2163772545642122,
        "time": 2.7408907413482666,
        "additional_info": {
            "duration": 2.730087995529175,
            "num_run": 1146,
            "train_loss": 1.1286145408984047,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1146,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 8.229356888856502e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.305251988391398,
            "classifier:CustomMLPClassifier:max_iter": 257,
            "classifier:CustomMLPClassifier:num_units": 55,
            "classifier:CustomMLPClassifier:tol": 0.00047251753456273256,
            "feature_preprocessor:select_rates_classification:alpha": 0.41465652075224074,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09647011756896973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1147,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.032322335244261736,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0009701553675096677,
            "classifier:CustomMLPClassifier:max_iter": 311,
            "classifier:CustomMLPClassifier:num_units": 436,
            "classifier:CustomMLPClassifier:tol": 0.0010862351245539267,
            "feature_preprocessor:select_rates_classification:alpha": 0.152585302919043,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09696483612060547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1148,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 1.7068088048871032e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.1319775485358883,
            "classifier:CustomMLPClassifier:max_iter": 371,
            "classifier:CustomMLPClassifier:num_units": 363,
            "classifier:CustomMLPClassifier:tol": 0.0012708874333659012,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020004718091358619,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.852969657367398,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11743312697685719,
            "feature_preprocessor:select_percentile_classification:percentile": 19.607040405588926,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.27425767899773,
        "time": 0.4489121437072754,
        "additional_info": {
            "duration": 0.43552613258361816,
            "num_run": 1149,
            "train_loss": 1.228088537085905,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.009398823558456908,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.3102500516703428,
            "classifier:CustomMLPClassifier:max_iter": 313,
            "classifier:CustomMLPClassifier:num_units": 239,
            "classifier:CustomMLPClassifier:tol": 0.0015695199045724353,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00037046098315026663,
            "feature_preprocessor:select_rates_classification:alpha": 0.23214688875154554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09721016883850098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1150,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.013790529977865493,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024825835189609808,
            "classifier:CustomMLPClassifier:max_iter": 372,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.001055767733489832,
            "feature_preprocessor:select_rates_classification:alpha": 0.11888833920970962,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10074305534362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.0005668148620567592,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0193449566541111,
            "classifier:CustomMLPClassifier:max_iter": 140,
            "classifier:CustomMLPClassifier:num_units": 108,
            "classifier:CustomMLPClassifier:tol": 3.318699590320609e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.464676790860804,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09728407859802246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0003069909961862251,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.20175339442194062,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 457,
            "classifier:CustomMLPClassifier:tol": 5.978945879504961e-05,
            "feature_preprocessor:select_percentile_classification:percentile": 23.702181755081366,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2941965183236086,
        "time": 1.3198540210723877,
        "additional_info": {
            "duration": 1.307663917541504,
            "num_run": 1153,
            "train_loss": 1.1903553632973585,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 1.7880932556643956e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13903477187657778,
            "classifier:CustomMLPClassifier:max_iter": 100,
            "classifier:CustomMLPClassifier:num_units": 218,
            "classifier:CustomMLPClassifier:tol": 2.8204910027679023e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.10847704118701262,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12438702583312988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1154,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 5.6654381192668464e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07354197223422106,
            "classifier:CustomMLPClassifier:max_iter": 410,
            "classifier:CustomMLPClassifier:num_units": 268,
            "classifier:CustomMLPClassifier:tol": 2.348008422435007e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.43056789119577515,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12316298484802246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1155,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00010779088046537687,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0034156546128414384,
            "classifier:CustomMLPClassifier:max_iter": 331,
            "classifier:CustomMLPClassifier:num_units": 480,
            "classifier:CustomMLPClassifier:tol": 0.0020623555322826013,
            "feature_preprocessor:select_percentile_classification:percentile": 10.905584371571175,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.30806708335876465,
        "additional_info": {
            "duration": 0.2947678565979004,
            "num_run": 1156,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 1.0393827634477858e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5319412751577254,
            "classifier:CustomMLPClassifier:max_iter": 449,
            "classifier:CustomMLPClassifier:num_units": 294,
            "classifier:CustomMLPClassifier:tol": 0.004847753512106394,
            "feature_preprocessor:select_rates_classification:alpha": 0.44052577244640956,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12387299537658691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1157,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.0011375511491379321,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07216897933440794,
            "classifier:CustomMLPClassifier:max_iter": 294,
            "classifier:CustomMLPClassifier:num_units": 162,
            "classifier:CustomMLPClassifier:tol": 0.0003008618148870796,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 923,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 26.765844229068534,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2563450648819867,
        "time": 0.5450308322906494,
        "additional_info": {
            "duration": 0.5273077487945557,
            "num_run": 1158,
            "train_loss": 1.1744829626652302,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1158,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0003624553616245261,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00015946056238357002,
            "classifier:CustomMLPClassifier:max_iter": 191,
            "classifier:CustomMLPClassifier:num_units": 321,
            "classifier:CustomMLPClassifier:tol": 0.00015977417856705538,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00066629323397737,
            "feature_preprocessor:select_rates_classification:alpha": 0.0829296128857596,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12998008728027344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 9.025632134125346e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00022120080473559504,
            "classifier:CustomMLPClassifier:max_iter": 260,
            "classifier:CustomMLPClassifier:num_units": 360,
            "classifier:CustomMLPClassifier:tol": 0.0008259761137692702,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02698347580004012,
            "feature_preprocessor:select_rates_classification:alpha": 0.08519104587752933,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09669280052185059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.00021748164168919074,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.6407292355560366,
            "classifier:CustomMLPClassifier:max_iter": 407,
            "classifier:CustomMLPClassifier:num_units": 442,
            "classifier:CustomMLPClassifier:tol": 0.0005465545038295449,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008884654147668264,
            "feature_preprocessor:select_percentile_classification:percentile": 24.815100249256734,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.226094806399132,
        "time": 0.3440217971801758,
        "additional_info": {
            "duration": 0.3323960304260254,
            "num_run": 1161,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.09099663385203945,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.016869670005621947,
            "classifier:CustomMLPClassifier:max_iter": 134,
            "classifier:CustomMLPClassifier:num_units": 311,
            "classifier:CustomMLPClassifier:tol": 0.0006369748324103636,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14913330831963914,
            "feature_preprocessor:select_rates_classification:alpha": 0.4499166682127317,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10236811637878418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0004087572147824126,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00014193365820054776,
            "classifier:CustomMLPClassifier:max_iter": 437,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 0.0044787755966162295,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003011921257450833,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1877,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5391136380838629,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2347855581064087,
        "time": 1.1809940338134766,
        "additional_info": {
            "duration": 1.1678006649017334,
            "num_run": 1163,
            "train_loss": 1.2154457254303082,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.5085987792388954e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.000933480963974454,
            "classifier:CustomMLPClassifier:max_iter": 439,
            "classifier:CustomMLPClassifier:num_units": 199,
            "classifier:CustomMLPClassifier:tol": 7.507012388169495e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.030323210523780487,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.12437701225280762,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.4781172299926046e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.007899671439126862,
            "classifier:CustomMLPClassifier:max_iter": 254,
            "classifier:CustomMLPClassifier:num_units": 344,
            "classifier:CustomMLPClassifier:tol": 0.0006528590006520699,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08713174403704667,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 731,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 7.75563301409783,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2380880463356103,
        "time": 0.5334310531616211,
        "additional_info": {
            "duration": 0.5229272842407227,
            "num_run": 1165,
            "train_loss": 1.2182969559688943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.005391982885143853,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.7602564789552263,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 336,
            "classifier:CustomMLPClassifier:tol": 0.0015773506454542703,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49603519011343583,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7370682137553735,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21278475911398131,
            "feature_preprocessor:select_percentile_classification:percentile": 77.1594727999118,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.222039119622468,
        "time": 0.3388850688934326,
        "additional_info": {
            "duration": 0.32548093795776367,
            "num_run": 1166,
            "train_loss": 1.2022060389436091,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.07660286481995167,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.014497742544681655,
            "classifier:CustomMLPClassifier:max_iter": 218,
            "classifier:CustomMLPClassifier:num_units": 427,
            "classifier:CustomMLPClassifier:tol": 0.000575461620386262,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001168079994170186,
            "feature_preprocessor:select_rates_classification:alpha": 0.308706573183483,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.10120892524719238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1167,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 3.4809816402259533e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0796471107315494,
            "classifier:CustomMLPClassifier:max_iter": 102,
            "classifier:CustomMLPClassifier:num_units": 274,
            "classifier:CustomMLPClassifier:tol": 0.004053361230375617,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007567397127540005,
            "feature_preprocessor:select_rates_classification:alpha": 0.38308129739958163,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1314840316772461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0023080920594625754,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.23181021209881078,
            "classifier:CustomMLPClassifier:max_iter": 318,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 0.00017875847581957813,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004754468225788971,
            "feature_preprocessor:select_percentile_classification:percentile": 63.10869898575942,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.270277624794221,
        "time": 0.41982603073120117,
        "additional_info": {
            "duration": 0.40886783599853516,
            "num_run": 1169,
            "train_loss": 1.0281095439953525,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 5.631881776429995e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.012120503649062328,
            "classifier:CustomMLPClassifier:max_iter": 320,
            "classifier:CustomMLPClassifier:num_units": 477,
            "classifier:CustomMLPClassifier:tol": 0.00024034964977453325,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09764529872291086,
            "feature_preprocessor:select_rates_classification:alpha": 0.11359481872617037,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.1292870044708252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.017636757805211265,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00040236032414321324,
            "classifier:CustomMLPClassifier:max_iter": 198,
            "classifier:CustomMLPClassifier:num_units": 106,
            "classifier:CustomMLPClassifier:tol": 0.0008608662481581449,
            "feature_preprocessor:select_percentile_classification:percentile": 76.3848061558571,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2208417255329502,
        "time": 0.37677502632141113,
        "additional_info": {
            "duration": 0.3570060729980469,
            "num_run": 1171,
            "train_loss": 1.1777282338887325,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.00013880141929126488,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9981206752561537,
            "classifier:CustomMLPClassifier:max_iter": 162,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.00998062364288188,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012768186611172485,
            "feature_preprocessor:select_rates_classification:alpha": 0.054748098302391274,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12981891632080078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.06648309572115157,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.36304218084059003,
            "classifier:CustomMLPClassifier:max_iter": 108,
            "classifier:CustomMLPClassifier:num_units": 349,
            "classifier:CustomMLPClassifier:tol": 1.8012970811515842e-05,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7203612206423851,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29402516954213076,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5271761637077977,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2301681889260312,
        "time": 0.7217679023742676,
        "additional_info": {
            "duration": 0.7092499732971191,
            "num_run": 1173,
            "train_loss": 1.1894952208074872,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1173,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.01382437303009542,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02197447544548148,
            "classifier:CustomMLPClassifier:max_iter": 487,
            "classifier:CustomMLPClassifier:num_units": 440,
            "classifier:CustomMLPClassifier:tol": 0.002359382212551419,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09235306585979,
            "feature_preprocessor:select_rates_classification:alpha": 0.2984362203331044,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1012427806854248,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1174,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 6.23621968879619e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.25212429845972584,
            "classifier:CustomMLPClassifier:max_iter": 417,
            "classifier:CustomMLPClassifier:num_units": 93,
            "classifier:CustomMLPClassifier:tol": 1.1633707673250576e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.3497874575378793,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12838196754455566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 4.2735803424688516e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0014086680066870087,
            "classifier:CustomMLPClassifier:max_iter": 302,
            "classifier:CustomMLPClassifier:num_units": 425,
            "classifier:CustomMLPClassifier:tol": 0.0004534027772343,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 636,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.09915009031494737,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.226408639127241,
        "time": 8.275542974472046,
        "additional_info": {
            "duration": 8.260833024978638,
            "num_run": 1176,
            "train_loss": 1.0786366507786915,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.0009650050022305871,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0036734230956343935,
            "classifier:CustomMLPClassifier:max_iter": 291,
            "classifier:CustomMLPClassifier:num_units": 291,
            "classifier:CustomMLPClassifier:tol": 1.913895654848359e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012378264409765188,
            "feature_preprocessor:select_rates_classification:alpha": 0.1421259487411648,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.12544798851013184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 0.03182135290953902,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.9777114552727155,
            "classifier:CustomMLPClassifier:max_iter": 340,
            "classifier:CustomMLPClassifier:num_units": 192,
            "classifier:CustomMLPClassifier:tol": 1.296002379796258e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000712749612190374,
            "feature_preprocessor:select_rates_classification:alpha": 0.3825258741815253,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.09694695472717285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 1178,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0014642658299055533,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011981563588661701,
            "classifier:CustomMLPClassifier:max_iter": 137,
            "classifier:CustomMLPClassifier:num_units": 322,
            "classifier:CustomMLPClassifier:tol": 0.0019900113531099227,
            "feature_preprocessor:select_rates_classification:alpha": 0.025890892752285573,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.226094806399132,
        "time": 0.31855201721191406,
        "additional_info": {
            "duration": 0.30692100524902344,
            "num_run": 1179,
            "train_loss": 1.2259480868622084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.714993486875298e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.024974464715090326,
            "classifier:CustomMLPClassifier:max_iter": 455,
            "classifier:CustomMLPClassifier:num_units": 452,
            "classifier:CustomMLPClassifier:tol": 0.0009200146633526513,
            "feature_preprocessor:select_rates_classification:alpha": 0.4889018325586026,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2102325661070361,
        "time": 1.3839449882507324,
        "additional_info": {
            "duration": 1.371433973312378,
            "num_run": 1180,
            "train_loss": 1.0038525883666718,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1180,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.012535500720986572,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0008027022079186755,
            "classifier:CustomMLPClassifier:max_iter": 236,
            "classifier:CustomMLPClassifier:num_units": 278,
            "classifier:CustomMLPClassifier:tol": 0.0006028294294715917,
            "feature_preprocessor:select_percentile_classification:percentile": 58.87753021573392,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.4713591611175085,
        "time": 0.2870299816131592,
        "additional_info": {
            "duration": 0.2746138572692871,
            "num_run": 1181,
            "train_loss": 1.4601302188083374,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1181,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0005394484762478719,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.5387110342939301,
            "classifier:CustomMLPClassifier:max_iter": 237,
            "classifier:CustomMLPClassifier:num_units": 51,
            "classifier:CustomMLPClassifier:tol": 0.006118792162957668,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013300816772625676,
            "feature_preprocessor:select_rates_classification:alpha": 0.15221047904048593,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.10277986526489258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "logistic",
            "classifier:CustomMLPClassifier:alpha": 6.203268767094336e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.07106072258511856,
            "classifier:CustomMLPClassifier:max_iter": 413,
            "classifier:CustomMLPClassifier:num_units": 241,
            "classifier:CustomMLPClassifier:tol": 0.006414755209151161,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1653195613194723,
            "feature_preprocessor:select_rates_classification:alpha": 0.09816369220939153,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.1944186131172099,
        "time": 0.33145999908447266,
        "additional_info": {
            "duration": 0.319472074508667,
            "num_run": 1183,
            "train_loss": 1.1882154869424868,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.09906872226921,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.13945995298757963,
            "classifier:CustomMLPClassifier:max_iter": 375,
            "classifier:CustomMLPClassifier:num_units": 309,
            "classifier:CustomMLPClassifier:tol": 2.1519003381149675e-05,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2538029402797008,
            "feature_preprocessor:select_rates_classification:alpha": 0.35662299481097715,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.09664797782897949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1184,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 4.407361378615541e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.01422870895998419,
            "classifier:CustomMLPClassifier:max_iter": 288,
            "classifier:CustomMLPClassifier:num_units": 444,
            "classifier:CustomMLPClassifier:tol": 2.593576030322727e-05,
            "feature_preprocessor:select_rates_classification:alpha": 0.27077590605389806,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.1237478256225586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1185,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 4.556905331454506e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.0005906547111652091,
            "classifier:CustomMLPClassifier:max_iter": 489,
            "classifier:CustomMLPClassifier:num_units": 424,
            "classifier:CustomMLPClassifier:tol": 0.0003950913871505776,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3178338202032785,
            "feature_preprocessor:select_rates_classification:alpha": 0.1369629196608877,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.10187697410583496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1186,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "identity",
            "classifier:CustomMLPClassifier:alpha": 0.0002883644432471234,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.013327254708184546,
            "classifier:CustomMLPClassifier:max_iter": 139,
            "classifier:CustomMLPClassifier:num_units": 469,
            "classifier:CustomMLPClassifier:tol": 0.0011557434021479437,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019927899873529126,
            "feature_preprocessor:select_rates_classification:alpha": 0.41857926959647296,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.12959599494934082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 1187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 0.00033043303783016943,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00029806284711537956,
            "classifier:CustomMLPClassifier:max_iter": 458,
            "classifier:CustomMLPClassifier:num_units": 326,
            "classifier:CustomMLPClassifier:tol": 0.0011114923842271592,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.736194607049149,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.24728512613810943,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7211511339079675,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2214806537256377,
        "time": 0.9423561096191406,
        "additional_info": {
            "duration": 0.9281430244445801,
            "num_run": 1188,
            "train_loss": 1.1733287618914736,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 4.112491232707491e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.00011452167897767684,
            "classifier:CustomMLPClassifier:max_iter": 216,
            "classifier:CustomMLPClassifier:num_units": 363,
            "classifier:CustomMLPClassifier:tol": 0.0001880848128209294,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.787487301659883,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.212702996783982,
        "time": 3.352811098098755,
        "additional_info": {
            "duration": 3.340456962585449,
            "num_run": 1189,
            "train_loss": 1.1793508695004835,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1189,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomMLPClassifier:activation": "relu",
            "classifier:CustomMLPClassifier:alpha": 3.867448974052993e-06,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.19622429166998523,
            "classifier:CustomMLPClassifier:max_iter": 292,
            "classifier:CustomMLPClassifier:num_units": 118,
            "classifier:CustomMLPClassifier:tol": 0.0005630761276626198,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04251124278867038,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8788223278866789,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.062207497673982926,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.36853604876515333,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.268230477402212,
        "time": 0.4515411853790283,
        "additional_info": {
            "duration": 0.4396529197692871,
            "num_run": 1190,
            "train_loss": 1.1359309168817355,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1190,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 0.002663968449230971,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.029682522049200983,
            "classifier:CustomMLPClassifier:max_iter": 284,
            "classifier:CustomMLPClassifier:num_units": 412,
            "classifier:CustomMLPClassifier:tol": 0.0007707801736564923,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13889694494120108,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7555697280030405,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26520593568613543,
            "feature_preprocessor:select_rates_classification:alpha": 0.43363918273112434,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 1.0051391124725342,
        "additional_info": {
            "error": "Timeout",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 1191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomMLPClassifier",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomMLPClassifier:activation": "tanh",
            "classifier:CustomMLPClassifier:alpha": 2.96288984336469e-05,
            "classifier:CustomMLPClassifier:learning_rate_init": 0.02281835686589433,
            "classifier:CustomMLPClassifier:max_iter": 466,
            "classifier:CustomMLPClassifier:num_units": 367,
            "classifier:CustomMLPClassifier:tol": 0.002537055436732227,
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49800424696883777,
            "feature_preprocessor:select_rates_classification:alpha": 0.071053735922153,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]