[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01
        },
        "cost": 1.2684962379896476,
        "time": 0.9214780330657959,
        "additional_info": {
            "duration": 0.9125649929046631,
            "num_run": 2,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06943546983792238,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 193,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 318,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2406556519603407,
        "time": 0.4587979316711426,
        "additional_info": {
            "duration": 0.4233698844909668,
            "num_run": 3,
            "train_loss": 1.1697931140045583,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19744241073972732,
            "feature_preprocessor:kitchen_sinks:gamma": 0.008038493427960746,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.13323283195495605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005914257872015065,
            "feature_preprocessor:select_percentile_classification:percentile": 57.378373122989764,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.2382822036743164,
        "additional_info": {
            "duration": 0.22522282600402832,
            "num_run": 5,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2797285530486886,
        "time": 0.3756241798400879,
        "additional_info": {
            "duration": 0.36081624031066895,
            "num_run": 6,
            "train_loss": 1.1604514174094094,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002836249135958794,
            "feature_preprocessor:pca:keep_variance": 0.5554331431994848,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2789307252463658,
        "time": 0.25388288497924805,
        "additional_info": {
            "duration": 0.2373511791229248,
            "num_run": 7,
            "train_loss": 1.1814486534395006,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002119388709440359,
            "feature_preprocessor:pca:keep_variance": 0.8778885047995537,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.227493390938579,
        "time": 0.21759581565856934,
        "additional_info": {
            "duration": 0.19797897338867188,
            "num_run": 8,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01885721793297807,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 495.1165435342211,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.02874497201376828
        },
        "cost": 1.267326592811427,
        "time": 0.2162928581237793,
        "additional_info": {
            "duration": 0.20673298835754395,
            "num_run": 9,
            "train_loss": 1.1663125112558244,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29499356307409363,
            "feature_preprocessor:kitchen_sinks:gamma": 1.6375323826658983,
            "feature_preprocessor:kitchen_sinks:n_components": 450
        },
        "cost": 0.0,
        "time": 0.16698193550109863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25455985918335106,
            "feature_preprocessor:select_rates_classification:alpha": 0.4493709834409605,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.242451613494032,
        "time": 0.21867012977600098,
        "additional_info": {
            "duration": 0.2003021240234375,
            "num_run": 11,
            "train_loss": 1.211564155651178,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8953675059096271,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.138715361760742,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1739
        },
        "cost": 0.0,
        "time": 0.11019492149353027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007155049082425777,
            "feature_preprocessor:pca:keep_variance": 0.5946596309582917,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2341475778887185,
        "time": 0.23409819602966309,
        "additional_info": {
            "duration": 0.21174001693725586,
            "num_run": 13,
            "train_loss": 1.230283827031025,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6542304494615282,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.22045111656188965,
        "additional_info": {
            "duration": 0.19956493377685547,
            "num_run": 14,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043658949105762616,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.21732521057128906,
        "additional_info": {
            "duration": 0.20026803016662598,
            "num_run": 15,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.31392359433182015,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 256,
            "feature_preprocessor:kernel_pca:gamma": 0.011799963802116281
        },
        "cost": 0.0,
        "time": 0.21343469619750977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45796264447516394,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005947421763508947,
            "feature_preprocessor:kitchen_sinks:n_components": 6450
        },
        "cost": 0.0,
        "time": 0.14920306205749512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9287950708917703,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.047217884855318804,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1689,
            "feature_preprocessor:nystroem_sampler:coef0": 0.15225824291801904,
            "feature_preprocessor:nystroem_sampler:gamma": 0.20813396869837938
        },
        "cost": 1.229569449779817,
        "time": 0.41733312606811523,
        "additional_info": {
            "duration": 0.40552282333374023,
            "num_run": 18,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011418655807632584
        },
        "cost": 1.229569449779817,
        "time": 0.2092747688293457,
        "additional_info": {
            "duration": 0.19871902465820312,
            "num_run": 19,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.5158873418936069,
            "feature_preprocessor:kitchen_sinks:n_components": 687
        },
        "cost": 0.0,
        "time": 0.13075518608093262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005052275870042271,
            "feature_preprocessor:kitchen_sinks:n_components": 189
        },
        "cost": 0.0,
        "time": 0.13199734687805176,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005414338362974642,
            "feature_preprocessor:kitchen_sinks:gamma": 0.003189160906134114,
            "feature_preprocessor:kitchen_sinks:n_components": 253
        },
        "cost": 0.0,
        "time": 0.12868404388427734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004919010429024109,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8859114595308957,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07402638422779316,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.262639878841831,
        "time": 0.4730398654937744,
        "additional_info": {
            "duration": 0.4555208683013916,
            "num_run": 23,
            "train_loss": 1.1667609833887347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8864629151087128,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0578209087088015,
            "feature_preprocessor:kitchen_sinks:gamma": 5.842927835677571,
            "feature_preprocessor:kitchen_sinks:n_components": 261
        },
        "cost": 0.0,
        "time": 0.1070551872253418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19823736724416274,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.944435017369399,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29705081749401524,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 513,
            "feature_preprocessor:kernel_pca:coef0": 0.05388153952932839,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 0.18724042796167997
        },
        "cost": 0.0,
        "time": 0.16852712631225586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002473582286010448,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006159430646835054,
            "feature_preprocessor:kitchen_sinks:n_components": 1424
        },
        "cost": 0.0,
        "time": 0.13535785675048828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9016381361305943,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29554073231571154,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 813
        },
        "cost": 0.0,
        "time": 0.1328418254852295,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01744132075211021
        },
        "cost": 1.2683874523693144,
        "time": 0.1954810619354248,
        "additional_info": {
            "duration": 0.18302273750305176,
            "num_run": 28,
            "train_loss": 1.1723709133145752,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0014869348436455788,
            "feature_preprocessor:kitchen_sinks:n_components": 122
        },
        "cost": 0.0,
        "time": 0.1067209243774414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01457020441192646,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2702004794549882,
        "time": 9.436058044433594,
        "additional_info": {
            "duration": 9.408404111862183,
            "num_run": 30,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.060667436902394824,
            "feature_preprocessor:kitchen_sinks:gamma": 7.611724111367771,
            "feature_preprocessor:kitchen_sinks:n_components": 1576
        },
        "cost": 0.0,
        "time": 0.15540504455566406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9497064225179507,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27334596187724014,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8922402903023858,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2643441203071715,
        "time": 0.25061678886413574,
        "additional_info": {
            "duration": 0.2397921085357666,
            "num_run": 32,
            "train_loss": 1.1856774258789895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 852
        },
        "cost": 0.0,
        "time": 0.18843388557434082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06414482231639615,
            "feature_preprocessor:kitchen_sinks:gamma": 6.992037478899618e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 69
        },
        "cost": 0.0,
        "time": 0.1741478443145752,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.44778265352784e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 163
        },
        "cost": 0.0,
        "time": 0.10552501678466797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1180,
            "feature_preprocessor:kernel_pca:coef0": 0.09744367836641388,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 4.628444810611482e-05
        },
        "cost": 0.0,
        "time": 0.19838809967041016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014929942965190724,
            "feature_preprocessor:select_percentile_classification:percentile": 76.34569734067234,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2568921055547089,
        "time": 0.2772359848022461,
        "additional_info": {
            "duration": 0.2633240222930908,
            "num_run": 37,
            "train_loss": 1.175987498088726,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.10552518182247506,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.19602203369140625,
        "additional_info": {
            "duration": 0.18582701683044434,
            "num_run": 38,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.9836940264176655e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 2023
        },
        "cost": 0.0,
        "time": 0.16571712493896484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02549986406469584,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 104,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 727,
            "feature_preprocessor:kernel_pca:coef0": -0.6316227143953035,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.006327264847847074
        },
        "cost": 0.0,
        "time": 0.21854591369628906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22932487132935545,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 750,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 36.878621938090404,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2760568386028046,
        "time": 0.28127408027648926,
        "additional_info": {
            "duration": 0.2716968059539795,
            "num_run": 41,
            "train_loss": 1.16667299789866,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05792037081744539,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8459283947935319,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2637894397912593,
            "feature_preprocessor:kitchen_sinks:gamma": 0.16959922815190662,
            "feature_preprocessor:kitchen_sinks:n_components": 179
        },
        "cost": 0.0,
        "time": 0.13585186004638672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 24.767347423153257,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2338928791495065,
        "time": 0.22414016723632812,
        "additional_info": {
            "duration": 0.21455931663513184,
            "num_run": 43,
            "train_loss": 1.2376593748795675,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08845371741528696,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1637,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 38.7883915451977,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2760568386028046,
        "time": 0.22053313255310059,
        "additional_info": {
            "duration": 0.21009111404418945,
            "num_run": 44,
            "train_loss": 1.16667299789866,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1846,
            "feature_preprocessor:kernel_pca:coef0": 0.6484681233538958
        },
        "cost": 0.0,
        "time": 0.21082806587219238,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.156325 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.156325 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9187310767456176,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227493390938579,
        "time": 0.21470308303833008,
        "additional_info": {
            "duration": 0.19506478309631348,
            "num_run": 46,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008811371526271767,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8165979773841446,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1571211304925981,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.24499287293623617,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2609900301866572,
        "time": 0.22727489471435547,
        "additional_info": {
            "duration": 0.21569466590881348,
            "num_run": 47,
            "train_loss": 1.192136840637237,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016166405214078293,
            "feature_preprocessor:kitchen_sinks:gamma": 0.5861697799506456,
            "feature_preprocessor:kitchen_sinks:n_components": 923
        },
        "cost": 0.0,
        "time": 0.12980890274047852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0049864390499942506,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1370,
            "feature_preprocessor:kernel_pca:coef0": 0.43726973311143014,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 8.164870840381665e-05
        },
        "cost": 0.0,
        "time": 0.18226003646850586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002755720155517966,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 827
        },
        "cost": 0.0,
        "time": 0.20718598365783691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048847406377892644,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8851103977533672,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06795545482717096,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.266791996524307,
        "time": 0.456524133682251,
        "additional_info": {
            "duration": 0.4356560707092285,
            "num_run": 51,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11495561686889288,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9838204100167987,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19085677758207015,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.247464484564989,
        "time": 0.29595494270324707,
        "additional_info": {
            "duration": 0.27898526191711426,
            "num_run": 52,
            "train_loss": 1.1420650362673146,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3293147573318521,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2688136625553785,
        "time": 0.21185708045959473,
        "additional_info": {
            "duration": 0.2007770538330078,
            "num_run": 53,
            "train_loss": 1.189315347885327,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003500873216281415,
            "feature_preprocessor:kitchen_sinks:gamma": 0.029987375511376323,
            "feature_preprocessor:kitchen_sinks:n_components": 56
        },
        "cost": 0.0,
        "time": 0.10329103469848633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15483392427877088,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8066672830099788,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10601125122477545,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1257,
            "feature_preprocessor:nystroem_sampler:coef0": 0.8332514655436811,
            "feature_preprocessor:nystroem_sampler:gamma": 0.8558344404398662
        },
        "cost": 1.2176478927791472,
        "time": 0.4234650135040283,
        "additional_info": {
            "duration": 0.4074099063873291,
            "num_run": 55,
            "train_loss": 1.195061796938512,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008388588399283742,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9408634092379619,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2704430349540206,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 24,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2643441203071715,
        "time": 0.35513997077941895,
        "additional_info": {
            "duration": 0.34360718727111816,
            "num_run": 56,
            "train_loss": 1.1858816674680783,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10770267912632508,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3089019626867162,
        "time": 0.26634907722473145,
        "additional_info": {
            "duration": 0.2528350353240967,
            "num_run": 57,
            "train_loss": 1.0233686453433066,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006460997631257698,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2702004794549882,
        "time": 9.602604150772095,
        "additional_info": {
            "duration": 9.584702968597412,
            "num_run": 58,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012809572075518452,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1177,
            "feature_preprocessor:kernel_pca:coef0": 0.24527256337453318
        },
        "cost": 0.0,
        "time": 0.20675182342529297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5117617408760586,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2861921787261963,
        "additional_info": {
            "duration": 0.27543115615844727,
            "num_run": 60,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1711,
            "feature_preprocessor:kernel_pca:coef0": 0.7210519107660511,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.7583729525359643
        },
        "cost": 0.0,
        "time": 0.20449423789978027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007832459663444844,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9904800608194575,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18086709694212458,
            "feature_preprocessor:select_rates_classification:alpha": 0.13056064674012313,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2488513014645983,
        "time": 0.17171096801757812,
        "additional_info": {
            "duration": 0.16196918487548828,
            "num_run": 62,
            "train_loss": 1.1693521123503292,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1323,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.361332342000833,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2700918935942935,
        "time": 0.28467607498168945,
        "additional_info": {
            "duration": 0.27411818504333496,
            "num_run": 63,
            "train_loss": 1.1860651089269085,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9652164464933035,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10635909928603518,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 2275,
            "feature_preprocessor:nystroem_sampler:coef0": -0.052651523471355155,
            "feature_preprocessor:nystroem_sampler:gamma": 4.5179757047991375e-05
        },
        "cost": 1.229569449779817,
        "time": 0.3366539478302002,
        "additional_info": {
            "duration": 0.31954503059387207,
            "num_run": 64,
            "train_loss": 1.2282574263013553,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.764807925295798,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.048596100421439234
        },
        "cost": 1.2555594817056273,
        "time": 0.23035979270935059,
        "additional_info": {
            "duration": 0.2128300666809082,
            "num_run": 65,
            "train_loss": 1.169508357404076,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009878704530583165,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7131387237212781,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12187879318892032,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 81.23386809117324,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00026390753358240967
        },
        "cost": 1.2705722968308857,
        "time": 0.16760492324829102,
        "additional_info": {
            "duration": 0.157426118850708,
            "num_run": 66,
            "train_loss": 1.1674211675894148,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 169
        },
        "cost": 0.0,
        "time": 0.19733023643493652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7002105829931748,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22882802665299543,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 57,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2684962379896476,
        "time": 0.3096177577972412,
        "additional_info": {
            "duration": 0.29157304763793945,
            "num_run": 68,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13223622026646123,
            "feature_preprocessor:kitchen_sinks:gamma": 5.4502082525417375e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 444
        },
        "cost": 0.0,
        "time": 0.13298702239990234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7420101767775763,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2274375304932005,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1440,
            "feature_preprocessor:kernel_pca:coef0": 0.9848239704134747
        },
        "cost": 0.0,
        "time": 0.1575307846069336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.134282 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.134282 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007129108535445005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8710960090505256,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15410441753691012,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 660,
            "feature_preprocessor:kernel_pca:coef0": 0.5976384995443298
        },
        "cost": 0.0,
        "time": 0.1869041919708252,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.146579 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.146579 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06326794126113616,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1060,
            "feature_preprocessor:kernel_pca:gamma": 0.0009417645270373073
        },
        "cost": 0.0,
        "time": 0.22711396217346191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 75,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.263918109880746,
        "time": 0.31666111946105957,
        "additional_info": {
            "duration": 0.3004169464111328,
            "num_run": 73,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038195246391802204,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1217,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3146522045135498,
        "additional_info": {
            "duration": 0.3009793758392334,
            "num_run": 74,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006533285382969344,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1739
        },
        "cost": 0.0,
        "time": 0.13905596733093262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039665085801622596,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 455,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 644
        },
        "cost": 0.0,
        "time": 0.2209300994873047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017733556317862668,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 424,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.03772106416976472,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00033037525260440294
        },
        "cost": 1.2488513014645983,
        "time": 0.21289515495300293,
        "additional_info": {
            "duration": 0.20261502265930176,
            "num_run": 77,
            "train_loss": 1.1911236402724021,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 573,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 17020.232768702463,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00015071912322684903
        },
        "cost": 1.2410733293704137,
        "time": 0.19109725952148438,
        "additional_info": {
            "duration": 0.1809830665588379,
            "num_run": 78,
            "train_loss": 1.1990394054574267,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005933900738546171,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 93
        },
        "cost": 1.229569449779817,
        "time": 0.2398078441619873,
        "additional_info": {
            "duration": 0.22275805473327637,
            "num_run": 79,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42542398998336906,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 160
        },
        "cost": 0.0,
        "time": 0.20573997497558594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.35224276619670625,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1663,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.101145813349162e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1371
        },
        "cost": 0.0,
        "time": 0.1747579574584961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002710454551086328,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 322,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229569449779817,
        "time": 0.2912468910217285,
        "additional_info": {
            "duration": 0.27289390563964844,
            "num_run": 82,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017897512174765557,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1711,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 100
        },
        "cost": 0.0,
        "time": 0.1379232406616211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036617240680997414,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 659,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 171,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2389514104950001,
        "time": 0.33189892768859863,
        "additional_info": {
            "duration": 0.3110940456390381,
            "num_run": 84,
            "train_loss": 1.172682866320141,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02035445576912545,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 42,
            "feature_preprocessor:kernel_pca:coef0": 0.3461031408787314,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 0.0003051627151147938
        },
        "cost": 0.0,
        "time": 0.24454474449157715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00033610009802922367,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 979,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1793
        },
        "cost": 0.0,
        "time": 0.16475701332092285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1986,
            "feature_preprocessor:nystroem_sampler:coef0": 0.634141285711187,
            "feature_preprocessor:nystroem_sampler:gamma": 0.002622396955448113
        },
        "cost": 1.243149188452013,
        "time": 0.310837984085083,
        "additional_info": {
            "duration": 0.2948179244995117,
            "num_run": 87,
            "train_loss": 1.2164803086964304,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2775437085871175,
        "time": 0.2508358955383301,
        "additional_info": {
            "duration": 0.2371199131011963,
            "num_run": 88,
            "train_loss": 1.1968093002405962,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2875063253832348,
        "time": 0.8850417137145996,
        "additional_info": {
            "duration": 0.8683841228485107,
            "num_run": 89,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4020520260228444,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.211265470120202,
        "time": 0.24668598175048828,
        "additional_info": {
            "duration": 0.2348630428314209,
            "num_run": 90,
            "train_loss": 1.1810337739864982,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1765
        },
        "cost": 0.0,
        "time": 0.16102099418640137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028354072798167005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1688
        },
        "cost": 0.0,
        "time": 0.15640711784362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 194,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2554508958449326,
        "time": 0.3201889991760254,
        "additional_info": {
            "duration": 0.3069019317626953,
            "num_run": 93,
            "train_loss": 1.1772870663598276,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1975
        },
        "cost": 0.0,
        "time": 0.10434579849243164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002449345531273098,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 845,
            "feature_preprocessor:kernel_pca:gamma": 8.190197728926648e-05
        },
        "cost": 0.0,
        "time": 0.22507691383361816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004881717687672681,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 660
        },
        "cost": 0.0,
        "time": 0.10536384582519531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 729,
            "feature_preprocessor:kernel_pca:coef0": 0.35768644341304934,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 1.8635860285066956
        },
        "cost": 0.0,
        "time": 0.18275094032287598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3085843383613462,
        "time": 0.3259878158569336,
        "additional_info": {
            "duration": 0.308013916015625,
            "num_run": 98,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.9258736558413703,
            "feature_preprocessor:kitchen_sinks:n_components": 617
        },
        "cost": 0.0,
        "time": 0.13324522972106934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008826480176672095,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1699
        },
        "cost": 0.0,
        "time": 0.11374211311340332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1258,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.3590907521389302,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2640266957414403,
        "time": 0.30158209800720215,
        "additional_info": {
            "duration": 0.2656099796295166,
            "num_run": 101,
            "train_loss": 1.1607361740098916,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1072734819518386,
            "feature_preprocessor:kitchen_sinks:gamma": 3.840372842449419e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 378
        },
        "cost": 0.0,
        "time": 0.1101992130279541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1632,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 818
        },
        "cost": 0.0,
        "time": 0.15333008766174316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8206741412593063,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1976212854110494,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 228
        },
        "cost": 0.0,
        "time": 0.10997509956359863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7734516018152426,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.025531252303767175,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 430,
            "feature_preprocessor:kernel_pca:gamma": 2.0242899941034915
        },
        "cost": 0.0,
        "time": 0.25379395484924316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.903765960170585,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1997952248963762
        },
        "cost": 1.266791996524307,
        "time": 0.20620203018188477,
        "additional_info": {
            "duration": 0.18804717063903809,
            "num_run": 106,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 949,
            "feature_preprocessor:kernel_pca:coef0": -0.6226219150681209
        },
        "cost": 0.0,
        "time": 0.15987777709960938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006836394159956015,
            "feature_preprocessor:kitchen_sinks:n_components": 646
        },
        "cost": 0.0,
        "time": 0.10611796379089355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 9.262306928634644,
        "additional_info": {
            "duration": 9.244480848312378,
            "num_run": 109,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 603
        },
        "cost": 0.0,
        "time": 0.10558390617370605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9631376724421451,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04674572408257014,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006179426468600775,
            "feature_preprocessor:kitchen_sinks:n_components": 123
        },
        "cost": 0.0,
        "time": 0.13494610786437988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 190
        },
        "cost": 0.0,
        "time": 0.10598421096801758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016898089198421925,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 301,
            "feature_preprocessor:kernel_pca:coef0": -0.11185498809386751
        },
        "cost": 0.0,
        "time": 0.24693799018859863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.00151003 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.00151003 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00030490425836518455,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7492273210903775,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26284430588149527,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 440
        },
        "cost": 0.0,
        "time": 0.16956090927124023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1751,
            "feature_preprocessor:nystroem_sampler:coef0": 0.8157733875010982,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 1.207250482393866
        },
        "cost": 1.229569449779817,
        "time": 0.3586537837982178,
        "additional_info": {
            "duration": 0.34767889976501465,
            "num_run": 115,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6162648547914192,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2468294356738883,
        "time": 0.36443305015563965,
        "additional_info": {
            "duration": 0.3503568172454834,
            "num_run": 116,
            "train_loss": 1.1735200957048266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1509,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.41886654653355826,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2347994925721628,
        "time": 0.3544950485229492,
        "additional_info": {
            "duration": 0.34392571449279785,
            "num_run": 117,
            "train_loss": 1.1816790172298164,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002803079647560884,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 277
        },
        "cost": 0.0,
        "time": 0.14055585861206055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8061391313851187,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.024122774066295156,
            "feature_preprocessor:select_percentile_classification:percentile": 54.51690615906056,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.4329719543457031,
        "additional_info": {
            "duration": 0.3998739719390869,
            "num_run": 119,
            "train_loss": 1.2290327923971933,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004938694629024162,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.20399999618530273,
        "additional_info": {
            "duration": 0.18587374687194824,
            "num_run": 120,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2554508958449326,
        "time": 0.2219710350036621,
        "additional_info": {
            "duration": 0.19479703903198242,
            "num_run": 121,
            "train_loss": 1.1772870663598276,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13014833641642878,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1169,
            "feature_preprocessor:kernel_pca:gamma": 0.0017599216843862235
        },
        "cost": 0.0,
        "time": 0.16675615310668945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 966,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1080
        },
        "cost": 0.0,
        "time": 0.18087387084960938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001562130739465419,
            "feature_preprocessor:pca:keep_variance": 0.523349257449984,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2538554399999253,
        "time": 0.23600316047668457,
        "additional_info": {
            "duration": 0.22132205963134766,
            "num_run": 124,
            "train_loss": 1.17557369283958,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011480165334102143
        },
        "cost": 1.229569449779817,
        "time": 0.2079448699951172,
        "additional_info": {
            "duration": 0.18528485298156738,
            "num_run": 125,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06826458946029798,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 768
        },
        "cost": 0.0,
        "time": 0.14031124114990234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011391208442022217,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 123
        },
        "cost": 0.0,
        "time": 0.10656523704528809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8480285006664225,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2560617557148534,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1189,
            "feature_preprocessor:kernel_pca:coef0": -0.7610416591064728,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 2.510563586414368
        },
        "cost": 0.0,
        "time": 0.16753697395324707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9001118460094863,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1965231188126866,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00010146894934963936,
            "feature_preprocessor:kitchen_sinks:n_components": 533
        },
        "cost": 0.0,
        "time": 0.11078906059265137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006277828403867025,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 922
        },
        "cost": 0.0,
        "time": 0.10656309127807617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0736830809807771,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 477,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.20256519317626953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 40
        },
        "cost": 0.0,
        "time": 0.13279414176940918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0052921190008715065,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 878
        },
        "cost": 0.0,
        "time": 0.11226511001586914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013152919089156025,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1338,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 874
        },
        "cost": 0.0,
        "time": 0.14860200881958008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032526128718113014,
            "feature_preprocessor:kitchen_sinks:gamma": 1.2921325012282563,
            "feature_preprocessor:kitchen_sinks:n_components": 332
        },
        "cost": 0.0,
        "time": 0.13097715377807617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003448357300115652,
            "feature_preprocessor:kitchen_sinks:gamma": 1.579344178432771,
            "feature_preprocessor:kitchen_sinks:n_components": 2457
        },
        "cost": 0.0,
        "time": 0.11308908462524414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1058
        },
        "cost": 0.0,
        "time": 0.2004542350769043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0047432335970875455,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8614182640940418,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23804085215150886,
            "feature_preprocessor:select_rates_classification:alpha": 0.2670006270101454,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.2040548324584961,
        "additional_info": {
            "duration": 0.1936500072479248,
            "num_run": 138,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004893155349059006
        },
        "cost": 1.229569449779817,
        "time": 0.20524311065673828,
        "additional_info": {
            "duration": 0.19014310836791992,
            "num_run": 139,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022543948581112798,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9370305324251003,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29225083747154335,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 684
        },
        "cost": 0.0,
        "time": 0.12099885940551758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17839912516212073,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9073011752554723,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09466891471622849,
            "feature_preprocessor:kitchen_sinks:gamma": 0.030597671520309042,
            "feature_preprocessor:kitchen_sinks:n_components": 1262
        },
        "cost": 0.0,
        "time": 0.13967013359069824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6824113525222748,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2433038341065217,
        "time": 0.2151191234588623,
        "additional_info": {
            "duration": 0.201185941696167,
            "num_run": 142,
            "train_loss": 1.2339489454424457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 8.568537682624367,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2431493882116518,
        "time": 0.18942904472351074,
        "additional_info": {
            "duration": 0.17978310585021973,
            "num_run": 143,
            "train_loss": 1.2076542695940076,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0059543108275889895,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 28903.423562464446,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.021418963436992875
        },
        "cost": 1.2468840282436935,
        "time": 0.1611778736114502,
        "additional_info": {
            "duration": 0.1516399383544922,
            "num_run": 144,
            "train_loss": 1.1893836074489992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.012485694223436152,
            "feature_preprocessor:kitchen_sinks:n_components": 52
        },
        "cost": 0.0,
        "time": 0.170029878616333,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.265676744156253,
        "time": 0.8362460136413574,
        "additional_info": {
            "duration": 0.8230321407318115,
            "num_run": 146,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1630,
            "feature_preprocessor:nystroem_sampler:coef0": -0.4087855884540521,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 3.185569807963797
        },
        "cost": 1.2475730704256833,
        "time": 0.37377405166625977,
        "additional_info": {
            "duration": 0.3625040054321289,
            "num_run": 147,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 850
        },
        "cost": 0.0,
        "time": 0.13941502571105957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006636649079902456,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 702,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2762740103241936,
        "time": 0.9931857585906982,
        "additional_info": {
            "duration": 0.9792797565460205,
            "num_run": 149,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1722,
            "feature_preprocessor:kernel_pca:coef0": -0.5329420059891035
        },
        "cost": 0.0,
        "time": 0.19274592399597168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.201509 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.201509 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11542809607245348,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.15682196617126465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 504,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 132,
            "feature_preprocessor:nystroem_sampler:coef0": 0.520529845412681,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 1.5589341755009565
        },
        "cost": 1.2781872902542093,
        "time": 0.3313570022583008,
        "additional_info": {
            "duration": 0.3131871223449707,
            "num_run": 152,
            "train_loss": 1.098043626375534,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002734896354806979,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1050,
            "feature_preprocessor:kernel_pca:coef0": 0.2560106796323285
        },
        "cost": 0.0,
        "time": 0.15556621551513672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.266583 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.266583 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18665262684832937,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1275
        },
        "cost": 0.0,
        "time": 0.1560218334197998,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0876754642093026,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1385,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 32.711154166202824,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 1.8117998259557488e-05
        },
        "cost": 1.2512991776817342,
        "time": 0.24609899520874023,
        "additional_info": {
            "duration": 0.23638200759887695,
            "num_run": 155,
            "train_loss": 1.1785242342401536,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00042882654555961034,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1147,
            "feature_preprocessor:kernel_pca:gamma": 1.0555618243934803
        },
        "cost": 0.0,
        "time": 0.1526501178741455,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.032564357831349096,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1922
        },
        "cost": 0.0,
        "time": 0.11083316802978516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018297228806890306,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1998,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.47352242907391506,
            "feature_preprocessor:kitchen_sinks:n_components": 461
        },
        "cost": 0.0,
        "time": 0.19993805885314941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.77196204511111,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.148706481232185
        },
        "cost": 1.2312736912451574,
        "time": 0.21322107315063477,
        "additional_info": {
            "duration": 0.20295119285583496,
            "num_run": 159,
            "train_loss": 1.2282574263013553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1603,
            "feature_preprocessor:kernel_pca:gamma": 0.003328472614990763
        },
        "cost": 0.0,
        "time": 0.1616220474243164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2914461447698156,
            "feature_preprocessor:kitchen_sinks:gamma": 5.536623687842656e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1604
        },
        "cost": 0.0,
        "time": 0.1313180923461914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010365341509586776,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1871,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 1.0491394764437432,
            "feature_preprocessor:kitchen_sinks:n_components": 205
        },
        "cost": 0.0,
        "time": 0.16973590850830078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 118
        },
        "cost": 0.0,
        "time": 0.6952221393585205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 250,
            "feature_preprocessor:nystroem_sampler:coef0": -0.46654185291248806,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00019532583276018963
        },
        "cost": 1.229569449779817,
        "time": 0.24512314796447754,
        "additional_info": {
            "duration": 0.22552180290222168,
            "num_run": 164,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7753814291972623,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2054415222839467,
            "feature_preprocessor:kitchen_sinks:gamma": 1.443895417235432,
            "feature_preprocessor:kitchen_sinks:n_components": 215
        },
        "cost": 0.0,
        "time": 0.11374998092651367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028684989967067533,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 541
        },
        "cost": 0.0,
        "time": 0.10902810096740723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 631,
            "feature_preprocessor:kernel_pca:coef0": -0.008685603848475276
        },
        "cost": 0.0,
        "time": 0.14432501792907715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.2484 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.2484 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036195152673203696,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 383,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2684962379896476,
        "time": 0.3523221015930176,
        "additional_info": {
            "duration": 0.3364701271057129,
            "num_run": 168,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004296156870688838,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1606
        },
        "cost": 0.0,
        "time": 0.138596773147583,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009595874161825892,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7145894444987969,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1789898340526251,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 145
        },
        "cost": 0.0,
        "time": 0.13960599899291992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009527435067730281,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7815799162464134,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2747244145133618,
        "time": 0.29660701751708984,
        "additional_info": {
            "duration": 0.28547000885009766,
            "num_run": 171,
            "train_loss": 1.1786740830190758,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013423200846569081
        },
        "cost": 1.229569449779817,
        "time": 0.22526979446411133,
        "additional_info": {
            "duration": 0.21265196800231934,
            "num_run": 172,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001319514683454916,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1301
        },
        "cost": 0.0,
        "time": 0.16425800323486328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06524268315868119,
            "feature_preprocessor:select_rates_classification:alpha": 0.38882608338210006,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.23074603080749512,
        "additional_info": {
            "duration": 0.22117304801940918,
            "num_run": 174,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.25782912595672147,
            "feature_preprocessor:kitchen_sinks:n_components": 4085
        },
        "cost": 0.0,
        "time": 0.11043977737426758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017422905459975692,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0004813092538229081,
            "feature_preprocessor:kitchen_sinks:n_components": 2737
        },
        "cost": 0.0,
        "time": 0.15931224822998047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.3161294584807205,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.2229750156402588,
        "additional_info": {
            "duration": 0.21304011344909668,
            "num_run": 177,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.060934281372366665,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9708728378975816,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07728023072975612,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 205
        },
        "cost": 0.0,
        "time": 0.2276148796081543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002437015371510098,
            "feature_preprocessor:select_percentile_classification:percentile": 91.56322796705999,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2543900362870453,
        "time": 0.24956011772155762,
        "additional_info": {
            "duration": 0.23781490325927734,
            "num_run": 179,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 3.268471038419857e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 64
        },
        "cost": 0.0,
        "time": 0.14703106880187988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5389891429613094,
        "time": 0.4804563522338867,
        "additional_info": {
            "duration": 0.46750307083129883,
            "num_run": 181,
            "train_loss": 1.5391381172960141,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03787451867119733,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1036,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1438
        },
        "cost": 0.0,
        "time": 0.1806478500366211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.07075434620799192,
            "feature_preprocessor:kitchen_sinks:n_components": 69
        },
        "cost": 0.0,
        "time": 0.11225605010986328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13712851174473317,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1058
        },
        "cost": 0.0,
        "time": 0.13231420516967773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008164440503105609,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 23,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 4.493549941379422e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 122
        },
        "cost": 0.0,
        "time": 0.12171530723571777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.270781135535922,
        "time": 0.2988739013671875,
        "additional_info": {
            "duration": 0.2825617790222168,
            "num_run": 186,
            "train_loss": 1.1920083290905015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1317,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7056161221037844,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.261044223237185,
        "time": 0.2737882137298584,
        "additional_info": {
            "duration": 0.26276707649230957,
            "num_run": 187,
            "train_loss": 1.1667001943037434,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 57
        },
        "cost": 0.0,
        "time": 0.13179302215576172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020980641251780894,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00015823460717487566,
            "feature_preprocessor:kitchen_sinks:n_components": 4674
        },
        "cost": 0.0,
        "time": 0.1391458511352539,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8366247096972239,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2416278685307426
        },
        "cost": 1.2684962379896476,
        "time": 0.2997398376464844,
        "additional_info": {
            "duration": 0.2770817279815674,
            "num_run": 190,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09609429232889888,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 315
        },
        "cost": 0.0,
        "time": 0.1304640769958496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.297003614479469,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1253,
            "feature_preprocessor:kernel_pca:coef0": 0.9145280725901082,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.007285155152751648
        },
        "cost": 0.0,
        "time": 0.23282885551452637,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 946
        },
        "cost": 0.0,
        "time": 0.14704513549804688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16818169359761795,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 708,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.5862393198402392,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.259711799147742,
        "time": 0.30246496200561523,
        "additional_info": {
            "duration": 0.28374314308166504,
            "num_run": 194,
            "train_loss": 1.1955987916634252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 723,
            "feature_preprocessor:nystroem_sampler:coef0": -0.921283847109023,
            "feature_preprocessor:nystroem_sampler:gamma": 0.04646873446470033
        },
        "cost": 1.229569449779817,
        "time": 0.3450350761413574,
        "additional_info": {
            "duration": 0.3337228298187256,
            "num_run": 195,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010258558415851708,
            "feature_preprocessor:select_rates_classification:alpha": 0.4894008911707761,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2479446880419423,
        "time": 0.24772906303405762,
        "additional_info": {
            "duration": 0.2294609546661377,
            "num_run": 196,
            "train_loss": 1.1803191969756515,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002124383047688786,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1261
        },
        "cost": 0.0,
        "time": 0.1794891357421875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 257,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6969925471586004,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2479990808521089,
        "time": 0.2871711254119873,
        "additional_info": {
            "duration": 0.2756202220916748,
            "num_run": 198,
            "train_loss": 1.2059328884931506,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 223,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.229569449779817,
        "time": 0.33478283882141113,
        "additional_info": {
            "duration": 0.3202481269836426,
            "num_run": 199,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9944353354277017,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09849463321349813,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 494
        },
        "cost": 0.0,
        "time": 0.17791509628295898,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 695
        },
        "cost": 0.0,
        "time": 0.13439273834228516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018992238532466756,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.1430084470169963,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00010269109702178727
        },
        "cost": 1.275522242315685,
        "time": 0.16219425201416016,
        "additional_info": {
            "duration": 0.15130400657653809,
            "num_run": 202,
            "train_loss": 1.1815366389295752,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 102,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1868
        },
        "cost": 0.0,
        "time": 0.17798399925231934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028675842151089244,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 122
        },
        "cost": 0.0,
        "time": 0.11476588249206543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1098,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1734,
            "feature_preprocessor:kernel_pca:coef0": 0.7255580709166027
        },
        "cost": 0.0,
        "time": 0.21117782592773438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.285256 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.285256 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014401006413469236,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 451,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9393275961452956,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2645531587718466,
        "time": 0.2947850227355957,
        "additional_info": {
            "duration": 0.2836618423461914,
            "num_run": 206,
            "train_loss": 1.2073412423845855,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03193856919067331,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 169
        },
        "cost": 0.0,
        "time": 0.1060643196105957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10770526822655288,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8554649292733522,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26561129401169675,
            "feature_preprocessor:select_rates_classification:alpha": 0.11157507024259639,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2256890963885352,
        "time": 0.18927001953125,
        "additional_info": {
            "duration": 0.1792130470275879,
            "num_run": 208,
            "train_loss": 1.215275659292156,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1159,
            "feature_preprocessor:kernel_pca:coef0": 0.3661268006109477,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 8.000438997763386e-05
        },
        "cost": 0.0,
        "time": 0.2032930850982666,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 381,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1556,
            "feature_preprocessor:kernel_pca:gamma": 0.00010848974002111952
        },
        "cost": 0.0,
        "time": 0.21514487266540527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06885474420907998,
            "feature_preprocessor:select_rates_classification:alpha": 0.4462078975609774,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.2265777587890625,
        "additional_info": {
            "duration": 0.21703791618347168,
            "num_run": 211,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1271,
            "feature_preprocessor:kernel_pca:gamma": 0.0017015100481887714
        },
        "cost": 0.0,
        "time": 0.18233513832092285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1551,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0004163388840502172,
            "feature_preprocessor:kitchen_sinks:n_components": 996
        },
        "cost": 0.0,
        "time": 0.14873886108398438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002668494673392983
        },
        "cost": 1.2564660951282833,
        "time": 0.21705293655395508,
        "additional_info": {
            "duration": 0.20577001571655273,
            "num_run": 214,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1198,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 355
        },
        "cost": 0.0,
        "time": 0.25312304496765137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004482982191899585,
            "feature_preprocessor:kitchen_sinks:gamma": 4.251414705213039e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 841
        },
        "cost": 0.0,
        "time": 0.10475802421569824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2751504249397871,
        "time": 0.2586629390716553,
        "additional_info": {
            "duration": 0.24660682678222656,
            "num_run": 217,
            "train_loss": 1.1695216870556535,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013012206004443593,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.3089019626867162,
        "time": 0.2412397861480713,
        "additional_info": {
            "duration": 0.2092421054840088,
            "num_run": 218,
            "train_loss": 1.0233686453433066,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008604451467335285,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 329,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5320279593491861,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2573220729827881,
        "additional_info": {
            "duration": 0.24598407745361328,
            "num_run": 219,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 262,
            "feature_preprocessor:kernel_pca:coef0": 0.20940758229066536,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 4.361547676974578
        },
        "cost": 0.0,
        "time": 0.21491289138793945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2661027545826786,
        "time": 0.2571721076965332,
        "additional_info": {
            "duration": 0.2331562042236328,
            "num_run": 221,
            "train_loss": 1.0633308575009228,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.024862738970282634,
            "feature_preprocessor:select_percentile_classification:percentile": 32.88531413055895,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2452796401034176,
        "time": 0.18123292922973633,
        "additional_info": {
            "duration": 0.17134499549865723,
            "num_run": 222,
            "train_loss": 1.1930897890190089,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03065099779254354,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7966666757483227,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0070839599726532036
        },
        "cost": 1.2601378095741675,
        "time": 0.227431058883667,
        "additional_info": {
            "duration": 0.20032691955566406,
            "num_run": 223,
            "train_loss": 1.1701536006473943,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1491
        },
        "cost": 0.0,
        "time": 0.16702699661254883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 690
        },
        "cost": 0.0,
        "time": 0.13199305534362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03678867649486508,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1138,
            "feature_preprocessor:kernel_pca:coef0": 0.4678660482143291
        },
        "cost": 0.0,
        "time": 0.15146994590759277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.277918 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.277918 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2898138290527095,
            "feature_preprocessor:pca:keep_variance": 0.5679716413297281,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2559856918916914,
        "time": 0.21913909912109375,
        "additional_info": {
            "duration": 0.20645928382873535,
            "num_run": 227,
            "train_loss": 1.1755464964344964,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 311
        },
        "cost": 0.0,
        "time": 0.15708684921264648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010584276199294332,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 537,
            "feature_preprocessor:kernel_pca:coef0": -0.5057628719514453
        },
        "cost": 0.0,
        "time": 0.1732652187347412,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.026921485923457958,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 284,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 220.73553158673474,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.04182586230245123
        },
        "cost": 1.2512991776817342,
        "time": 0.2153928279876709,
        "additional_info": {
            "duration": 0.20548391342163086,
            "num_run": 230,
            "train_loss": 1.1785242342401536,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011142763705649336,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1597
        },
        "cost": 0.0,
        "time": 0.1353590488433838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 309
        },
        "cost": 0.0,
        "time": 0.10497498512268066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.09291580644559985,
            "feature_preprocessor:kitchen_sinks:n_components": 1017
        },
        "cost": 0.0,
        "time": 0.11130905151367188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 5.6389139910087565,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2385168672925835,
        "time": 0.16023683547973633,
        "additional_info": {
            "duration": 0.15078210830688477,
            "num_run": 234,
            "train_loss": 1.2240958392216823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2656223513460865,
        "time": 0.7594759464263916,
        "additional_info": {
            "duration": 0.7461280822753906,
            "num_run": 235,
            "train_loss": 1.1427102795106328,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05290882589191002,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 245,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 831,
            "feature_preprocessor:kernel_pca:coef0": -0.026537602190066067
        },
        "cost": 0.0,
        "time": 0.22385406494140625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21034879180960664,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7450114739615445,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0966805948769145,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1338,
            "feature_preprocessor:kernel_pca:gamma": 2.2727438272821354
        },
        "cost": 0.0,
        "time": 0.17525196075439453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007288462989492308,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1260,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 71.16801904165708,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.251353370732262,
        "time": 0.30620789527893066,
        "additional_info": {
            "duration": 0.28556013107299805,
            "num_run": 238,
            "train_loss": 1.150788686024229,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.043872356414795,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1311
        },
        "cost": 0.0,
        "time": 0.1056063175201416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9881090248386122,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2535378156745558,
        "time": 0.22329998016357422,
        "additional_info": {
            "duration": 0.2083277702331543,
            "num_run": 241,
            "train_loss": 1.1637832455830774,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1094
        },
        "cost": 1.229569449779817,
        "time": 0.3772621154785156,
        "additional_info": {
            "duration": 0.3586852550506592,
            "num_run": 242,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8925219865149008,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227493390938579,
        "time": 0.22627592086791992,
        "additional_info": {
            "duration": 0.2089850902557373,
            "num_run": 243,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 22,
            "feature_preprocessor:kernel_pca:gamma": 0.06293545138407561
        },
        "cost": 0.0,
        "time": 0.17833590507507324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 344,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2551336710388403,
        "time": 0.34476804733276367,
        "additional_info": {
            "duration": 0.32524704933166504,
            "num_run": 245,
            "train_loss": 1.179985906737899,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1549,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.08613250651900758,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2622138684154056,
        "time": 0.23462200164794922,
        "additional_info": {
            "duration": 0.2121410369873047,
            "num_run": 246,
            "train_loss": 1.1832633421014005,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1042,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3063781261444092,
        "additional_info": {
            "duration": 0.2797257900238037,
            "num_run": 247,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004185701344639246,
            "feature_preprocessor:kitchen_sinks:gamma": 0.9370597125876488,
            "feature_preprocessor:kitchen_sinks:n_components": 443
        },
        "cost": 0.0,
        "time": 0.15699291229248047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.836066580640915,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06276207919583097,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1143
        },
        "cost": 0.0,
        "time": 0.14653301239013672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2221174350273543,
        "time": 4.169634103775024,
        "additional_info": {
            "duration": 4.1459009647369385,
            "num_run": 250,
            "train_loss": 1.2290599888022766,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0047293679846988155,
            "feature_preprocessor:kitchen_sinks:gamma": 0.06563760352037656,
            "feature_preprocessor:kitchen_sinks:n_components": 7482
        },
        "cost": 0.0,
        "time": 0.13296198844909668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016904638615498424,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6553930914137138,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2609900301866572,
        "time": 0.25884222984313965,
        "additional_info": {
            "duration": 0.24788689613342285,
            "num_run": 252,
            "train_loss": 1.1725068953399918,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 1.0237554731170622,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 2.116647585103374e-05
        },
        "cost": 1.265250533970189,
        "time": 0.16723394393920898,
        "additional_info": {
            "duration": 0.15717697143554688,
            "num_run": 253,
            "train_loss": 1.168454093880652,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1307
        },
        "cost": 0.0,
        "time": 0.16692614555358887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07478773530015763,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1556
        },
        "cost": 0.0,
        "time": 0.10653114318847656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003976250544336193,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 24
        },
        "cost": 0.0,
        "time": 0.10591602325439453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.719360875314279,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.25976599219827,
        "time": 0.23632121086120605,
        "additional_info": {
            "duration": 0.2258129119873047,
            "num_run": 257,
            "train_loss": 1.1797827393526665,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03964351564378932,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1309,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 263,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2718505278698007,
        "time": 0.4201211929321289,
        "additional_info": {
            "duration": 0.40447092056274414,
            "num_run": 258,
            "train_loss": 1.1744367658970496,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2713701246332088,
        "time": 9.383416891098022,
        "additional_info": {
            "duration": 9.366883039474487,
            "num_run": 259,
            "train_loss": 1.162347695286559,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04983398663445821,
            "feature_preprocessor:kitchen_sinks:gamma": 0.017340234792152704,
            "feature_preprocessor:kitchen_sinks:n_components": 236
        },
        "cost": 0.0,
        "time": 0.13484859466552734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 69.34646682631204,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.17914891242980957,
        "additional_info": {
            "duration": 0.1633291244506836,
            "num_run": 261,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 652,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.7661416266588075,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2475188773751555,
        "time": 0.26244592666625977,
        "additional_info": {
            "duration": 0.2452869415283203,
            "num_run": 262,
            "train_loss": 1.1872009616655823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.257635740306504,
        "time": 0.29576802253723145,
        "additional_info": {
            "duration": 0.2834188938140869,
            "num_run": 263,
            "train_loss": 1.1652374476021417,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11117900924743901,
            "feature_preprocessor:pca:keep_variance": 0.5290055651898341,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2433038341065217,
        "time": 0.30513811111450195,
        "additional_info": {
            "duration": 0.28864097595214844,
            "num_run": 264,
            "train_loss": 1.2339489454424457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013653042289649822,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3436770439147949,
        "additional_info": {
            "duration": 0.3258638381958008,
            "num_run": 265,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013444081390775145,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9051539897918701,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022685858119462327,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2564660951282833,
        "time": 0.4786090850830078,
        "additional_info": {
            "duration": 0.46765804290771484,
            "num_run": 267,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2713701246332088,
        "time": 0.3519160747528076,
        "additional_info": {
            "duration": 0.3295249938964844,
            "num_run": 268,
            "train_loss": 1.162347695286559,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.031829180655312976,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7152912135847498,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29083532317249544,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 599
        },
        "cost": 0.0,
        "time": 0.10786318778991699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014945304914257064,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9731080532073975,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009280111057047912,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.265994168721984,
        "time": 0.4748268127441406,
        "additional_info": {
            "duration": 0.45166802406311035,
            "num_run": 271,
            "train_loss": 1.1773265182126322,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.13401293754577637,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 46, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 720, in fit\n    self._fit_transform(X, compute_sources=False)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 647, in _fit_transform\n    W, n_iter = _ica_par(X1, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 118, in _ica_par\n    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 61, in _sym_decorrelation\n    s, u = linalg.eigh(np.dot(W, W.T))\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/scipy/linalg/_decomp.py\", line 460, in eigh\n    a1 = _asarray_validated(a, check_finite=check_finite)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/scipy/_lib/_util.py\", line 240, in _asarray_validated\n    a = toarray(a)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/numpy/lib/function_base.py\", line 627, in asarray_chkfinite\n    raise ValueError(\nValueError: array must not contain infs or NaNs\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 49, in fit\n    raise ValueError(\nValueError: Bug in scikit-learn: https://github.com/scikit-learn/scikit-learn/pull/2738\n",
            "error": "ValueError('Bug in scikit-learn: https://github.com/scikit-learn/scikit-learn/pull/2738')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019500591561756587,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3411750793457031,
        "additional_info": {
            "duration": 0.32831382751464844,
            "num_run": 273,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25848606803210256,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 78,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.229569449779817,
        "time": 0.27719879150390625,
        "additional_info": {
            "duration": 0.26570701599121094,
            "num_run": 274,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.134340761387712,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2517793811586873,
        "time": 3.744319200515747,
        "additional_info": {
            "duration": 3.7180440425872803,
            "num_run": 275,
            "train_loss": 1.1732278686256632,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15228481113754713,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9036132703083306,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2696116901173402,
        "time": 0.23800110816955566,
        "additional_info": {
            "duration": 0.22689509391784668,
            "num_run": 276,
            "train_loss": 1.2017041160536617,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.273500176765336,
        "time": 1.4170129299163818,
        "additional_info": {
            "duration": 1.3969628810882568,
            "num_run": 277,
            "train_loss": 1.1814550497143252,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9051378429704162,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.054793534538888425,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 315
        },
        "cost": 0.0,
        "time": 0.1467139720916748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.273500176765336,
        "time": 1.6330780982971191,
        "additional_info": {
            "duration": 1.6171667575836182,
            "num_run": 279,
            "train_loss": 1.1814550497143252,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002764310274768541,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.918341875076294,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9267138999099428,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17344222772613974,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.041146235416794186,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0027271805548135814
        },
        "cost": 1.2708897213966166,
        "time": 0.18709135055541992,
        "additional_info": {
            "duration": 0.1749570369720459,
            "num_run": 281,
            "train_loss": 1.189200165990169,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011232023547236916,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.36918139457702637,
        "additional_info": {
            "duration": 0.35079288482666016,
            "num_run": 282,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015907247636747146,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1675,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 16.252879897437328,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2284085371372262,
        "time": 0.2755570411682129,
        "additional_info": {
            "duration": 0.2640829086303711,
            "num_run": 283,
            "train_loss": 1.1934636053134222,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009284608824482758,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.6593279838562012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20820159951002687,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1651,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.229569449779817,
        "time": 0.24802207946777344,
        "additional_info": {
            "duration": 0.23488283157348633,
            "num_run": 285,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 274,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2564660951282833,
        "time": 0.3714461326599121,
        "additional_info": {
            "duration": 0.3601419925689697,
            "num_run": 286,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021294155832160387,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3580617904663086,
        "additional_info": {
            "duration": 0.3398551940917969,
            "num_run": 287,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7002707268420351,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20072691354896957,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 153
        },
        "cost": 0.0,
        "time": 0.11079287528991699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0017935973011979217,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2683874523693144,
        "time": 0.630281925201416,
        "additional_info": {
            "duration": 0.6125860214233398,
            "num_run": 289,
            "train_loss": 1.1723709133145752,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8960514838203142,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21363381231839326,
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 389,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.266791996524307,
        "time": 0.318845272064209,
        "additional_info": {
            "duration": 0.30504584312438965,
            "num_run": 290,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19418818975112698,
            "feature_preprocessor:kitchen_sinks:gamma": 5.8088283306640995e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 1666
        },
        "cost": 0.0,
        "time": 0.10691475868225098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007714572090538513,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.2595899105072021,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00220921582413494,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2764830487888688,
        "time": 0.7476198673248291,
        "additional_info": {
            "duration": 0.7339718341827393,
            "num_run": 293,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004621588936275349,
            "feature_preprocessor:kitchen_sinks:n_components": 88
        },
        "cost": 0.0,
        "time": 0.1368260383605957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008089505494253978,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3726019859313965,
        "additional_info": {
            "duration": 0.3605213165283203,
            "num_run": 295,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013624382111035034,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9290428161621094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005000909296671782,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 19,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2921847063364784,
        "time": 0.24190211296081543,
        "additional_info": {
            "duration": 0.23245000839233398,
            "num_run": 297,
            "train_loss": 1.1843384057550832,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.7643612302995231,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2581159437834573,
        "time": 0.2436668872833252,
        "additional_info": {
            "duration": 0.2247929573059082,
            "num_run": 298,
            "train_loss": 1.1839235263020806,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003134870189391249,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005324204884669082,
            "feature_preprocessor:kitchen_sinks:n_components": 392
        },
        "cost": 0.0,
        "time": 0.13326811790466309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0409600734710693,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036305611064932444,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9712169170379639,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004235370952252653,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9816756248474121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010769393605502956,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7652926921520795,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2987604609294966
        },
        "cost": 1.264715937683069,
        "time": 0.23499298095703125,
        "additional_info": {
            "duration": 0.21112704277038574,
            "num_run": 303,
            "train_loss": 1.1667609833887347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 3485,
            "feature_preprocessor:nystroem_sampler:gamma": 3.117844052045456e-05
        },
        "cost": 1.229569449779817,
        "time": 0.32512617111206055,
        "additional_info": {
            "duration": 0.27155208587646484,
            "num_run": 304,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 8.521538474896582e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 196
        },
        "cost": 0.0,
        "time": 0.13346004486083984,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07075130572525778,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.985977337232333,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.01840537116032466,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2675356312761021,
        "time": 0.2711317539215088,
        "additional_info": {
            "duration": 0.2556769847869873,
            "num_run": 306,
            "train_loss": 1.141459244876801,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006477329295051358,
            "feature_preprocessor:select_rates_classification:alpha": 0.15890348900932658,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.19905805587768555,
        "additional_info": {
            "duration": 0.18954801559448242,
            "num_run": 307,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01126312483640723,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9357049465179443,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003509832976690721,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8371181488037109,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005149364878368002,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7928781509399414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029972364336245057,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3389778137207031,
        "additional_info": {
            "duration": 0.32109880447387695,
            "num_run": 311,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014070111868473794,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 2.1774508953094482,
        "additional_info": {
            "duration": 2.1500067710876465,
            "num_run": 312,
            "train_loss": 1.2282574263013553,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.5775396842211971,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2433038341065217,
        "time": 0.20392560958862305,
        "additional_info": {
            "duration": 0.18488407135009766,
            "num_run": 313,
            "train_loss": 1.2339489454424457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023901343440942222,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2429864095407905,
        "time": 0.28259873390197754,
        "additional_info": {
            "duration": 0.2592182159423828,
            "num_run": 314,
            "train_loss": 1.1886071671493048,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011088811530563535,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 8.754297044627327,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0001498712437618597
        },
        "cost": 1.2676984101873245,
        "time": 0.1911780834197998,
        "additional_info": {
            "duration": 0.18126296997070312,
            "num_run": 315,
            "train_loss": 1.155616853579407,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8203315958768453,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2643983133576993,
        "time": 0.19427204132080078,
        "additional_info": {
            "duration": 0.18343901634216309,
            "num_run": 316,
            "train_loss": 1.20045308141983,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015391138832728694,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.355787992477417,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002844158139067095,
            "feature_preprocessor:kitchen_sinks:n_components": 2524
        },
        "cost": 0.0,
        "time": 0.17089319229125977,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.334805965423584,
        "additional_info": {
            "duration": 0.3196990489959717,
            "num_run": 319,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0036543665404048307,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.3210270404815674,
        "additional_info": {
            "duration": 0.3095271587371826,
            "num_run": 320,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00015545841428056935,
            "feature_preprocessor:kitchen_sinks:gamma": 6.637115611422428e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 79
        },
        "cost": 0.0,
        "time": 0.1288912296295166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9950556755065918,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01396773917992022,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.118927001953125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 2278.924837438762,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0037691899165308443
        },
        "cost": 1.2468840282436935,
        "time": 0.19199490547180176,
        "additional_info": {
            "duration": 0.18219685554504395,
            "num_run": 324,
            "train_loss": 1.1893836074489992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.968735933303833,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02081112551134226,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9642488956451416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2684962379896476,
        "time": 0.516845703125,
        "additional_info": {
            "duration": 0.5040497779846191,
            "num_run": 327,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8230020538873285,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21194431626385563,
            "feature_preprocessor:select_percentile_classification:percentile": 6.753193316728971,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.19027113914489746,
        "additional_info": {
            "duration": 0.1802051067352295,
            "num_run": 328,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010254369030102018,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0252232551574707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00661665704121506,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9306161403656006,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9721777439117432,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002292104876894758,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 633
        },
        "cost": 0.0,
        "time": 0.16099119186401367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012480280366402464,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9242470264434814,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.5052599906921387,
        "additional_info": {
            "duration": 0.48879098892211914,
            "num_run": 334,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 744
        },
        "cost": 0.0,
        "time": 0.11493396759033203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9941980838775635,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9057037830352783,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 412,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1757
        },
        "cost": 0.0,
        "time": 0.13216304779052734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005338312963511098,
            "feature_preprocessor:select_percentile_classification:percentile": 41.58281660732804,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2527943806823991,
        "time": 0.22362184524536133,
        "additional_info": {
            "duration": 0.21413302421569824,
            "num_run": 339,
            "train_loss": 1.1807004837487458,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8862533109549511,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27283703336256987,
            "feature_preprocessor:kitchen_sinks:gamma": 4.960701523085915e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 7810
        },
        "cost": 0.0,
        "time": 0.14833998680114746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2492773118910239,
        "time": 3.8589229583740234,
        "additional_info": {
            "duration": 3.848158121109009,
            "num_run": 341,
            "train_loss": 1.1753966476555744,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9855220317840576,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012825197927361079,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.1272201538085938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0040791823825920065,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.1269102096557617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005003434988360542,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.079390048980713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2713701246332088,
        "time": 0.21199584007263184,
        "additional_info": {
            "duration": 0.19754481315612793,
            "num_run": 346,
            "train_loss": 1.162347695286559,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 183
        },
        "cost": 0.0,
        "time": 0.17868399620056152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06277060299696094,
            "feature_preprocessor:select_percentile_classification:percentile": 88.1675606958669,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2572639229306064,
        "time": 0.21859312057495117,
        "additional_info": {
            "duration": 0.20112109184265137,
            "num_run": 348,
            "train_loss": 1.163368366130075,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1220
        },
        "cost": 0.0,
        "time": 0.15363788604736328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.031685965752249814,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.078850269317627,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008520567700173083,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.986990213394165,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.28664219555745507,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2566859722137451,
        "additional_info": {
            "duration": 0.2376079559326172,
            "num_run": 352,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004006162063260352,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1585
        },
        "cost": 0.0,
        "time": 0.11392569541931152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012451301062266953,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.23506474494934082,
        "additional_info": {
            "duration": 0.21996808052062988,
            "num_run": 354,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8532809381343265,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29684685753046697,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00013815839966180293,
            "feature_preprocessor:kitchen_sinks:n_components": 315
        },
        "cost": 0.0,
        "time": 0.1094062328338623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9146227836608887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002501098260747378,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9877221158713563,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2588710304572235,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 1.3901506477562622,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.052935780218922535
        },
        "cost": 1.260029223713473,
        "time": 0.1583399772644043,
        "additional_info": {
            "duration": 0.14836478233337402,
            "num_run": 357,
            "train_loss": 1.1806188945334959,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3463228536015662
        },
        "cost": 1.273500176765336,
        "time": 0.22624802589416504,
        "additional_info": {
            "duration": 0.21167707443237305,
            "num_run": 358,
            "train_loss": 1.1814550497143252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011884521897836812,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 978,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2718505278698007,
        "time": 1.2108917236328125,
        "additional_info": {
            "duration": 1.1957151889801025,
            "num_run": 359,
            "train_loss": 1.1744367658970496,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0412030220031738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.03983573815537585,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2373474218740017,
        "time": 0.1549849510192871,
        "additional_info": {
            "duration": 0.14477992057800293,
            "num_run": 361,
            "train_loss": 1.1891799029618384,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021567378719407977,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 275,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.6138881327281874,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.2890799045562744,
        "additional_info": {
            "duration": 0.27150893211364746,
            "num_run": 362,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004936084883732247
        },
        "cost": 1.2254717249075073,
        "time": 0.229295015335083,
        "additional_info": {
            "duration": 0.2157750129699707,
            "num_run": 363,
            "train_loss": 1.220424324535437,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00044496756994036926,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 346
        },
        "cost": 0.0,
        "time": 0.1324176788330078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.813308031503451,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20600131333345492,
            "feature_preprocessor:pca:keep_variance": 0.9483504642636891,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.226695563136256,
        "time": 0.22756314277648926,
        "additional_info": {
            "duration": 0.20783591270446777,
            "num_run": 365,
            "train_loss": 1.2323374241657783,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010153781678371549,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9259219169616699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 4050,
            "feature_preprocessor:nystroem_sampler:coef0": -0.27645175880643236,
            "feature_preprocessor:nystroem_sampler:gamma": 0.05019192867780222
        },
        "cost": 1.229569449779817,
        "time": 0.28617382049560547,
        "additional_info": {
            "duration": 0.27269482612609863,
            "num_run": 367,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016904430040372197,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 2.381463014859291,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.030014296893633587
        },
        "cost": 1.229569449779817,
        "time": 0.18702483177185059,
        "additional_info": {
            "duration": 0.1774280071258545,
            "num_run": 368,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9784340858459473,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 380,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 813.6131659871655,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.002039318247382257
        },
        "cost": 1.229569449779817,
        "time": 0.24238896369934082,
        "additional_info": {
            "duration": 0.23238086700439453,
            "num_run": 370,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.07116582259013268,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2307932880085655,
        "time": 0.22587299346923828,
        "additional_info": {
            "duration": 0.2139289379119873,
            "num_run": 371,
            "train_loss": 1.2146992127144385,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.93196702003479,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 94,
            "feature_preprocessor:nystroem_sampler:coef0": -0.26740526761123906,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0021327508923993407
        },
        "cost": 1.229569449779817,
        "time": 0.24416780471801758,
        "additional_info": {
            "duration": 0.2257521152496338,
            "num_run": 373,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1826,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 768,
            "feature_preprocessor:kernel_pca:coef0": -0.6721252981853716
        },
        "cost": 0.0,
        "time": 0.1781291961669922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.196627 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.196627 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0696351528167725,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.229569449779817,
        "time": 0.2236158847808838,
        "additional_info": {
            "duration": 0.21104693412780762,
            "num_run": 376,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005440679153840402,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0745699405670166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011932442590908742,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9232141971588135,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 15,
            "feature_preprocessor:kernel_pca:coef0": -0.5566469603549928
        },
        "cost": 0.0,
        "time": 0.12865304946899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.3766096078138581,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.229569449779817,
        "time": 0.2042698860168457,
        "additional_info": {
            "duration": 0.18977904319763184,
            "num_run": 380,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03042407765402131,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9460129737854004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016736068106244416,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0245020389556885,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002889029541994146,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7197499591978355,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21583847534812822,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 11,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.263809324260413,
        "time": 0.3080921173095703,
        "additional_info": {
            "duration": 0.26046323776245117,
            "num_run": 383,
            "train_loss": 1.2168466545121626,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.263918109880746,
        "time": 0.28582191467285156,
        "additional_info": {
            "duration": 0.26372694969177246,
            "num_run": 384,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.054607671722769764,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9073973569997875,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.298425341676487,
            "feature_preprocessor:select_rates_classification:alpha": 0.4261510502047407,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.229569449779817,
        "time": 0.23253703117370605,
        "additional_info": {
            "duration": 0.2158489227294922,
            "num_run": 385,
            "train_loss": 1.2290327923971933,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.5312729107931159,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.22140288352966309,
        "additional_info": {
            "duration": 0.19214320182800293,
            "num_run": 386,
            "train_loss": 1.231059193126863,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003835746843492789,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9083971977233887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8914802074432373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013101234101708194,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2564660951282833,
        "time": 0.6822919845581055,
        "additional_info": {
            "duration": 0.6698789596557617,
            "num_run": 389,
            "train_loss": 1.1719346966293862,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3730091431987107,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1266
        },
        "cost": 0.0,
        "time": 0.11417126655578613,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003679312191267228,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9107321367599046,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19245590145483296,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.262639878841831,
        "time": 0.4239521026611328,
        "additional_info": {
            "duration": 0.4055900573730469,
            "num_run": 391,
            "train_loss": 1.1667609833887347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 27.64079444146798,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2600836165236395,
        "time": 0.15943217277526855,
        "additional_info": {
            "duration": 0.14971208572387695,
            "num_run": 392,
            "train_loss": 1.1914569305101546,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.266048361772512,
        "time": 0.4897420406341553,
        "additional_info": {
            "duration": 0.47447705268859863,
            "num_run": 393,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0451209545135498,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006350927865838661,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 1250,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00011232510608091194
        },
        "cost": 1.2388342918583146,
        "time": 0.28028368949890137,
        "additional_info": {
            "duration": 0.26491880416870117,
            "num_run": 395,
            "train_loss": 1.2197305476548488,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012889060317420667,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9181592464447021,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02236102334610214,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9137890338897705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.31217086249821996,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 398,
            "feature_preprocessor:kernel_pca:coef0": 0.3958180347864988
        },
        "cost": 0.0,
        "time": 0.31497883796691895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.0229813 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.0229813 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2564660951282833,
        "time": 0.2322549819946289,
        "additional_info": {
            "duration": 0.2179718017578125,
            "num_run": 399,
            "train_loss": 1.1719346966293862,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 968,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2406556519603407,
        "time": 0.3905038833618164,
        "additional_info": {
            "duration": 0.36728882789611816,
            "num_run": 400,
            "train_loss": 1.1697931140045583,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015100603601244713,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.5458261966705322,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1384,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 98.5965095170953,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 7.312124408286704e-05
        },
        "cost": 1.229569449779817,
        "time": 0.19654321670532227,
        "additional_info": {
            "duration": 0.18682026863098145,
            "num_run": 402,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0066338360180638505,
            "feature_preprocessor:pca:keep_variance": 0.9223520051051141,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2693482588424985,
        "time": 0.22099804878234863,
        "additional_info": {
            "duration": 0.20623207092285156,
            "num_run": 403,
            "train_loss": 1.1736624740050678,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008880562159842908,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0096499919891357,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0853271484375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 646,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 2.899323368233605,
            "feature_preprocessor:kitchen_sinks:n_components": 1545
        },
        "cost": 0.0,
        "time": 0.21396923065185547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7547499796700616,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06068413446652009,
            "feature_preprocessor:kitchen_sinks:gamma": 0.09415687521787064,
            "feature_preprocessor:kitchen_sinks:n_components": 972
        },
        "cost": 0.0,
        "time": 0.17899179458618164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008017129103834342,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.913330078125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9537839889526367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012931005920365033,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.1423711776733398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19139724811739292,
            "feature_preprocessor:select_rates_classification:alpha": 0.45537690625674554,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2292063649395493,
        "time": 0.19591307640075684,
        "additional_info": {
            "duration": 0.1852271556854248,
            "num_run": 411,
            "train_loss": 1.1914644009888355,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05351044051697784,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.4685778617858887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01627046253230462,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0176756381988525,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0009592700031185964,
            "feature_preprocessor:kitchen_sinks:n_components": 70
        },
        "cost": 0.0,
        "time": 0.11214303970336914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00024256645653260425,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2775437085871175,
        "time": 0.23869705200195312,
        "additional_info": {
            "duration": 0.22288107872009277,
            "num_run": 415,
            "train_loss": 1.1968093002405962,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 584
        },
        "cost": 0.0,
        "time": 0.14075899124145508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001456916862601853,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1488,
            "feature_preprocessor:kernel_pca:coef0": -0.9667364196167367,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.00995013449935639
        },
        "cost": 0.0,
        "time": 0.21524691581726074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.0685248 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.0685248 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9284718036651611,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.004105671451394596,
            "feature_preprocessor:kitchen_sinks:n_components": 533
        },
        "cost": 0.0,
        "time": 0.14015793800354004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003733822631826889,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.232839822769165,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007714572090538513,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.8050851821899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011755280716235713,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9496810436248779,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9925341606140137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008678399359883873,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 71
        },
        "cost": 1.229569449779817,
        "time": 0.2314300537109375,
        "additional_info": {
            "duration": 0.21222400665283203,
            "num_run": 424,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.48466016394707356,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.255505488414738,
        "time": 0.18409204483032227,
        "additional_info": {
            "duration": 0.1658768653869629,
            "num_run": 425,
            "train_loss": 1.1598456260188956,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0931312842491159,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1538,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 41.27497582204742,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.253909832810092,
        "time": 0.22576403617858887,
        "additional_info": {
            "duration": 0.21550798416137695,
            "num_run": 426,
            "train_loss": 1.1708137848480744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1725
        },
        "cost": 0.0,
        "time": 0.1127469539642334,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0549790859222412,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 744
        },
        "cost": 0.0,
        "time": 0.10558700561523438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002476437349966582,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0668790340423584,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003501011972436497,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 528,
            "feature_preprocessor:kernel_pca:gamma": 6.499742181482373e-05
        },
        "cost": 0.0,
        "time": 0.16102194786071777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3412604972823596,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7944627930034003,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.02993365610265214,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 1555,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0021187491824681843
        },
        "cost": 1.229569449779817,
        "time": 0.2973451614379883,
        "additional_info": {
            "duration": 0.28478312492370605,
            "num_run": 432,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02013904215118764,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7068526269479887,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2665183809243211,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2555594817056273,
        "time": 0.43898487091064453,
        "additional_info": {
            "duration": 0.4273250102996826,
            "num_run": 433,
            "train_loss": 1.169508357404076,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08049537267091098,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2747244145133618,
        "time": 0.6833090782165527,
        "additional_info": {
            "duration": 0.655238151550293,
            "num_run": 434,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 929
        },
        "cost": 0.0,
        "time": 0.13868403434753418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9050028324127197,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 802,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.6651824847239534,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2375645935953905,
        "time": 0.26917386054992676,
        "additional_info": {
            "duration": 0.2577519416809082,
            "num_run": 437,
            "train_loss": 1.1911247144762585,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005478294990071922,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.10087498930786325,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.006548775827682993
        },
        "cost": 1.2509815533563644,
        "time": 0.1835179328918457,
        "additional_info": {
            "duration": 0.17318296432495117,
            "num_run": 438,
            "train_loss": 1.187676630203576,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9308133199979525,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.23754382133483887,
        "additional_info": {
            "duration": 0.2258589267730713,
            "num_run": 439,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009991866149696084,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 292,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 592
        },
        "cost": 0.0,
        "time": 0.16570496559143066,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 11.206466498445646,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2547535206465905,
        "time": 0.1837780475616455,
        "additional_info": {
            "duration": 0.17338299751281738,
            "num_run": 441,
            "train_loss": 1.211285258223592,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20666240133028485,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7407185089607283,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22561386929297522,
            "feature_preprocessor:select_percentile_classification:percentile": 8.549604542275642,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2431493882116518,
        "time": 0.20052289962768555,
        "additional_info": {
            "duration": 0.1896209716796875,
            "num_run": 442,
            "train_loss": 1.2170988926365935,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13389996487719596,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0173418521881104,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0033339392434953746,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 765
        },
        "cost": 0.0,
        "time": 0.1444840431213379,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015059945186372,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9201631546020508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01765490693783316,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9368000030517578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 193,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229569449779817,
        "time": 0.30910372734069824,
        "additional_info": {
            "duration": 0.28147196769714355,
            "num_run": 447,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00593939579048185,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0014307708967959381,
            "feature_preprocessor:kitchen_sinks:n_components": 362
        },
        "cost": 0.0,
        "time": 0.13765501976013184,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013273238348735536,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2387800988077866,
        "time": 0.2300889492034912,
        "additional_info": {
            "duration": 0.21612191200256348,
            "num_run": 449,
            "train_loss": 1.1823247975750628,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.30365477561168536,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0485551357269287,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01660906268315125,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7041076674305192,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13983097747935497,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00016317909652145904,
            "feature_preprocessor:kitchen_sinks:n_components": 234
        },
        "cost": 0.0,
        "time": 0.1079709529876709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016491751828241828,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8932640552520752,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8366467374281992,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.015518634473608819
        },
        "cost": 1.2684962379896476,
        "time": 0.24063611030578613,
        "additional_info": {
            "duration": 0.227370023727417,
            "num_run": 453,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03782744092563435
        },
        "cost": 1.2564660951282833,
        "time": 0.2031259536743164,
        "additional_info": {
            "duration": 0.1901848316192627,
            "num_run": 454,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 849,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.2819336060196528,
            "feature_preprocessor:kitchen_sinks:n_components": 8961
        },
        "cost": 0.0,
        "time": 0.13821697235107422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002226671913969585,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.079429864883423,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012682086687727993,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9191038608551025,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.046031191779490846,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1317,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 7010,
            "feature_preprocessor:nystroem_sampler:coef0": -0.16460602948243364,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.03590594137348016
        },
        "cost": 1.2770176450759887,
        "time": 0.397050142288208,
        "additional_info": {
            "duration": 0.38394999504089355,
            "num_run": 458,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.064299795301578,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2509815533563644,
        "time": 0.7996988296508789,
        "additional_info": {
            "duration": 0.785297155380249,
            "num_run": 459,
            "train_loss": 1.1857926077741474,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039928629566510747,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.2582493662114572,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.240864690425016,
        "time": 0.22086811065673828,
        "additional_info": {
            "duration": 0.21001195907592773,
            "num_run": 460,
            "train_loss": 1.1801432259955023,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 44.99693875475532,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.229569449779817,
        "time": 0.3034176826477051,
        "additional_info": {
            "duration": 0.23023724555969238,
            "num_run": 461,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011713701352113113,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2713701246332088,
        "time": 0.21262097358703613,
        "additional_info": {
            "duration": 0.20127415657043457,
            "num_run": 462,
            "train_loss": 1.0680624948834887,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0364453792572021,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3393664651228645,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1766
        },
        "cost": 0.0,
        "time": 0.14332890510559082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12844778873930623,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9563271999359131,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0032874208545685766,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1191,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.18106717177926893,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.2972588539123535,
        "additional_info": {
            "duration": 0.2876911163330078,
            "num_run": 466,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.263918109880746,
        "time": 0.2564380168914795,
        "additional_info": {
            "duration": 0.24223995208740234,
            "num_run": 467,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0034013880029085818,
            "feature_preprocessor:kitchen_sinks:gamma": 2.550451227517683,
            "feature_preprocessor:kitchen_sinks:n_components": 1034
        },
        "cost": 0.0,
        "time": 0.10701203346252441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008553916017804102,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 3980
        },
        "cost": 1.2580615509732906,
        "time": 0.32384586334228516,
        "additional_info": {
            "duration": 0.30914306640625,
            "num_run": 469,
            "train_loss": 1.1707321956328245,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 71.25763847753252,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2750960321296205,
        "time": 0.24312615394592285,
        "additional_info": {
            "duration": 0.23054289817810059,
            "num_run": 470,
            "train_loss": 1.1828212662433149,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018378545667747787,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9504079818725586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012830232244683798,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7972624279833949,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10720324007810866,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.47716145896734585,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2087634008525383,
        "time": 0.21875619888305664,
        "additional_info": {
            "duration": 0.20725798606872559,
            "num_run": 472,
            "train_loss": 1.185739289167837,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10501622156139442,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.965507984161377,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.861793041229248,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 565,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00019854675079696742,
            "feature_preprocessor:kitchen_sinks:n_components": 71
        },
        "cost": 0.0,
        "time": 0.16495585441589355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1214,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.2646615448729026,
        "time": 0.2461249828338623,
        "additional_info": {
            "duration": 0.2266981601715088,
            "num_run": 476,
            "train_loss": 1.1805916981284126,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.3174216747283936,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 66.49368043442753,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.229569449779817,
        "time": 0.20173192024230957,
        "additional_info": {
            "duration": 0.1853928565979004,
            "num_run": 478,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007113035086197391,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 261
        },
        "cost": 0.0,
        "time": 0.14114904403686523,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009128235960465471,
            "feature_preprocessor:pca:keep_variance": 0.8567048999495834,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2433038341065217,
        "time": 0.2122201919555664,
        "additional_info": {
            "duration": 0.19362926483154297,
            "num_run": 480,
            "train_loss": 1.2339489454424457,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03745081186630902,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1213,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00020379564583175374,
            "feature_preprocessor:kitchen_sinks:n_components": 1142
        },
        "cost": 0.0,
        "time": 0.16884922981262207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20390562590729636,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7518858909606934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05185093769689147,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 160.1037422768686,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.023471706824612887
        },
        "cost": 1.2455972644287874,
        "time": 0.15468907356262207,
        "additional_info": {
            "duration": 0.14480113983154297,
            "num_run": 483,
            "train_loss": 1.1895675860097574,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 7.427042160764884,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 6.464380185919939e-05
        },
        "cost": 1.263066089027895,
        "time": 0.17192506790161133,
        "additional_info": {
            "duration": 0.16146516799926758,
            "num_run": 484,
            "train_loss": 1.1752542693553332,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.912904041835672,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2865714867334166,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1337,
            "feature_preprocessor:kernel_pca:coef0": 0.9731830119824676,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.002158081882587215
        },
        "cost": 0.0,
        "time": 0.15006494522094727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.018940067047484604,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8830690383911133,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00014275448724340015,
            "feature_preprocessor:kitchen_sinks:n_components": 920
        },
        "cost": 0.0,
        "time": 0.13190293312072754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 322.09507458883917,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 1.121915069512042e-05
        },
        "cost": 1.2468840282436935,
        "time": 0.16174578666687012,
        "additional_info": {
            "duration": 0.15226006507873535,
            "num_run": 488,
            "train_loss": 1.1893836074489992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04751052832131809,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.869431734085083,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.041489402985854275,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7636222714588269,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08430937583130672,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9027988234501678,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2645531587718466,
        "time": 0.301239013671875,
        "additional_info": {
            "duration": 0.2572309970855713,
            "num_run": 490,
            "train_loss": 1.2069535593366665,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 139
        },
        "cost": 1.261044223237185,
        "time": 0.31339502334594727,
        "additional_info": {
            "duration": 0.2963101863861084,
            "num_run": 491,
            "train_loss": 1.167291044736895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0017101407635427095,
            "feature_preprocessor:kitchen_sinks:n_components": 879
        },
        "cost": 0.0,
        "time": 0.13578104972839355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 466,
            "feature_preprocessor:kernel_pca:gamma": 0.0031640665974681428
        },
        "cost": 0.0,
        "time": 0.29960107803344727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 4.043700583763887,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 3.89407917761271e-05
        },
        "cost": 1.229569449779817,
        "time": 0.16149091720581055,
        "additional_info": {
            "duration": 0.1518421173095703,
            "num_run": 494,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.820445348873014,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05476726046213186
        },
        "cost": 1.266791996524307,
        "time": 0.2076280117034912,
        "additional_info": {
            "duration": 0.19144082069396973,
            "num_run": 495,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1254,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 490,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0068569172728594864
        },
        "cost": 1.2250999075316098,
        "time": 0.3662722110748291,
        "additional_info": {
            "duration": 0.34885573387145996,
            "num_run": 496,
            "train_loss": 1.0250073630250573,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1175,
            "feature_preprocessor:kernel_pca:coef0": 0.09214044870500882
        },
        "cost": 0.0,
        "time": 0.1838669776916504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005581387444654498,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.913817882537842,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001110687407943838,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1981,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 42,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2481076667128033,
        "time": 0.3406717777252197,
        "additional_info": {
            "duration": 0.3240382671356201,
            "num_run": 499,
            "train_loss": 1.179740601990221,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009852440586207356,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1198
        },
        "cost": 0.0,
        "time": 0.14113903045654297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16015885774438385,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.0714969635009766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02976466177556016,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7037573352564014,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.001794217270354441,
            "feature_preprocessor:kitchen_sinks:gamma": 0.040535179988808435,
            "feature_preprocessor:kitchen_sinks:n_components": 89
        },
        "cost": 0.0,
        "time": 0.10778594017028809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10009526618797471,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.0000221729278564,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007380990181156488,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.9654359817504883,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02325715036056925,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1901,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.002559417487876258,
            "feature_preprocessor:kitchen_sinks:n_components": 2140
        },
        "cost": 0.0,
        "time": 0.17908596992492676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3526210949276615,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1720,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2593399817718445,
        "time": 2.12180495262146,
        "additional_info": {
            "duration": 2.105665922164917,
            "num_run": 506,
            "train_loss": 1.1829908409486394,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021258519948933285,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.916710918868694,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18706284443658022
        },
        "cost": 1.264715937683069,
        "time": 0.21984577178955078,
        "additional_info": {
            "duration": 0.20132112503051758,
            "num_run": 507,
            "train_loss": 1.1667609833887347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04773364385606823,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8207067374117153,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10015630370205678
        },
        "cost": 1.2684962379896476,
        "time": 0.22014117240905762,
        "additional_info": {
            "duration": 0.20352673530578613,
            "num_run": 508,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.04076265689394368,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.232125911857647,
        "time": 0.1638779640197754,
        "additional_info": {
            "duration": 0.1542971134185791,
            "num_run": 509,
            "train_loss": 1.2155897607054345,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 26.64260024378742,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 1.3302328937192697e-05
        },
        "cost": 1.229569449779817,
        "time": 0.17360806465148926,
        "additional_info": {
            "duration": 0.16406512260437012,
            "num_run": 510,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.036705308252993424,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.42202782376581915,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2521970585687603,
        "time": 0.27057814598083496,
        "additional_info": {
            "duration": 0.25982213020324707,
            "num_run": 511,
            "train_loss": 1.2251559619180028,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001263439380278843
        },
        "cost": 1.2683874523693144,
        "time": 0.17374897003173828,
        "additional_info": {
            "duration": 0.1594407558441162,
            "num_run": 512,
            "train_loss": 1.1723709133145752,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.274569768858853,
        "time": 0.24808287620544434,
        "additional_info": {
            "duration": 0.23741817474365234,
            "num_run": 513,
            "train_loss": 1.0237563283912257,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016589014323749818,
            "feature_preprocessor:kitchen_sinks:gamma": 0.003877593739202318,
            "feature_preprocessor:kitchen_sinks:n_components": 1537
        },
        "cost": 0.0,
        "time": 0.13569998741149902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019464954568198377,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2702004794549882,
        "time": 0.4419372081756592,
        "additional_info": {
            "duration": 0.4287281036376953,
            "num_run": 515,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7217628955841064,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2684962379896476,
        "time": 0.4138059616088867,
        "additional_info": {
            "duration": 0.40201687812805176,
            "num_run": 517,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 36.057599373252806,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.3050208102568792,
        "time": 0.23112797737121582,
        "additional_info": {
            "duration": 0.2213609218597412,
            "num_run": 518,
            "train_loss": 1.2054300235500737,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003597052019668963,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2564660951282833,
        "time": 0.8952178955078125,
        "additional_info": {
            "duration": 0.8707852363586426,
            "num_run": 519,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00028836226939514233,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9376836952068683,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15847176543908512
        },
        "cost": 1.2684962379896476,
        "time": 0.2133800983428955,
        "additional_info": {
            "duration": 0.19878101348876953,
            "num_run": 520,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0694743929086227,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.23162603378295898,
        "additional_info": {
            "duration": 0.2184891700744629,
            "num_run": 521,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03124030973546571,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1723,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00010391276532837471,
            "feature_preprocessor:kitchen_sinks:n_components": 9661
        },
        "cost": 0.0,
        "time": 0.14656805992126465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1389
        },
        "cost": 0.0,
        "time": 0.17690610885620117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009962346304947837,
            "feature_preprocessor:select_rates_classification:alpha": 0.2170574699495342,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2484794840887008,
        "time": 0.23476791381835938,
        "additional_info": {
            "duration": 0.21519160270690918,
            "num_run": 524,
            "train_loss": 1.1595470026649075,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3157633936376843,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8029949917458065,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2140159541387647
        },
        "cost": 1.2684962379896476,
        "time": 0.23669219017028809,
        "additional_info": {
            "duration": 0.22545385360717773,
            "num_run": 525,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 60,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229569449779817,
        "time": 0.3391602039337158,
        "additional_info": {
            "duration": 0.31426191329956055,
            "num_run": 526,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04745930245194842,
            "feature_preprocessor:pca:keep_variance": 0.6999842706867163,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2392061092342121,
        "time": 0.23401212692260742,
        "additional_info": {
            "duration": 0.2183079719543457,
            "num_run": 527,
            "train_loss": 1.2315348616648567,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03965518234894216,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.4396579265594482,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017814084723595386,
            "feature_preprocessor:select_percentile_classification:percentile": 43.200519207566494,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.239532266335573,
        "time": 0.22640585899353027,
        "additional_info": {
            "duration": 0.2110133171081543,
            "num_run": 529,
            "train_loss": 1.16464659716899,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16705913829300784,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8728953411746885,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05094181108721101,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00011949312449466154,
            "feature_preprocessor:kitchen_sinks:n_components": 3790
        },
        "cost": 0.0,
        "time": 0.11234688758850098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8863072395324707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004742430077322541,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8936378955841064,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011083892137120738,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.3990399837493896,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008032111642818631,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2509815533563644,
        "time": 3.2023260593414307,
        "additional_info": {
            "duration": 3.188974142074585,
            "num_run": 534,
            "train_loss": 1.1857926077741474,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06327991381479367,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1435,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1073,
            "feature_preprocessor:kernel_pca:coef0": 0.663326736619672
        },
        "cost": 0.0,
        "time": 0.30681800842285156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 373,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.18045092766860815,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.25735998153686523,
        "additional_info": {
            "duration": 0.24776291847229004,
            "num_run": 536,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007252921973899235,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.2565889358520508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1331,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 54,
            "feature_preprocessor:nystroem_sampler:coef0": 0.5582600366053352,
            "feature_preprocessor:nystroem_sampler:gamma": 2.574707191408737
        },
        "cost": 1.229569449779817,
        "time": 0.3079030513763428,
        "additional_info": {
            "duration": 0.23227405548095703,
            "num_run": 538,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 809,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 279,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2718505278698007,
        "time": 0.40137600898742676,
        "additional_info": {
            "duration": 0.3906381130218506,
            "num_run": 539,
            "train_loss": 1.1744367658970496,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 640,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2718505278698007,
        "time": 0.3460121154785156,
        "additional_info": {
            "duration": 0.3314540386199951,
            "num_run": 540,
            "train_loss": 1.1744367658970496,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.4150400161743164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008091461551536798,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8545849323272705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1972
        },
        "cost": 0.0,
        "time": 0.12690186500549316,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012443270579720868,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.1763279438018799,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009273874263907564,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.1527390480041504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06638418710486725,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.7000057697296143,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07814970913580152,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.2272827625274658,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15293766123325606,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 4.403511570091169,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.004239167588440201
        },
        "cost": 1.2468840282436935,
        "time": 0.15828394889831543,
        "additional_info": {
            "duration": 0.14844799041748047,
            "num_run": 548,
            "train_loss": 1.1893836074489992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.07272333427933175,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.09729372814963484
        },
        "cost": 1.229569449779817,
        "time": 0.2136979103088379,
        "additional_info": {
            "duration": 0.2039632797241211,
            "num_run": 549,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0063800921733122,
            "feature_preprocessor:select_rates_classification:alpha": 0.31288369198224225,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2747786075638896,
        "time": 0.2023618221282959,
        "additional_info": {
            "duration": 0.18993115425109863,
            "num_run": 550,
            "train_loss": 1.164850838758079,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016435104892361115,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1216,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6436838443879356,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2654898166656494,
        "additional_info": {
            "duration": 0.2535061836242676,
            "num_run": 551,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1739,
            "feature_preprocessor:kernel_pca:coef0": 0.23997801676616426,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.0024561342679822206
        },
        "cost": 0.0,
        "time": 0.229644775390625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8657550811767578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.055758483485941125,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 867,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 162,
            "feature_preprocessor:nystroem_sampler:coef0": -0.6629987040060441,
            "feature_preprocessor:nystroem_sampler:gamma": 0.02790724078271485
        },
        "cost": 1.229569449779817,
        "time": 0.28411436080932617,
        "additional_info": {
            "duration": 0.2634119987487793,
            "num_run": 554,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023616962171277223,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 90
        },
        "cost": 0.0,
        "time": 0.1117238998413086,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0569148063659668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014253043689881632,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1014
        },
        "cost": 0.0,
        "time": 0.10854315757751465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009400259772059248,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 149,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2676984101873245,
        "time": 0.3063180446624756,
        "additional_info": {
            "duration": 0.28792381286621094,
            "num_run": 558,
            "train_loss": 1.1740304311265848,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 432
        },
        "cost": 0.0,
        "time": 0.13368606567382812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 11
        },
        "cost": 0.0,
        "time": 0.1311659812927246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00037838872999966733,
            "feature_preprocessor:pca:keep_variance": 0.9056887266848148,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2647701307335968,
        "time": 0.22992205619812012,
        "additional_info": {
            "duration": 0.21931791305541992,
            "num_run": 561,
            "train_loss": 1.1792116148459173,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012161178626725918,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9292000551152529,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09397367227277822,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 607,
            "feature_preprocessor:nystroem_sampler:gamma": 1.3755746038602708
        },
        "cost": 1.229569449779817,
        "time": 0.28021812438964844,
        "additional_info": {
            "duration": 0.2556023597717285,
            "num_run": 562,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07579097434293532,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0621709823608398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.23910585638987,
        "time": 0.3489978313446045,
        "additional_info": {
            "duration": 0.33624815940856934,
            "num_run": 564,
            "train_loss": 1.1698416476418285,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21908295909833264,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1704
        },
        "cost": 0.0,
        "time": 0.10484814643859863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08836121361335278,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1903,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.274887193424584,
        "time": 0.29370713233947754,
        "additional_info": {
            "duration": 0.27568602561950684,
            "num_run": 566,
            "train_loss": 1.0534105659203434,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1469,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1955,
            "feature_preprocessor:kernel_pca:gamma": 0.648600429046298
        },
        "cost": 0.0,
        "time": 0.22304368019104004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010369811431166337,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.782412052154541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0794617047284633,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.305143117904663,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010426556025223632,
            "feature_preprocessor:pca:keep_variance": 0.8089087005282436,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227493390938579,
        "time": 0.19030475616455078,
        "additional_info": {
            "duration": 0.17690300941467285,
            "num_run": 570,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9841255011145471,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15782200411196012,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.253212257852111,
        "time": 0.7646310329437256,
        "additional_info": {
            "duration": 0.7524020671844482,
            "num_run": 571,
            "train_loss": 1.1686450058181634,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.6984933064858646,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0012816275807946637
        },
        "cost": 1.229569449779817,
        "time": 0.21403813362121582,
        "additional_info": {
            "duration": 0.1941838264465332,
            "num_run": 572,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005135836645484888,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.897165060043335,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008148927359586006,
            "feature_preprocessor:pca:keep_variance": 0.7061400444620355,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2362865623161143,
        "time": 0.24396324157714844,
        "additional_info": {
            "duration": 0.23183107376098633,
            "num_run": 574,
            "train_loss": 1.1956867771534998,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1693
        },
        "cost": 0.0,
        "time": 0.16317415237426758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021581589223946502,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7516307830810547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 767
        },
        "cost": 0.0,
        "time": 0.13919615745544434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000960599461433062,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1862,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 29,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.229569449779817,
        "time": 0.34125590324401855,
        "additional_info": {
            "duration": 0.3284311294555664,
            "num_run": 578,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.80627744415745,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.012678202642872678,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 149
        },
        "cost": 0.0,
        "time": 0.10833287239074707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8599844585517467,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11018294578963804,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.1353139877319336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009312524437361091,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9373080410144365,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2773265975593768,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 206
        },
        "cost": 0.0,
        "time": 0.13463306427001953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.6875119209289551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1094,
            "feature_preprocessor:kernel_pca:coef0": -0.9884426639679298,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.012779168749339024
        },
        "cost": 0.0,
        "time": 0.13342976570129395,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47499164728854515,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 182,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2534836226240278,
        "time": 0.3442041873931885,
        "additional_info": {
            "duration": 0.32527709007263184,
            "num_run": 584,
            "train_loss": 1.172955367472902,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038875231128961865,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7671020030975342,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1142,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1264
        },
        "cost": 0.0,
        "time": 0.13621926307678223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.7443935229687781,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2392061092342121,
        "time": 0.23994684219360352,
        "additional_info": {
            "duration": 0.22759771347045898,
            "num_run": 587,
            "train_loss": 1.22900559599211,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11127486276637413,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2304214706326677,
        "time": 0.34766697883605957,
        "additional_info": {
            "duration": 0.3326730728149414,
            "num_run": 588,
            "train_loss": 1.1555416606389817,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011893392715237308,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 114,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.217700851235023,
            "feature_preprocessor:kitchen_sinks:n_components": 84
        },
        "cost": 0.0,
        "time": 0.15601515769958496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0025758049324205896,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1725
        },
        "cost": 0.0,
        "time": 0.1702432632446289,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 533,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2558771060309968,
        "time": 0.36428213119506836,
        "additional_info": {
            "duration": 0.3509831428527832,
            "num_run": 591,
            "train_loss": 1.1814550497143252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.09890987754377915,
            "feature_preprocessor:kitchen_sinks:n_components": 536
        },
        "cost": 0.0,
        "time": 0.1985318660736084,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1510,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 77.90836954290667,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.263120282078423,
        "time": 0.2801988124847412,
        "additional_info": {
            "duration": 0.26546573638916016,
            "num_run": 593,
            "train_loss": 1.1746820706447276,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 190,
            "feature_preprocessor:nystroem_sampler:coef0": -0.8416234423021807,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 2.6606674219850053
        },
        "cost": 1.254390236046684,
        "time": 0.2666759490966797,
        "additional_info": {
            "duration": 0.2073678970336914,
            "num_run": 594,
            "train_loss": 1.0855668727171246,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.755079984664917,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 349,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2564660951282833,
        "time": 0.3202071189880371,
        "additional_info": {
            "duration": 0.30842018127441406,
            "num_run": 596,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025196067817661802,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9020118713378906,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01851452884545409,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7700976850197977,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.27228178593915436,
            "feature_preprocessor:pca:keep_variance": 0.7969840810180583,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.20669198036193848,
        "additional_info": {
            "duration": 0.19028806686401367,
            "num_run": 598,
            "train_loss": 1.2286451093492743,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009995065732596752,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 11
        },
        "cost": 0.0,
        "time": 0.14358186721801758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04798268283622092,
            "feature_preprocessor:select_rates_classification:alpha": 0.3204991163332177,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.18475008010864258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005540346586002969,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.9951770305633545,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004785249695520343,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00046959920587209624,
            "feature_preprocessor:kitchen_sinks:n_components": 7490
        },
        "cost": 0.0,
        "time": 0.13827013969421387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012661793304490992,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.644644737243652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01898397996085966,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.21576189994812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9581376979301446,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.30739688873291016,
        "additional_info": {
            "duration": 0.29688119888305664,
            "num_run": 605,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00350760936667324,
            "feature_preprocessor:kitchen_sinks:gamma": 0.001675938173699781,
            "feature_preprocessor:kitchen_sinks:n_components": 1046
        },
        "cost": 0.0,
        "time": 0.10691094398498535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8549115154492632,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29128035814970604,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 150
        },
        "cost": 0.0,
        "time": 0.11588811874389648,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.710783958435059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.96570514844822,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.009920222824271463,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1241,
            "feature_preprocessor:kernel_pca:coef0": -0.8068669836431899,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 9.003715655712712e-05
        },
        "cost": 0.0,
        "time": 0.19075727462768555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.0773546 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.0773546 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003252653696023603,
            "feature_preprocessor:pca:keep_variance": 0.7262067772168278,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.28361082077026367,
        "additional_info": {
            "duration": 0.2679562568664551,
            "num_run": 610,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040130838907811653,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1264
        },
        "cost": 0.0,
        "time": 0.15108609199523926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011169629866055231,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.904401779174805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 940,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 113
        },
        "cost": 0.0,
        "time": 0.16773509979248047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013778189656618397
        },
        "cost": 1.2564660951282833,
        "time": 0.24609112739562988,
        "additional_info": {
            "duration": 0.23351287841796875,
            "num_run": 614,
            "train_loss": 1.173573414311137,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021368374825642873,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1473
        },
        "cost": 0.0,
        "time": 0.13847708702087402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17945261267272086,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17983933882801584,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2392146420102033,
        "time": 0.21413493156433105,
        "additional_info": {
            "duration": 0.20315289497375488,
            "num_run": 616,
            "train_loss": 1.190825016918414,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 9.213740553177006e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3535
        },
        "cost": 0.0,
        "time": 0.13574600219726562,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00035331072533374767,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 542
        },
        "cost": 0.0,
        "time": 0.11754703521728516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 436
        },
        "cost": 0.0,
        "time": 0.10816001892089844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2842118155658091,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.637211799621582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002860653376201465,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 46.41707373600207,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 6.269115861489452e-05
        },
        "cost": 1.2581078105267436,
        "time": 0.1616499423980713,
        "additional_info": {
            "duration": 0.1489250659942627,
            "num_run": 621,
            "train_loss": 1.1820608411048388,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2684962379896476,
        "time": 1.126142978668213,
        "additional_info": {
            "duration": 1.111854076385498,
            "num_run": 622,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 364,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 504
        },
        "cost": 0.0,
        "time": 0.1718738079071045,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00034598271971139654,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1651,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1736
        },
        "cost": 0.0,
        "time": 0.14731311798095703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 278,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.004449249019045309,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.240864690425016,
        "time": 0.27779388427734375,
        "additional_info": {
            "duration": 0.26723313331604004,
            "num_run": 625,
            "train_loss": 1.1850593790407546,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.880056036442942,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19625993361752722,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.23113398086050996,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2392146420102033,
        "time": 0.23322820663452148,
        "additional_info": {
            "duration": 0.22184205055236816,
            "num_run": 626,
            "train_loss": 1.190437333870495,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7324064577607106,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08788785822586333,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 370
        },
        "cost": 0.0,
        "time": 0.1383380889892578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 283,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.229569449779817,
        "time": 0.3527641296386719,
        "additional_info": {
            "duration": 0.3338198661804199,
            "num_run": 628,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06930112255233521,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.45253138550458194,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.24701189994812012,
        "additional_info": {
            "duration": 0.23589611053466797,
            "num_run": 629,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002518934945612048,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.79516653294306,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07913740064697206,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 936
        },
        "cost": 0.0,
        "time": 0.1349470615386963,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.997997394963615,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1297436350103674,
            "feature_preprocessor:pca:keep_variance": 0.6132871503506131,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227493390938579,
        "time": 0.23148632049560547,
        "additional_info": {
            "duration": 0.21927094459533691,
            "num_run": 631,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 870,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1181
        },
        "cost": 0.0,
        "time": 0.17214179039001465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038108415805241845,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8314703127236467,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08140372029593813,
            "feature_preprocessor:kitchen_sinks:gamma": 0.3894898024256933,
            "feature_preprocessor:kitchen_sinks:n_components": 758
        },
        "cost": 0.0,
        "time": 0.10970711708068848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038621785057020665,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 1.0674550533294678,
        "additional_info": {
            "duration": 1.0553350448608398,
            "num_run": 634,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7680631992276589,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2646359361444135,
            "feature_preprocessor:kitchen_sinks:gamma": 0.028957870973141,
            "feature_preprocessor:kitchen_sinks:n_components": 532
        },
        "cost": 0.0,
        "time": 0.1709461212158203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02639191916467524,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 84,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1872,
            "feature_preprocessor:kernel_pca:coef0": -0.46230591918510733
        },
        "cost": 0.0,
        "time": 0.234483003616333,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.106841087341309,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000771489778819133,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 607
        },
        "cost": 0.0,
        "time": 0.13345694541931152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18861443337358028,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.560257911682129,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7137495844202381,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2503277810436546,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 3985,
            "feature_preprocessor:nystroem_sampler:coef0": -0.14556913259611148,
            "feature_preprocessor:nystroem_sampler:gamma": 1.8505569973233973
        },
        "cost": 1.2477819091307198,
        "time": 0.7123730182647705,
        "additional_info": {
            "duration": 0.6987321376800537,
            "num_run": 640,
            "train_loss": 1.1769601723968999,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011262921862077927
        },
        "cost": 1.229569449779817,
        "time": 0.34832096099853516,
        "additional_info": {
            "duration": 0.32190990447998047,
            "num_run": 641,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009720151582003678,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 188,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 891,
            "feature_preprocessor:kernel_pca:coef0": -0.3559730176255207
        },
        "cost": 0.0,
        "time": 0.45756077766418457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.226499 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.226499 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 139
        },
        "cost": 0.0,
        "time": 0.13837099075317383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008474789189080094,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.461100101470947,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.47657579741410816,
            "feature_preprocessor:kitchen_sinks:gamma": 0.002465921401135064,
            "feature_preprocessor:kitchen_sinks:n_components": 6456
        },
        "cost": 0.0,
        "time": 0.16233015060424805,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010246453733321975,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7885079897050747,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19272341091703654,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.21561972379424788,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.26114773750305176,
        "additional_info": {
            "duration": 0.24957990646362305,
            "num_run": 646,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6117759281121277,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.21442604064941406,
        "additional_info": {
            "duration": 0.1944441795349121,
            "num_run": 647,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01932808660353107,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.43483825595847647,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2233119010925293,
        "additional_info": {
            "duration": 0.2124648094177246,
            "num_run": 648,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033562382999352935,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.587916851043701,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1378,
            "feature_preprocessor:kernel_pca:coef0": -0.8635653399461669
        },
        "cost": 0.0,
        "time": 0.21090197563171387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.132406 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.132406 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6813315841572735,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2576899333570317,
        "time": 0.2315819263458252,
        "additional_info": {
            "duration": 0.20634007453918457,
            "num_run": 651,
            "train_loss": 1.1839235263020806,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 72
        },
        "cost": 1.229569449779817,
        "time": 0.26500391960144043,
        "additional_info": {
            "duration": 0.24703168869018555,
            "num_run": 652,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 56,
            "feature_preprocessor:kernel_pca:gamma": 0.003982411146443424
        },
        "cost": 0.0,
        "time": 0.2221698760986328,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06334517166505105,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1669,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 614
        },
        "cost": 0.0,
        "time": 0.14404511451721191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0384888711941867,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.913641929626465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.1366466487620706,
            "feature_preprocessor:kitchen_sinks:n_components": 79
        },
        "cost": 0.0,
        "time": 0.1637730598449707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028675882325762568,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.265676744156253,
        "time": 1.029181957244873,
        "additional_info": {
            "duration": 1.0166120529174805,
            "num_run": 657,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003439827084876366,
            "feature_preprocessor:select_rates_classification:alpha": 0.19037465796195938,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.229569449779817,
        "time": 0.1812131404876709,
        "additional_info": {
            "duration": 0.17133331298828125,
            "num_run": 658,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9555165853069378,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13466551898494086,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.266791996524307,
        "time": 1.413865327835083,
        "additional_info": {
            "duration": 1.4031939506530762,
            "num_run": 659,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012735473349151304,
            "feature_preprocessor:select_rates_classification:alpha": 0.04374791086501585,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2430408023509572,
        "time": 0.15448307991027832,
        "additional_info": {
            "duration": 0.1451430320739746,
            "num_run": 660,
            "train_loss": 1.2227146817353305,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.029276525442632737,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 723,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1761
        },
        "cost": 0.0,
        "time": 0.16688323020935059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004771474058853427,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8180124330306021,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1528692560620611,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 22
        },
        "cost": 0.0,
        "time": 0.14336824417114258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09595914238493984,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0029296345060796755,
            "feature_preprocessor:kitchen_sinks:n_components": 734
        },
        "cost": 0.0,
        "time": 0.10672283172607422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001965021357554923,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.181153059005737,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2702004794549882,
        "time": 0.19539880752563477,
        "additional_info": {
            "duration": 0.17335987091064453,
            "num_run": 665,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005324206338380718,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.889049768447876,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 163
        },
        "cost": 0.0,
        "time": 0.1353590488433838,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000402702552303451
        },
        "cost": 1.2554508958449326,
        "time": 0.21188616752624512,
        "additional_info": {
            "duration": 0.200361967086792,
            "num_run": 668,
            "train_loss": 1.1772870663598276,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003370634058141542,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.606281995773315,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 14.13379260221966,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2437383773089383,
        "time": 0.1989901065826416,
        "additional_info": {
            "duration": 0.1889972686767578,
            "num_run": 670,
            "train_loss": 1.2207149403088158,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0067917437190631565,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 330,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.265994168721984,
        "time": 0.37992191314697266,
        "additional_info": {
            "duration": 0.36396026611328125,
            "num_run": 671,
            "train_loss": 1.1773265182126322,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021158217341965716,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.453675985336304,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.25083677575226226,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9326767566266911,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.012687161457321513,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2569925581586896,
        "time": 1.0609989166259766,
        "additional_info": {
            "duration": 1.0482730865478516,
            "num_run": 673,
            "train_loss": 1.1670334845414958,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 1.5714781284332275,
        "additional_info": {
            "duration": 1.5597949028015137,
            "num_run": 674,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.19919157425776735,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.24352002143859863,
        "additional_info": {
            "duration": 0.23212599754333496,
            "num_run": 675,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 116,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229569449779817,
        "time": 0.2990121841430664,
        "additional_info": {
            "duration": 0.27670884132385254,
            "num_run": 676,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019261095892571217,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 1.3151211738586426,
        "additional_info": {
            "duration": 1.2995939254760742,
            "num_run": 677,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2073605197960936,
            "feature_preprocessor:kitchen_sinks:gamma": 0.007046591356745406,
            "feature_preprocessor:kitchen_sinks:n_components": 7704
        },
        "cost": 0.0,
        "time": 0.13939929008483887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001861835440352367,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1251
        },
        "cost": 0.0,
        "time": 0.10821199417114258,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.2802700996398926,
        "additional_info": {
            "duration": 0.2686920166015625,
            "num_run": 680,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007835013424882865,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1094,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2701462864044601,
        "time": 0.40502190589904785,
        "additional_info": {
            "duration": 0.3894791603088379,
            "num_run": 681,
            "train_loss": 1.1727980482152989,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06590066258693013,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 45,
            "feature_preprocessor:kernel_pca:coef0": 0.3828933858269228,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 4.789063440914542e-05
        },
        "cost": 0.0,
        "time": 0.20901083946228027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 48.06755990231817,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.246349232196935,
        "time": 0.24737310409545898,
        "additional_info": {
            "duration": 0.23534107208251953,
            "num_run": 683,
            "train_loss": 1.1607708408936561,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.850471862528092,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12183782205415773,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2274389981284124,
        "time": 0.44483089447021484,
        "additional_info": {
            "duration": 0.42334890365600586,
            "num_run": 684,
            "train_loss": 1.2076750697242662,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.471113920211792,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1035
        },
        "cost": 0.0,
        "time": 0.16875314712524414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19647697603765538,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.065551996231079,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010582161569052636,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.858006000518799,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.49127801367496504,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.19632792472839355,
        "additional_info": {
            "duration": 0.18619298934936523,
            "num_run": 689,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 40
        },
        "cost": 0.0,
        "time": 0.10879993438720703,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023323778789663234,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 255,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.251353370732262,
        "time": 0.3530550003051758,
        "additional_info": {
            "duration": 0.3372530937194824,
            "num_run": 691,
            "train_loss": 1.1654491596699117,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1789
        },
        "cost": 0.0,
        "time": 0.25283026695251465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043741635663740334,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.879015922546387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.301689147949219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9453365199254928,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0074139433681715316,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 22,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2706264898814135,
        "time": 0.33884096145629883,
        "additional_info": {
            "duration": 0.31452107429504395,
            "num_run": 695,
            "train_loss": 1.185739289167837,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 114
        },
        "cost": 0.0,
        "time": 0.1395571231842041,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 158,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2702004794549882,
        "time": 0.26583218574523926,
        "additional_info": {
            "duration": 0.2537050247192383,
            "num_run": 697,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.3867727049903441,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.229569449779817,
        "time": 0.21309471130371094,
        "additional_info": {
            "duration": 0.19404387474060059,
            "num_run": 698,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04413237487789064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 340,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 958
        },
        "cost": 0.0,
        "time": 0.1667647361755371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13704079075931194,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 335,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2564660951282833,
        "time": 0.2927119731903076,
        "additional_info": {
            "duration": 0.2781410217285156,
            "num_run": 700,
            "train_loss": 1.1719346966293862,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.091631889343262,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.28229566437675163,
            "feature_preprocessor:kitchen_sinks:n_components": 467
        },
        "cost": 0.0,
        "time": 0.11311006546020508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013543329174789964,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.363945007324219,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1175,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8976473056720649,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.3155632019042969,
        "additional_info": {
            "duration": 0.3039207458496094,
            "num_run": 704,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01697634632402034,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.822798252105713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9519737005313009,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07141735348217387,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1859,
            "feature_preprocessor:kernel_pca:coef0": 0.5583937480578418,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.0010898996874718896
        },
        "cost": 0.0,
        "time": 0.17643308639526367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8788335494183872,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2066185786883734,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 934,
            "feature_preprocessor:kernel_pca:coef0": -0.9833415864607111
        },
        "cost": 0.0,
        "time": 0.17218375205993652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.147337 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.147337 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8819639198222771,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06406620480740553,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.269983507493238,
        "time": 0.4461781978607178,
        "additional_info": {
            "duration": 0.43328094482421875,
            "num_run": 708,
            "train_loss": 1.1457301546787353,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07863907072897998,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 343,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2702004794549882,
        "time": 0.3217458724975586,
        "additional_info": {
            "duration": 0.3058738708496094,
            "num_run": 709,
            "train_loss": 1.1685420793707266,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02542288602754012,
            "feature_preprocessor:pca:keep_variance": 0.6836805288940245,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.20932412147521973,
        "additional_info": {
            "duration": 0.1880199909210205,
            "num_run": 710,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005760969624349777,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.303952017201917,
        "time": 0.31935715675354004,
        "additional_info": {
            "duration": 0.3087120056152344,
            "num_run": 711,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9210832292893048,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28443029526452346,
            "feature_preprocessor:select_percentile_classification:percentile": 74.20771890110467,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2592857887213165,
        "time": 0.2133650779724121,
        "additional_info": {
            "duration": 0.19626116752624512,
            "num_run": 712,
            "train_loss": 1.1717043328390704,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0049823506154098056,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 605,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 365
        },
        "cost": 0.0,
        "time": 0.15929603576660156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.032649993896484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02081112551134226,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.891803979873657,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 700,
            "feature_preprocessor:nystroem_sampler:gamma": 5.802652641930181e-05
        },
        "cost": 1.229569449779817,
        "time": 0.30681395530700684,
        "additional_info": {
            "duration": 0.2924048900604248,
            "num_run": 716,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1612
        },
        "cost": 0.0,
        "time": 0.13682913780212402,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3975,
            "feature_preprocessor:nystroem_sampler:coef0": -0.507713333703681,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00013270767754368698
        },
        "cost": 1.229569449779817,
        "time": 0.2710142135620117,
        "additional_info": {
            "duration": 0.2544369697570801,
            "num_run": 718,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.32524193661619294,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.65132212638855,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.5559575323802045,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2789307252463658,
        "time": 0.23714494705200195,
        "additional_info": {
            "duration": 0.21762371063232422,
            "num_run": 720,
            "train_loss": 1.1821968231302553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001653888972694722,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2509815533563644,
        "time": 4.7961297035217285,
        "additional_info": {
            "duration": 4.782974004745483,
            "num_run": 721,
            "train_loss": 1.1857926077741474,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1114,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.6156442848542817,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.256837912504181,
        "time": 0.24566221237182617,
        "additional_info": {
            "duration": 0.23365092277526855,
            "num_run": 722,
            "train_loss": 1.2018811612376672,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.173575162887573,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000321823785040965,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.2048199918001521,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.021020206898260643
        },
        "cost": 1.2698286620790906,
        "time": 0.24997663497924805,
        "additional_info": {
            "duration": 0.24080204963684082,
            "num_run": 724,
            "train_loss": 1.1663125112558244,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8625994535396494,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05061472534356995,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 236
        },
        "cost": 0.0,
        "time": 0.11273479461669922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8323051747831156,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2677897828257843
        },
        "cost": 1.264715937683069,
        "time": 0.2122211456298828,
        "additional_info": {
            "duration": 0.20134878158569336,
            "num_run": 726,
            "train_loss": 1.1667609833887347,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1436,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1214,
            "feature_preprocessor:kernel_pca:coef0": -0.9192515180163687
        },
        "cost": 0.0,
        "time": 0.4610729217529297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.169585 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.169585 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.757190227508545,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011805048364433158,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.216758966445923,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 160,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 39.94402131395918,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2425689318903563,
        "time": 0.18964481353759766,
        "additional_info": {
            "duration": 0.1792280673980713,
            "num_run": 730,
            "train_loss": 1.1840115117921552,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019175737989702438,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.2521090507507324,
        "additional_info": {
            "duration": 0.23417115211486816,
            "num_run": 731,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 566,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2537007943454168,
        "time": 1.1181256771087646,
        "additional_info": {
            "duration": 1.1007728576660156,
            "num_run": 732,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1190
        },
        "cost": 0.0,
        "time": 0.11287593841552734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017583727590364154,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.523823976516724,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 770
        },
        "cost": 0.0,
        "time": 0.13088703155517578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03414661151841412,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.19484281539917,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010861523903948251,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.8731348514556885,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014109085704658384,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.333817005157471,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0038228717745981203,
            "feature_preprocessor:pca:keep_variance": 0.699067384625228,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.21513009071350098,
        "additional_info": {
            "duration": 0.19436907768249512,
            "num_run": 739,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012550483777368827,
            "feature_preprocessor:kitchen_sinks:gamma": 7.365693971355628e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 59
        },
        "cost": 0.0,
        "time": 0.11640214920043945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009824145936759636,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.5492379665374756,
        "additional_info": {
            "duration": 0.535531759262085,
            "num_run": 741,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8453730822835419,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2826504979038284,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1483,
            "feature_preprocessor:kernel_pca:coef0": -0.03699188441781298
        },
        "cost": 0.0,
        "time": 0.27921628952026367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.141276 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.141276 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8752044062487595,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.001042278294322156,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 29
        },
        "cost": 0.0,
        "time": 0.12037897109985352,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4965893735977931,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7856933670571442,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1950912777217131,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1485,
            "feature_preprocessor:kernel_pca:coef0": 0.7795897246149481,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.0005722171410601055
        },
        "cost": 0.0,
        "time": 0.17730402946472168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.257635740306504,
        "time": 0.18329977989196777,
        "additional_info": {
            "duration": 0.17010211944580078,
            "num_run": 745,
            "train_loss": 1.1652374476021417,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15628577828562193,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9403676111781487,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03069177426381354,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2208935967986059,
        "time": 0.28222203254699707,
        "additional_info": {
            "duration": 0.26620006561279297,
            "num_run": 746,
            "train_loss": 1.2076750697242662,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003893873063938209,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.035955905914307,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.203444957733154,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01281830953649864,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.966303110122681,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 67,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229569449779817,
        "time": 0.3083508014678955,
        "additional_info": {
            "duration": 0.2960178852081299,
            "num_run": 750,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2684962379896476,
        "time": 3.5106911659240723,
        "additional_info": {
            "duration": 3.4955990314483643,
            "num_run": 751,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3748360597768734,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2743525971374643,
        "time": 0.26215410232543945,
        "additional_info": {
            "duration": 0.2506890296936035,
            "num_run": 752,
            "train_loss": 1.1977393000843966,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00046869219325260716,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1987,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.23979112119429474,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.229569449779817,
        "time": 0.23057007789611816,
        "additional_info": {
            "duration": 0.22021198272705078,
            "num_run": 753,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.408748149871826,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007865416621301494
        },
        "cost": 1.2684962379896476,
        "time": 0.22280120849609375,
        "additional_info": {
            "duration": 0.20956969261169434,
            "num_run": 755,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00047384272657957546,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1540,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1999,
            "feature_preprocessor:kernel_pca:coef0": -0.15363229716283233,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 4.446233664800935
        },
        "cost": 0.0,
        "time": 0.31459808349609375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0197580075748449,
            "feature_preprocessor:kitchen_sinks:n_components": 83
        },
        "cost": 0.0,
        "time": 0.13311481475830078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0035591285128656626,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.229569449779817,
        "time": 0.258181095123291,
        "additional_info": {
            "duration": 0.2407999038696289,
            "num_run": 758,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02081112551134226,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.58174204826355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9299173724050767,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.245752339285453,
            "feature_preprocessor:pca:keep_variance": 0.7447962098310099,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.227493390938579,
        "time": 0.21862220764160156,
        "additional_info": {
            "duration": 0.20144200325012207,
            "num_run": 760,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0030292554907063005,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2897372296386203,
        "time": 0.4479951858520508,
        "additional_info": {
            "duration": 0.4359092712402344,
            "num_run": 761,
            "train_loss": 1.021729927661556,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020779955687699594,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8299397318803031,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1784627955007069,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 72
        },
        "cost": 0.0,
        "time": 0.14384102821350098,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02257032288450368,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.7479212284088135,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003416113113495683,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.851975917816162,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.3084759522602907,
        "time": 0.32007884979248047,
        "additional_info": {
            "duration": 0.309359073638916,
            "num_run": 765,
            "train_loss": 1.0233686453433066,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 24
        },
        "cost": 0.0,
        "time": 0.13741803169250488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.273500176765336,
        "time": 0.2063121795654297,
        "additional_info": {
            "duration": 0.18746423721313477,
            "num_run": 767,
            "train_loss": 1.1814550497143252,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.847728854086157,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1522503476932282,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 12
        },
        "cost": 0.0,
        "time": 0.10826420783996582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004733022182733141,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1962,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 61,
            "feature_preprocessor:nystroem_sampler:coef0": 0.14263759227454487,
            "feature_preprocessor:nystroem_sampler:gamma": 0.7247536595819808
        },
        "cost": 1.2312736912451574,
        "time": 0.28185606002807617,
        "additional_info": {
            "duration": 0.2648649215698242,
            "num_run": 769,
            "train_loss": 1.2290327923971933,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02038752707180539,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 100
        },
        "cost": 0.0,
        "time": 0.10601592063903809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.179208993911743,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003583043292223319,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.8377320766448975,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0324968535119586,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.926093101501465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1973
        },
        "cost": 0.0,
        "time": 0.13567805290222168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010521727398919064,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 171,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49851445600803634,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.3119020462036133,
        "additional_info": {
            "duration": 0.30158114433288574,
            "num_run": 775,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2997486932418837,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.966354846954346,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.050338193746320564,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1862,
            "feature_preprocessor:kernel_pca:coef0": -0.34272751356896203,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.029427915605780154
        },
        "cost": 0.0,
        "time": 0.26221275329589844,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.0470877 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.0470877 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1230343469416019,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0002465622276354121,
            "feature_preprocessor:kitchen_sinks:n_components": 387
        },
        "cost": 0.0,
        "time": 0.10683083534240723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022887026274634586
        },
        "cost": 1.2509815533563644,
        "time": 0.23113536834716797,
        "additional_info": {
            "duration": 0.2194197177886963,
            "num_run": 779,
            "train_loss": 1.1849292561882345,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021158217341965716,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 273
        },
        "cost": 0.0,
        "time": 0.11194014549255371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007530298216049263,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.501433849334717,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8788977258688042,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.015997877488123202,
            "feature_preprocessor:select_percentile_classification:percentile": 2.312875131137199,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.229569449779817,
        "time": 0.2610900402069092,
        "additional_info": {
            "duration": 0.25144410133361816,
            "num_run": 782,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08677760039243237,
            "feature_preprocessor:pca:keep_variance": 0.8423082622992073,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2530034191470745,
        "time": 0.24584674835205078,
        "additional_info": {
            "duration": 0.23342370986938477,
            "num_run": 783,
            "train_loss": 1.1829028554585648,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 17
        },
        "cost": 0.0,
        "time": 0.13457584381103516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02257032288450368,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.14673376083374,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1993
        },
        "cost": 0.0,
        "time": 0.11201000213623047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 658,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.707415263566767,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.229569449779817,
        "time": 0.26227474212646484,
        "additional_info": {
            "duration": 0.24941205978393555,
            "num_run": 787,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03157128621100166,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9351417671491569,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.028444926942373366,
            "feature_preprocessor:pca:keep_variance": 0.7326459044176332,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227493390938579,
        "time": 0.197800874710083,
        "additional_info": {
            "duration": 0.18192505836486816,
            "num_run": 788,
            "train_loss": 1.229896143983106,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9254739659479623,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.014256505138018849,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.266791996524307,
        "time": 4.764380216598511,
        "additional_info": {
            "duration": 4.7531468868255615,
            "num_run": 789,
            "train_loss": 1.1602333090668147,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 789,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08812012053374972,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 33,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2221174350273543,
        "time": 0.2939639091491699,
        "additional_info": {
            "duration": 0.27800798416137695,
            "num_run": 790,
            "train_loss": 1.2290599888022766,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 790,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01925349740482925,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 330,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1813
        },
        "cost": 0.0,
        "time": 0.14618587493896484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 791,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2191448464224903,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1710
        },
        "cost": 0.0,
        "time": 0.132918119430542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 792,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 344,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 164
        },
        "cost": 0.0,
        "time": 0.1452479362487793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 793,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.027012184706999304,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9749073136692377,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28019854511503606,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 772
        },
        "cost": 0.0,
        "time": 0.13500070571899414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 794,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4462185258324791,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 22,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 331,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2676984101873245,
        "time": 0.34885334968566895,
        "additional_info": {
            "duration": 0.3315739631652832,
            "num_run": 795,
            "train_loss": 1.1744367658970496,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 795,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.051729396308637834,
            "feature_preprocessor:select_rates_classification:alpha": 0.23545054107626648,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.240647518703627,
        "time": 0.1878218650817871,
        "additional_info": {
            "duration": 0.17775917053222656,
            "num_run": 796,
            "train_loss": 1.1889884539223992,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 796,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3280661099123563,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.801079988479614,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 797,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.893560886383057,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 798,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1360,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 64.98299054826609,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2359604052147535,
        "time": 0.2778298854827881,
        "additional_info": {
            "duration": 0.2566499710083008,
            "num_run": 799,
            "train_loss": 1.212454703642174,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 799,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.721994876861572,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 800,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 253,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2713701246332088,
        "time": 0.328402042388916,
        "additional_info": {
            "duration": 0.31386494636535645,
            "num_run": 801,
            "train_loss": 1.162347695286559,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 801,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003415979161293383,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 949
        },
        "cost": 0.0,
        "time": 0.13784313201904297,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 802,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.4683842338351502,
            "feature_preprocessor:kitchen_sinks:n_components": 483
        },
        "cost": 0.0,
        "time": 0.1356661319732666,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 803,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7126758063938223,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06816474356498299,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1815
        },
        "cost": 0.0,
        "time": 0.14373493194580078,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 804,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05284193788950114,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.18743814659958358,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.21070194244384766,
        "additional_info": {
            "duration": 0.1993260383605957,
            "num_run": 805,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 805,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023885777985360997,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8629838454089985,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20256741450431304
        },
        "cost": 1.2312736912451574,
        "time": 0.1837608814239502,
        "additional_info": {
            "duration": 0.164992094039917,
            "num_run": 806,
            "train_loss": 1.2282574263013553,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 806,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38934139628408815,
            "feature_preprocessor:select_percentile_classification:percentile": 11.128145823774819,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2497033223174494,
        "time": 0.2279820442199707,
        "additional_info": {
            "duration": 0.2184619903564453,
            "num_run": 807,
            "train_loss": 1.224046768482484,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 807,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011204765435199736,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1364,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1533
        },
        "cost": 0.0,
        "time": 0.17782902717590332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 808,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 932,
            "feature_preprocessor:nystroem_sampler:coef0": -0.3696828325189423,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.08963420233281433
        },
        "cost": 1.2378734853851303,
        "time": 0.7612659931182861,
        "additional_info": {
            "duration": 0.7459349632263184,
            "num_run": 809,
            "train_loss": 1.1719016410514063,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 809,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21201189082727992,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0025803520127072183,
            "feature_preprocessor:kitchen_sinks:n_components": 2978
        },
        "cost": 0.0,
        "time": 0.11575675010681152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 810,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2684962379896476,
        "time": 0.26128482818603516,
        "additional_info": {
            "duration": 0.244215726852417,
            "num_run": 811,
            "train_loss": 1.1618720267485656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 811,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8611598998516039,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2116047369451016,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9852029629391771,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2580617507329295,
        "time": 0.2742807865142822,
        "additional_info": {
            "duration": 0.2632780075073242,
            "num_run": 812,
            "train_loss": 1.1856774258789895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 812,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 219
        },
        "cost": 0.0,
        "time": 0.11303591728210449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 813,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015671852051571094,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1132,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 625
        },
        "cost": 0.0,
        "time": 0.17778420448303223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 814,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009586421653015475,
            "feature_preprocessor:kitchen_sinks:gamma": 4.270127874235042e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 66
        },
        "cost": 0.0,
        "time": 0.10662722587585449,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 815,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 91.94529815415062,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.229569449779817,
        "time": 0.19310903549194336,
        "additional_info": {
            "duration": 0.17920517921447754,
            "num_run": 816,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 816,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 745,
            "feature_preprocessor:nystroem_sampler:coef0": 0.7486276340717644,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 0.04445560318675228
        },
        "cost": 1.229569449779817,
        "time": 0.9251258373260498,
        "additional_info": {
            "duration": 0.9120111465454102,
            "num_run": 817,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 817,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8745267499434511,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19914444821640223,
            "feature_preprocessor:kitchen_sinks:gamma": 0.2165230348184504,
            "feature_preprocessor:kitchen_sinks:n_components": 339
        },
        "cost": 0.0,
        "time": 0.1425940990447998,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 818,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 726,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform"
        },
        "cost": 1.2481076667128033,
        "time": 0.26499414443969727,
        "additional_info": {
            "duration": 0.24879002571105957,
            "num_run": 819,
            "train_loss": 1.1706564655904712,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 819,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.78262186050415,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 820,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7572878827933113,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2532320224352401,
            "feature_preprocessor:select_rates_classification:alpha": 0.17683808190737996,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2814327945140294,
        "time": 0.2200009822845459,
        "additional_info": {
            "duration": 0.20343804359436035,
            "num_run": 821,
            "train_loss": 1.167060680946579,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 821,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08677575776969841,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.462718963623047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 822,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9232614585158032,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12020690188814401,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 25
        },
        "cost": 0.0,
        "time": 0.11659884452819824,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 823,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04424323581798182,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8135394982976174,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229569449779817,
        "time": 0.2581150531768799,
        "additional_info": {
            "duration": 0.24724674224853516,
            "num_run": 824,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 824,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02939811725924612,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 209,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.008586434155754774,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.22223455366404,
        "time": 0.29954004287719727,
        "additional_info": {
            "duration": 0.2882199287414551,
            "num_run": 825,
            "train_loss": 1.208761851723742,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 825,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2890178652696946,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.229569449779817,
        "time": 1.3354790210723877,
        "additional_info": {
            "duration": 1.3121628761291504,
            "num_run": 826,
            "train_loss": 1.2294204754451123,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 826,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2565122302024616,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1023,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0005998889282539939,
            "feature_preprocessor:kitchen_sinks:n_components": 5753
        },
        "cost": 0.0,
        "time": 0.1512608528137207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 827,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42883657603493175,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.949092149734497,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_SPD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 828,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02779121267282785,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9947789425847413,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18867078407153015,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1622
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]