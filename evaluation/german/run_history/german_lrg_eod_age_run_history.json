[
    {
        "config_id": 1,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01
        },
        "cost": 1.2483838137826997,
        "time": 0.9420228004455566,
        "additional_info": {
            "duration": 0.9326291084289551,
            "num_run": 2,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Default"
        }
    },
    {
        "config_id": 2,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06943546983792238,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 193,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 318,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2232763667785487,
        "time": 0.3353548049926758,
        "additional_info": {
            "duration": 0.3171541690826416,
            "num_run": 3,
            "train_loss": 1.1583118550859557,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 3,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19744241073972732,
            "feature_preprocessor:kitchen_sinks:gamma": 0.008038493427960746,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.13143682479858398,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 4,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005914257872015065,
            "feature_preprocessor:select_percentile_classification:percentile": 57.378373122989764,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.21635890007019043,
        "additional_info": {
            "duration": 0.2020552158355713,
            "num_run": 5,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 5,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2567812586381417,
        "time": 0.4052860736846924,
        "additional_info": {
            "duration": 0.39333391189575195,
            "num_run": 6,
            "train_loss": 1.1705220605815705,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 6,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002836249135958794,
            "feature_preprocessor:pca:keep_variance": 0.5554331431994848,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2518107017746167,
        "time": 0.18548798561096191,
        "additional_info": {
            "duration": 0.16903400421142578,
            "num_run": 7,
            "train_loss": 1.2038865945083816,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 7,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002119388709440359,
            "feature_preprocessor:pca:keep_variance": 0.8778885047995537,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2272560292224401,
        "time": 0.1862351894378662,
        "additional_info": {
            "duration": 0.1653289794921875,
            "num_run": 8,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 8,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01885721793297807,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 495.1165435342211,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.02874497201376828
        },
        "cost": 1.2383578124934744,
        "time": 0.21339178085327148,
        "additional_info": {
            "duration": 0.20446515083312988,
            "num_run": 9,
            "train_loss": 1.1806200878923505,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 9,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.29499356307409363,
            "feature_preprocessor:kitchen_sinks:gamma": 1.6375323826658983,
            "feature_preprocessor:kitchen_sinks:n_components": 450
        },
        "cost": 0.0,
        "time": 0.16275882720947266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 10,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45630629507533466,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.224060068781918,
        "time": 0.6907939910888672,
        "additional_info": {
            "duration": 0.6754360198974609,
            "num_run": 11,
            "train_loss": 1.1852811828420176,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 11,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8953675059096271,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.138715361760742,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1739
        },
        "cost": 0.0,
        "time": 0.10780906677246094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 12,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002225356922408864,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 261
        },
        "cost": 0.0,
        "time": 0.22443485260009766,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 13,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001377535218689547,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1959,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2493964327417943,
        "time": 0.36578798294067383,
        "additional_info": {
            "duration": 0.351207971572876,
            "num_run": 14,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 14,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.33060598373413086,
        "additional_info": {
            "duration": 0.3171210289001465,
            "num_run": 15,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 15,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9861051844890611,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10821014688453756,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00015172476078205405,
            "feature_preprocessor:kitchen_sinks:n_components": 5795
        },
        "cost": 0.0,
        "time": 0.13385820388793945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 16,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2305980296521821,
        "time": 0.2099161148071289,
        "additional_info": {
            "duration": 0.19635391235351562,
            "num_run": 17,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 17,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002328039701048767,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 756,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06657025075592271,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2227710625968362,
        "time": 0.27225780487060547,
        "additional_info": {
            "duration": 0.2617790699005127,
            "num_run": 18,
            "train_loss": 1.1858157367047961,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 18,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8018370860360803,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17179487174982927,
            "feature_preprocessor:kitchen_sinks:gamma": 0.04733148850198137,
            "feature_preprocessor:kitchen_sinks:n_components": 9351
        },
        "cost": 0.0,
        "time": 0.13323497772216797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 19,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2643950014902146,
        "time": 1.1335067749023438,
        "additional_info": {
            "duration": 1.1204609870910645,
            "num_run": 20,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 20,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014651560995004403,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1987,
            "feature_preprocessor:kernel_pca:gamma": 0.006153283285022424
        },
        "cost": 0.0,
        "time": 0.19836211204528809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 21,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016629582016150876,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0074490791281164636,
            "feature_preprocessor:kitchen_sinks:n_components": 5536
        },
        "cost": 0.0,
        "time": 0.13308382034301758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 22,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04047487595389383,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 2.932753324508667,
        "additional_info": {
            "duration": 2.870344877243042,
            "num_run": 23,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 23,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1554
        },
        "cost": 0.0,
        "time": 0.516171932220459,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 24,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05490299435036052,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1897,
            "feature_preprocessor:kernel_pca:coef0": 0.806601899434723
        },
        "cost": 0.0,
        "time": 0.13330316543579102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 25,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 234,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 329,
            "feature_preprocessor:kernel_pca:gamma": 0.10871870200916484
        },
        "cost": 0.0,
        "time": 0.2921600341796875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 26,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 3894,
            "feature_preprocessor:nystroem_sampler:gamma": 5.53558347375688
        },
        "cost": 1.2443035710241805,
        "time": 0.547584056854248,
        "additional_info": {
            "duration": 0.5290870666503906,
            "num_run": 27,
            "train_loss": 1.0016460599131565,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 27,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019438523789984858,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1694,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.5985235586479674,
            "feature_preprocessor:kitchen_sinks:n_components": 486
        },
        "cost": 0.0,
        "time": 0.17278599739074707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 28,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021750679316905764,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5944730435832759,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2517258142124414,
        "time": 0.2540600299835205,
        "additional_info": {
            "duration": 0.24301910400390625,
            "num_run": 29,
            "train_loss": 1.1728135082734263,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 29,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0885507718795432,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0003883410163850968,
            "feature_preprocessor:kitchen_sinks:n_components": 121
        },
        "cost": 0.0,
        "time": 0.15411710739135742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 30,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8425025030082764,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22568657126055675,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3325,
            "feature_preprocessor:nystroem_sampler:coef0": 0.83480705572558,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.03919971871878286
        },
        "cost": 1.2879805041622188,
        "time": 0.8690800666809082,
        "additional_info": {
            "duration": 0.8515408039093018,
            "num_run": 31,
            "train_loss": 1.2078468847213888,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 31,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 61,
            "feature_preprocessor:nystroem_sampler:coef0": 0.16627545276520506,
            "feature_preprocessor:nystroem_sampler:gamma": 0.25414487964192556
        },
        "cost": 1.2305980296521821,
        "time": 0.265286922454834,
        "additional_info": {
            "duration": 0.25150203704833984,
            "num_run": 32,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 32,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 399,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.228799698094048,
        "time": 0.30330896377563477,
        "additional_info": {
            "duration": 0.29222989082336426,
            "num_run": 33,
            "train_loss": 1.2189813854077607,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 33,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023415799733744764,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8772501258572116,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12058636851232067,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 127,
            "feature_preprocessor:nystroem_sampler:coef0": -0.4073600529682413,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.08880829015833379
        },
        "cost": 1.2353988113913563,
        "time": 0.37285304069519043,
        "additional_info": {
            "duration": 0.3367328643798828,
            "num_run": 34,
            "train_loss": 1.187650830099829,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 34,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7484989105733454,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12066932906443266,
            "feature_preprocessor:select_rates_classification:alpha": 0.40552486135499716,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2371122553873148,
        "time": 0.1829230785369873,
        "additional_info": {
            "duration": 0.17280197143554688,
            "num_run": 35,
            "train_loss": 1.2189259684498004,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 35,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1446,
            "feature_preprocessor:kernel_pca:gamma": 0.0014000711731137093
        },
        "cost": 0.0,
        "time": 0.15126800537109375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 36,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016761086695100329,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7939442330516276,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21297005989907575,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1138,
            "feature_preprocessor:kernel_pca:coef0": 0.9341525188139943,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.00029183484558824416
        },
        "cost": 0.0,
        "time": 0.19427180290222168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 37,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.7968971841027708,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.251409999098871,
        "time": 0.2557182312011719,
        "additional_info": {
            "duration": 0.24404406547546387,
            "num_run": 38,
            "train_loss": 1.2206828622788775,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 38,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020436603534095387,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8932504145635813,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07985165157413568,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 2.8413823449143187,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0026556450195227084
        },
        "cost": 1.2552593143059951,
        "time": 0.1834108829498291,
        "additional_info": {
            "duration": 0.17429280281066895,
            "num_run": 39,
            "train_loss": 1.2109173367158599,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 39,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 86.57939368150289,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2333023680677742,
        "time": 0.2702319622039795,
        "additional_info": {
            "duration": 0.25348997116088867,
            "num_run": 40,
            "train_loss": 1.1582564381279954,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 40,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004317041229734325,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7384900134986303,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23423585837546368,
            "feature_preprocessor:select_rates_classification:alpha": 0.31518257238931474,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2468401449110917,
        "time": 0.21585297584533691,
        "additional_info": {
            "duration": 0.2072770595550537,
            "num_run": 41,
            "train_loss": 1.1994275516737307,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 41,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06302413730082546,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2227710625968362,
        "time": 0.276623010635376,
        "additional_info": {
            "duration": 0.26683902740478516,
            "num_run": 42,
            "train_loss": 1.1938439841555621,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 42,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1920,
            "feature_preprocessor:kernel_pca:gamma": 1.9792970160916794
        },
        "cost": 0.0,
        "time": 0.329542875289917,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 43,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.1217036226377004e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 109
        },
        "cost": 0.0,
        "time": 0.1319727897644043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 44,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003157307653916276,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.1852400302886963,
        "additional_info": {
            "duration": 0.16699719429016113,
            "num_run": 45,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 45,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9759587835647926,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2643078873965227,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 358.36069662814646,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0052427925160825764
        },
        "cost": 1.2305980296521821,
        "time": 0.155195951461792,
        "additional_info": {
            "duration": 0.14616012573242188,
            "num_run": 46,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 46,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9330022911603105,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26910718151900737,
            "feature_preprocessor:select_rates_classification:alpha": 0.2673967606444621,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2329648284147425,
        "time": 0.21476984024047852,
        "additional_info": {
            "duration": 0.2057809829711914,
            "num_run": 47,
            "train_loss": 1.1998512716205885,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 47,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.485428871856702,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.24140620231628418,
        "additional_info": {
            "duration": 0.22762012481689453,
            "num_run": 48,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 48,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003481153830221084,
            "feature_preprocessor:select_percentile_classification:percentile": 2.5862756974315837,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.24412894248962402,
        "additional_info": {
            "duration": 0.23485803604125977,
            "num_run": 49,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 49,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006222383813123533,
            "feature_preprocessor:kitchen_sinks:gamma": 0.49113414099044683,
            "feature_preprocessor:kitchen_sinks:n_components": 813
        },
        "cost": 0.0,
        "time": 0.13036489486694336,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 50,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001028433636349449,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7613886945627427,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.06005397663002918,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2405,
            "feature_preprocessor:nystroem_sampler:gamma": 0.001813071002894766
        },
        "cost": 1.1970082502304136,
        "time": 0.5734138488769531,
        "additional_info": {
            "duration": 0.5601108074188232,
            "num_run": 51,
            "train_loss": 1.1927552607131793,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 51,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0023584462626058816,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9699128005084409,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10936280577420703,
            "feature_preprocessor:pca:keep_variance": 0.9407137137589467,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2239140287926984,
        "time": 0.2546520233154297,
        "additional_info": {
            "duration": 0.23534488677978516,
            "num_run": 52,
            "train_loss": 1.2382549674608192,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 52,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09529903584024944,
            "feature_preprocessor:kitchen_sinks:gamma": 0.24384054549651785,
            "feature_preprocessor:kitchen_sinks:n_components": 160
        },
        "cost": 0.0,
        "time": 0.10897183418273926,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 53,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008160067532031556,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8415607592847896,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.052801019063926896,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 940
        },
        "cost": 0.0,
        "time": 0.13305997848510742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 54,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 5.684962825625047,
            "feature_preprocessor:kitchen_sinks:n_components": 59
        },
        "cost": 0.0,
        "time": 0.135512113571167,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 55,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.14850837404750059,
            "feature_preprocessor:kitchen_sinks:n_components": 1531
        },
        "cost": 0.0,
        "time": 0.10863494873046875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 56,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.058807920519598184,
            "feature_preprocessor:kitchen_sinks:n_components": 1375
        },
        "cost": 0.0,
        "time": 0.12939786911010742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 57,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19734190193523402,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 248
        },
        "cost": 0.0,
        "time": 0.1299760341644287,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 58,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007778054239203642,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 7321,
            "feature_preprocessor:nystroem_sampler:gamma": 0.007732612461749062
        },
        "cost": 1.247752183555559,
        "time": 0.9257521629333496,
        "additional_info": {
            "duration": 0.9066629409790039,
            "num_run": 59,
            "train_loss": 1.0032921198263127,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 59,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005119375055089901,
            "feature_preprocessor:pca:keep_variance": 0.8865621339829421,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.21970105171203613,
        "additional_info": {
            "duration": 0.20255208015441895,
            "num_run": 60,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 60,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2434132569191747,
        "time": 0.2035069465637207,
        "additional_info": {
            "duration": 0.19187521934509277,
            "num_run": 61,
            "train_loss": 1.1944893719342615,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 61,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 867,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0024048074934997768
        },
        "cost": 1.2305980296521821,
        "time": 0.399852991104126,
        "additional_info": {
            "duration": 0.38230204582214355,
            "num_run": 62,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 62,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.619659708732194e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 425
        },
        "cost": 0.0,
        "time": 0.10344386100769043,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 63,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1921,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1532,
            "feature_preprocessor:kernel_pca:coef0": 0.15670287092748691
        },
        "cost": 0.0,
        "time": 0.1819767951965332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.978333 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 64,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1582,
            "feature_preprocessor:kernel_pca:coef0": -0.39656972148537584,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.000775809717163263
        },
        "cost": 0.0,
        "time": 0.3089931011199951,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.0205653 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.0205653 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 65,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 4.369970894082242,
            "feature_preprocessor:kitchen_sinks:n_components": 144
        },
        "cost": 0.0,
        "time": 0.15461397171020508,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 66,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.032393347833722184,
            "feature_preprocessor:select_rates_classification:alpha": 0.3597884045116385,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2305980296521821,
        "time": 0.20173192024230957,
        "additional_info": {
            "duration": 0.19017791748046875,
            "num_run": 67,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 67,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 307,
            "feature_preprocessor:nystroem_sampler:coef0": -0.20667878039874554,
            "feature_preprocessor:nystroem_sampler:gamma": 0.019307749124593387
        },
        "cost": 1.2623420072455547,
        "time": 0.8223621845245361,
        "additional_info": {
            "duration": 0.8088390827178955,
            "num_run": 68,
            "train_loss": 1.122786323100035,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 68,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017092105567115504,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1372
        },
        "cost": 0.0,
        "time": 0.19742798805236816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 69,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04583855164219459,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1779
        },
        "cost": 0.0,
        "time": 0.10892176628112793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 70,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2525944037779861,
        "time": 0.3305349349975586,
        "additional_info": {
            "duration": 0.3132610321044922,
            "num_run": 71,
            "train_loss": 1.1916991716207619,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 71,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001977291205397978,
            "feature_preprocessor:kitchen_sinks:gamma": 0.002429060431541132,
            "feature_preprocessor:kitchen_sinks:n_components": 1326
        },
        "cost": 0.0,
        "time": 0.13131999969482422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 72,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05722466994179369,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9911202232802303,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.07431651676130951,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 8,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.23507189750671387,
        "additional_info": {
            "duration": 0.22593307495117188,
            "num_run": 73,
            "train_loss": 1.2288023279287388,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 73,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007867287440516542,
            "feature_preprocessor:kitchen_sinks:gamma": 3.1217036226377004e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 142
        },
        "cost": 0.0,
        "time": 0.10359001159667969,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 74,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.238105160402618,
        "time": 4.2835471630096436,
        "additional_info": {
            "duration": 4.270940065383911,
            "num_run": 75,
            "train_loss": 1.1972469378977957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 75,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.049042529949095845,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 120
        },
        "cost": 0.0,
        "time": 0.1609642505645752,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 76,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1209,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 27,
            "feature_preprocessor:kernel_pca:coef0": 0.19336398035022606,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.020263987046251077
        },
        "cost": 0.0,
        "time": 0.21964502334594727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 77,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9076880746501301,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08851211846106868,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 674,
            "feature_preprocessor:kernel_pca:gamma": 0.011251360443920947
        },
        "cost": 0.0,
        "time": 0.16024494171142578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 78,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1622,
            "feature_preprocessor:kernel_pca:coef0": 0.7631883492446745
        },
        "cost": 0.0,
        "time": 0.15438389778137207,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.289195 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.289195 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 79,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002410658836124756,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 192,
            "feature_preprocessor:nystroem_sampler:coef0": 0.307449122529605,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.8526703203782496
        },
        "cost": 1.20815549317604,
        "time": 0.36759185791015625,
        "additional_info": {
            "duration": 0.29264307022094727,
            "num_run": 80,
            "train_loss": 1.1485333108897984,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 80,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018490067468233732,
            "feature_preprocessor:kitchen_sinks:gamma": 0.35264246071332683,
            "feature_preprocessor:kitchen_sinks:n_components": 379
        },
        "cost": 0.0,
        "time": 0.10891604423522949,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 81,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1169
        },
        "cost": 0.0,
        "time": 0.10974311828613281,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 82,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04090947372931221,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7744915799700929,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23780340322886354,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1099
        },
        "cost": 0.0,
        "time": 0.10701417922973633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 83,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00043300710530542357,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.7151542962678208,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 3.4542373167910895e-05
        },
        "cost": 1.231251384418784,
        "time": 0.19655108451843262,
        "additional_info": {
            "duration": 0.18697190284729004,
            "num_run": 84,
            "train_loss": 1.1743487342706618,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 84,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2350158120637325,
        "time": 0.8685259819030762,
        "additional_info": {
            "duration": 0.855147123336792,
            "num_run": 85,
            "train_loss": 1.156610378214839,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 85,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010155147219503936,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 296
        },
        "cost": 0.0,
        "time": 0.1314239501953125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 86,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04214631481412443,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 124
        },
        "cost": 0.0,
        "time": 0.15512323379516602,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 87,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1025
        },
        "cost": 0.0,
        "time": 0.1310560703277588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 88,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1030
        },
        "cost": 0.0,
        "time": 0.10324406623840332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 89,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013368491082704558,
            "feature_preprocessor:select_rates_classification:alpha": 0.2319538289132838,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.20569586753845215,
        "additional_info": {
            "duration": 0.19271397590637207,
            "num_run": 90,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 90,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4655216305411587,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 57,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 647
        },
        "cost": 0.0,
        "time": 0.12435507774353027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 91,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 177
        },
        "cost": 0.0,
        "time": 0.17306184768676758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 92,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 676,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 42
        },
        "cost": 0.0,
        "time": 0.13779830932617188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 93,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0020341318254312388,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1875
        },
        "cost": 0.0,
        "time": 0.13163995742797852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 94,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0038431602699981783,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 370,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.245041813352958,
        "time": 0.2940480709075928,
        "additional_info": {
            "duration": 0.27342963218688965,
            "num_run": 95,
            "train_loss": 1.1690422515422954,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 95,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 366
        },
        "cost": 0.0,
        "time": 0.16659998893737793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 96,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2567812586381417,
        "time": 0.36432576179504395,
        "additional_info": {
            "duration": 0.35415196418762207,
            "num_run": 97,
            "train_loss": 1.1705220605815705,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 97,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016798416514964456,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1631
        },
        "cost": 0.0,
        "time": 0.16010403633117676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 98,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 881
        },
        "cost": 0.0,
        "time": 0.13542914390563965,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 99,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7120556960958573,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09099210673250795,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1266
        },
        "cost": 0.0,
        "time": 0.11366701126098633,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 100,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 239
        },
        "cost": 0.0,
        "time": 0.13296794891357422,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 101,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 956
        },
        "cost": 0.0,
        "time": 0.1345219612121582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 102,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 257,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.271075963973999,
        "additional_info": {
            "duration": 0.25673484802246094,
            "num_run": 103,
            "train_loss": 1.2255102081024258,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 103,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003901176878861048,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 398
        },
        "cost": 0.0,
        "time": 0.10976219177246094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 104,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04659922995766976,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 97,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0509487896927692
        },
        "cost": 1.2305980296521821,
        "time": 0.2523479461669922,
        "additional_info": {
            "duration": 0.24089503288269043,
            "num_run": 105,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 105,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2841705648249004,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 600
        },
        "cost": 0.0,
        "time": 0.15466594696044922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 106,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1385
        },
        "cost": 0.0,
        "time": 0.12872099876403809,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 107,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01112457426193413,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1180,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2325424011995356,
        "time": 1.6974704265594482,
        "additional_info": {
            "duration": 1.6819679737091064,
            "num_run": 108,
            "train_loss": 1.1819336460577443,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 108,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 568,
            "feature_preprocessor:kernel_pca:coef0": 0.987501153534766,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 1.4893664811452672
        },
        "cost": 0.0,
        "time": 0.23914527893066406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 109,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8276869463889849,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04848263480746938,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 117,
            "feature_preprocessor:kernel_pca:coef0": -0.9786865418988433
        },
        "cost": 0.0,
        "time": 0.2906348705291748,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 110,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 40
        },
        "cost": 0.0,
        "time": 0.13109922409057617,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 111,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 156,
            "feature_preprocessor:nystroem_sampler:coef0": 0.44072178306258003,
            "feature_preprocessor:nystroem_sampler:gamma": 0.05941660070247501
        },
        "cost": 1.2305980296521821,
        "time": 0.3071861267089844,
        "additional_info": {
            "duration": 0.28485608100891113,
            "num_run": 112,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 112,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002664619874282058,
            "feature_preprocessor:kitchen_sinks:gamma": 0.11649137322044044,
            "feature_preprocessor:kitchen_sinks:n_components": 129
        },
        "cost": 0.0,
        "time": 0.10387992858886719,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 113,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00011200772584058917,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1760
        },
        "cost": 0.0,
        "time": 0.1946718692779541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 114,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008607517982660344,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.264310113928039,
        "time": 1.08713698387146,
        "additional_info": {
            "duration": 1.0669996738433838,
            "num_run": 115,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 115,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.722766085818138,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.241614925361041,
        "time": 0.27941107749938965,
        "additional_info": {
            "duration": 0.26035404205322266,
            "num_run": 116,
            "train_loss": 1.1864057075255352,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 116,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001255049118902084,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1932
        },
        "cost": 0.0,
        "time": 0.1057732105255127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 117,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04387788356973482,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.748989513394216,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10315516857523646,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1918
        },
        "cost": 0.0,
        "time": 0.13359403610229492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 118,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.001734724931090874,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 434
        },
        "cost": 0.0,
        "time": 0.10467791557312012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 119,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 43
        },
        "cost": 0.0,
        "time": 0.10407495498657227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 120,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.399463159521452,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1438,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 699
        },
        "cost": 0.0,
        "time": 0.1461780071258545,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 121,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4209861217867639,
            "feature_preprocessor:kitchen_sinks:gamma": 0.12744615031571735,
            "feature_preprocessor:kitchen_sinks:n_components": 719
        },
        "cost": 0.0,
        "time": 0.13237929344177246,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 122,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010733602756392768,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1915,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.010837186591255857,
            "feature_preprocessor:kitchen_sinks:n_components": 70
        },
        "cost": 0.0,
        "time": 0.1619577407836914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 123,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02864511202695061,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1026,
            "feature_preprocessor:kernel_pca:coef0": -0.4226374131247823
        },
        "cost": 0.0,
        "time": 0.19900202751159668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.134097 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.134097 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 124,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3215441985679294,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 624,
            "feature_preprocessor:kernel_pca:coef0": 0.8554910317109599
        },
        "cost": 0.0,
        "time": 0.20097899436950684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.169092 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.169092 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 125,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012384357334528181,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8903336462328342,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1790023859024347,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2540314605479574,
        "time": 0.32448887825012207,
        "additional_info": {
            "duration": 0.3138890266418457,
            "num_run": 126,
            "train_loss": 1.0848715281394776,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 126,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014278304150245216,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0007909766552049041,
            "feature_preprocessor:kitchen_sinks:n_components": 53
        },
        "cost": 0.0,
        "time": 0.12966132164001465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 127,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1419
        },
        "cost": 0.0,
        "time": 0.10411882400512695,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 128,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 216
        },
        "cost": 0.0,
        "time": 0.1399679183959961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 129,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.49057921616822686,
            "feature_preprocessor:select_rates_classification:alpha": 0.06379053994891036,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.2264108657836914,
        "additional_info": {
            "duration": 0.21748590469360352,
            "num_run": 130,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 130,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00329303046833315,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 353
        },
        "cost": 0.0,
        "time": 0.136430025100708,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 131,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8157541208629273,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1709653450672991,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0001345584834458488,
            "feature_preprocessor:kitchen_sinks:n_components": 395
        },
        "cost": 0.0,
        "time": 0.11194181442260742,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 132,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8164170547894972,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.238105160402618,
        "time": 0.23323392868041992,
        "additional_info": {
            "duration": 0.222304105758667,
            "num_run": 133,
            "train_loss": 1.1972469378977957,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 133,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03894704758029955,
            "feature_preprocessor:kitchen_sinks:gamma": 0.39806239953794004,
            "feature_preprocessor:kitchen_sinks:n_components": 2462
        },
        "cost": 0.0,
        "time": 0.16049504280090332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 134,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.147526076129814,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1022,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.03527571089276763,
            "feature_preprocessor:kitchen_sinks:n_components": 1685
        },
        "cost": 0.0,
        "time": 0.17220115661621094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 135,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00021151061039248272,
            "feature_preprocessor:pca:keep_variance": 0.58641309144508,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2465854822245659,
        "time": 0.2167680263519287,
        "additional_info": {
            "duration": 0.20423293113708496,
            "num_run": 136,
            "train_loss": 1.1764739310886365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 136,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1683
        },
        "cost": 0.0,
        "time": 0.18839502334594727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 137,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16535146725743063,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1452
        },
        "cost": 0.0,
        "time": 0.13703703880310059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 138,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9034394218644273,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.02246119135755298,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.10761713981628418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 139,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1027,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2305980296521821,
        "time": 0.2561938762664795,
        "additional_info": {
            "duration": 0.2440178394317627,
            "num_run": 140,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 140,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17643142658987582,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 327
        },
        "cost": 0.0,
        "time": 0.13714098930358887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 141,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007014509595444173,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7800029232099027,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.25,
            "feature_preprocessor:select_percentile_classification:percentile": 91.98012837260445,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2254576976643063,
        "time": 0.2355508804321289,
        "additional_info": {
            "duration": 0.22164511680603027,
            "num_run": 142,
            "train_loss": 1.2156338486234874,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 142,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 58,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2305980296521821,
        "time": 0.32122325897216797,
        "additional_info": {
            "duration": 0.304912805557251,
            "num_run": 143,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 143,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04148087403489184,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1193
        },
        "cost": 0.0,
        "time": 0.1418743133544922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 144,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.245041813352958,
        "time": 3.153510093688965,
        "additional_info": {
            "duration": 3.141597270965576,
            "num_run": 145,
            "train_loss": 1.1644723747917234,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 145,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.21399319927228602,
            "feature_preprocessor:kitchen_sinks:n_components": 68
        },
        "cost": 0.0,
        "time": 0.10549235343933105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 146,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.006403048837545379,
            "feature_preprocessor:kitchen_sinks:n_components": 3846
        },
        "cost": 0.0,
        "time": 0.1362898349761963,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 147,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0008849454923172479,
            "feature_preprocessor:kitchen_sinks:n_components": 6419
        },
        "cost": 0.0,
        "time": 0.10902285575866699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 148,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4750464962314175,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1873
        },
        "cost": 0.0,
        "time": 0.13126301765441895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 149,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.11589446831311478,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2305980296521821,
        "time": 0.1542661190032959,
        "additional_info": {
            "duration": 0.14462900161743164,
            "num_run": 150,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 150,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006149691883485393,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 978,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 124
        },
        "cost": 0.0,
        "time": 0.16173577308654785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 151,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1443
        },
        "cost": 1.2443035710241805,
        "time": 0.7463538646697998,
        "additional_info": {
            "duration": 0.7322289943695068,
            "num_run": 152,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 152,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007225713884006859,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 321
        },
        "cost": 0.0,
        "time": 0.10405993461608887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 153,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 575,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2325424011995356,
        "time": 0.2971310615539551,
        "additional_info": {
            "duration": 0.2856481075286865,
            "num_run": 154,
            "train_loss": 1.1819336460577443,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 154,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02239985036721776
        },
        "cost": 1.2305980296521821,
        "time": 0.19726777076721191,
        "additional_info": {
            "duration": 0.17542815208435059,
            "num_run": 155,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 155,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 3269,
            "feature_preprocessor:nystroem_sampler:coef0": 0.6163901301270225,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.018077598470393984
        },
        "cost": 1.2305980296521821,
        "time": 0.5348379611968994,
        "additional_info": {
            "duration": 0.5142688751220703,
            "num_run": 156,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 156,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001287748027616788,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9489171763342181,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2532714936797191,
        "time": 0.2636449337005615,
        "additional_info": {
            "duration": 0.2525522708892822,
            "num_run": 157,
            "train_loss": 1.1992613007998494,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 157,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02933435355419999,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1640,
            "feature_preprocessor:kernel_pca:gamma": 0.0002377291385925897
        },
        "cost": 0.0,
        "time": 0.3063490390777588,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 158,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010433568638899093,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0008695226906543261,
            "feature_preprocessor:kitchen_sinks:n_components": 316
        },
        "cost": 0.0,
        "time": 0.10958290100097656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 159,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.3025178909301758,
        "additional_info": {
            "duration": 0.2860691547393799,
            "num_run": 160,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 160,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00037030135741609413,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1527,
            "feature_preprocessor:kernel_pca:coef0": 0.8774069957198574
        },
        "cost": 0.0,
        "time": 0.17545008659362793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.173268 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.173268 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 161,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.636706113815308,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 162,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2384664351907806,
        "time": 1.0628318786621094,
        "additional_info": {
            "duration": 1.0445432662963867,
            "num_run": 163,
            "train_loss": 1.2065137108391695,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 163,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0028782278720641194,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1639,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 56,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2314211595431346,
        "time": 0.4197351932525635,
        "additional_info": {
            "duration": 0.4069647789001465,
            "num_run": 164,
            "train_loss": 1.1693649015480874,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 164,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9779501811185513,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.29578399658203125,
        "additional_info": {
            "duration": 0.22798585891723633,
            "num_run": 165,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 165,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 199
        },
        "cost": 0.0,
        "time": 0.19283795356750488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 166,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.840111620980907,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00632346673691164
        },
        "cost": 1.2486384764692255,
        "time": 0.15546202659606934,
        "additional_info": {
            "duration": 0.1458292007446289,
            "num_run": 167,
            "train_loss": 1.183169004657183,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 167,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1501,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.8949424327966611,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2485535889070503,
        "time": 0.22465109825134277,
        "additional_info": {
            "duration": 0.2104649543762207,
            "num_run": 168,
            "train_loss": 1.184335927665521,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 168,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07853003841585286,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0015820559549182245,
            "feature_preprocessor:kitchen_sinks:n_components": 216
        },
        "cost": 0.0,
        "time": 0.15520215034484863,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 169,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12325592183132117,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2193441746049192,
        "time": 0.24081778526306152,
        "additional_info": {
            "duration": 0.22980570793151855,
            "num_run": 170,
            "train_loss": 1.16977885752009,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 170,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 890
        },
        "cost": 0.0,
        "time": 0.12978792190551758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 171,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16861312370712278,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.06448519458337798,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.24692678451538086,
        "additional_info": {
            "duration": 0.23606014251708984,
            "num_run": 172,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 172,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1203,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.11522132725258272,
            "feature_preprocessor:kitchen_sinks:n_components": 50
        },
        "cost": 0.0,
        "time": 0.19731998443603516,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 173,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 49.91168143058689,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.23782896995544434,
        "additional_info": {
            "duration": 0.2230370044708252,
            "num_run": 174,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 174,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1652
        },
        "cost": 0.0,
        "time": 0.10442304611206055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 175,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 919
        },
        "cost": 0.0,
        "time": 0.16450190544128418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 176,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000503376782994931,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 715,
            "feature_preprocessor:kernel_pca:coef0": 0.015072685517343531,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.0006572802423399825
        },
        "cost": 0.0,
        "time": 0.24175214767456055,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 177,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.03342836482180622,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2448720382286074,
        "time": 0.24764513969421387,
        "additional_info": {
            "duration": 0.2364180088043213,
            "num_run": 178,
            "train_loss": 1.183755720819637,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 178,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1336
        },
        "cost": 0.0,
        "time": 0.10919499397277832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 179,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.017825136115365525,
            "feature_preprocessor:kitchen_sinks:gamma": 0.5012481069184603,
            "feature_preprocessor:kitchen_sinks:n_components": 2778
        },
        "cost": 0.0,
        "time": 0.10438179969787598,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 180,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22037911016258838,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 720,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 209,
            "feature_preprocessor:kernel_pca:gamma": 0.0009589443910876779
        },
        "cost": 0.0,
        "time": 0.4618661403656006,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 181,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006645082450280931,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 1874
        },
        "cost": 1.2305980296521821,
        "time": 0.5893449783325195,
        "additional_info": {
            "duration": 0.5688366889953613,
            "num_run": 182,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 182,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.161417776654809,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8144549744788961,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.011386573772474734,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2463308195380398,
        "time": 5.010874032974243,
        "additional_info": {
            "duration": 4.9865782260894775,
            "num_run": 183,
            "train_loss": 1.177106300234196,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 183,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014515826894380868,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 367
        },
        "cost": 0.0,
        "time": 0.10654783248901367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 184,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 903,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7608431518701231,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 5,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2463328301337095,
        "time": 0.2915639877319336,
        "additional_info": {
            "duration": 0.2809000015258789,
            "num_run": 185,
            "train_loss": 1.1892741074049902,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 185,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8366238262371009,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2910496125305146,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 960,
            "feature_preprocessor:kernel_pca:gamma": 0.17288587156956414
        },
        "cost": 0.0,
        "time": 0.19763994216918945,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 186,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.32614272499266767,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1353
        },
        "cost": 0.0,
        "time": 0.26569199562072754,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 187,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.45628804552032576,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1869
        },
        "cost": 0.0,
        "time": 0.13291597366333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 188,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4862759314696793,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1861,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1468
        },
        "cost": 0.0,
        "time": 0.1359250545501709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 189,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.234678272410701,
        "time": 4.646082162857056,
        "additional_info": {
            "duration": 4.634387016296387,
            "num_run": 190,
            "train_loss": 1.1923087581583265,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 190,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1236,
            "feature_preprocessor:kernel_pca:coef0": -0.9981319555185093,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.009503280567177318
        },
        "cost": 0.0,
        "time": 0.41650915145874023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 191,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001291508421947138,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 541,
            "feature_preprocessor:kernel_pca:gamma": 0.5700585475806743
        },
        "cost": 0.0,
        "time": 0.5637660026550293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 192,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 914,
            "feature_preprocessor:kernel_pca:coef0": 0.2741449721329763,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.0013182816936928492
        },
        "cost": 0.0,
        "time": 0.2971529960632324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 193,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 290
        },
        "cost": 0.0,
        "time": 0.13789820671081543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 194,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018005255040570833,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1501,
            "feature_preprocessor:kernel_pca:coef0": -0.7420349580730254
        },
        "cost": 0.0,
        "time": 0.3215830326080322,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.132635 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.132635 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 195,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 782,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 884
        },
        "cost": 0.0,
        "time": 0.20012736320495605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 196,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00046285960242489305,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1967,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.42615668387430594,
            "feature_preprocessor:kitchen_sinks:n_components": 142
        },
        "cost": 0.0,
        "time": 0.13543295860290527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 197,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018143984225294776,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7963241639940194,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.19362191787960506,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1838
        },
        "cost": 0.0,
        "time": 0.16762304306030273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 198,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2356297389427513,
        "time": 0.28371214866638184,
        "additional_info": {
            "duration": 0.2654449939727783,
            "num_run": 199,
            "train_loss": 1.178586109273471,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 199,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008009057879536848,
            "feature_preprocessor:pca:keep_variance": 0.913155611314894,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.248468701344875,
        "time": 0.24118709564208984,
        "additional_info": {
            "duration": 0.23080801963806152,
            "num_run": 200,
            "train_loss": 1.1631946178674646,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 200,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09910801915287118,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1586
        },
        "cost": 0.0,
        "time": 0.15507292747497559,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 201,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2186820293623897,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 2.9782779216766357,
        "additional_info": {
            "duration": 2.9584667682647705,
            "num_run": 202,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 202,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02005357057173751,
            "feature_preprocessor:select_percentile_classification:percentile": 40.65053523462531,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.18026280403137207,
        "additional_info": {
            "duration": 0.1703650951385498,
            "num_run": 203,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 203,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6776210029226036,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2478351593017578,
        "additional_info": {
            "duration": 0.23710179328918457,
            "num_run": 204,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 204,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023340673133021462,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 774,
            "feature_preprocessor:kernel_pca:coef0": -0.05712077446015362,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.961132363346469
        },
        "cost": 0.0,
        "time": 0.129608154296875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 205,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1039,
            "feature_preprocessor:kernel_pca:gamma": 3.0003225602170565
        },
        "cost": 0.0,
        "time": 0.1644148826599121,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 206,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.960947897689621,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22312334761514765,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1981
        },
        "cost": 0.0,
        "time": 0.14317607879638672,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 207,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0013027048056560677,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7714801378856307,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09487446901304962,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 242
        },
        "cost": 0.0,
        "time": 0.23884010314941406,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 208,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04349742846022237,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.860975212108147,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.08190774994528072,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 44
        },
        "cost": 0.0,
        "time": 0.10799813270568848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 209,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022021824790157858,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5414040696181663,
        "time": 1.994863748550415,
        "additional_info": {
            "duration": 1.9815921783447266,
            "num_run": 210,
            "train_loss": 1.5415537114284534,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 210,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030842852353829817
        },
        "cost": 1.2467552573489165,
        "time": 0.2544558048248291,
        "additional_info": {
            "duration": 0.23991990089416504,
            "num_run": 211,
            "train_loss": 1.1578424821559925,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 211,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14686306717592362,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1640,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 288,
            "feature_preprocessor:nystroem_sampler:coef0": 0.4439285648901672,
            "feature_preprocessor:nystroem_sampler:gamma": 0.4769512275425213
        },
        "cost": 1.2443035710241805,
        "time": 0.8047411441802979,
        "additional_info": {
            "duration": 0.7900779247283936,
            "num_run": 212,
            "train_loss": 1.2238641481892696,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 212,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1686,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 395,
            "feature_preprocessor:nystroem_sampler:coef0": 0.27365433441241005,
            "feature_preprocessor:nystroem_sampler:gamma": 0.002091666592414786
        },
        "cost": 1.24034764371542,
        "time": 0.5900590419769287,
        "additional_info": {
            "duration": 0.5735290050506592,
            "num_run": 213,
            "train_loss": 1.1706556771054863,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 213,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022623336771604636,
            "feature_preprocessor:kitchen_sinks:gamma": 0.010669229926385847,
            "feature_preprocessor:kitchen_sinks:n_components": 1813
        },
        "cost": 0.0,
        "time": 0.1054389476776123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 214,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03168534172837995,
            "feature_preprocessor:select_rates_classification:alpha": 0.016227953112438034,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.18077421188354492,
        "additional_info": {
            "duration": 0.1707777976989746,
            "num_run": 215,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 215,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5414040696181663,
        "time": 1.2661221027374268,
        "additional_info": {
            "duration": 1.2495410442352295,
            "num_run": 216,
            "train_loss": 1.5415537114284534,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 216,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00019322183317718286,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2313362719809593,
        "time": 1.4610331058502197,
        "additional_info": {
            "duration": 1.4390480518341064,
            "num_run": 217,
            "train_loss": 1.183856790760703,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 217,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.20532026266333048,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.20484399795532227,
        "additional_info": {
            "duration": 0.18758130073547363,
            "num_run": 218,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 218,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01432952181449274,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1998
        },
        "cost": 0.0,
        "time": 0.13191604614257812,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 219,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.224060068781918,
        "time": 0.2118380069732666,
        "additional_info": {
            "duration": 0.19320201873779297,
            "num_run": 220,
            "train_loss": 1.1852811828420176,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 220,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.264859597288682,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.24665188789367676,
        "additional_info": {
            "duration": 0.23198723793029785,
            "num_run": 221,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 221,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.777827335274982,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12798671647240625,
            "feature_preprocessor:pca:keep_variance": 0.9617848792750122,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.20589208602905273,
        "additional_info": {
            "duration": 0.19199419021606445,
            "num_run": 222,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 222,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 1.070882797241211,
        "additional_info": {
            "duration": 1.0520591735839844,
            "num_run": 223,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 223,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010728386645759246,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 280,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1215,
            "feature_preprocessor:kernel_pca:coef0": 0.10083187444731156,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 9.572130172231585e-05
        },
        "cost": 0.0,
        "time": 0.17981505393981934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 224,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19094211010525888,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.9294375875112144,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2750892639160156,
        "additional_info": {
            "duration": 0.26407289505004883,
            "num_run": 225,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 225,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7896530473328831,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2353605187265068,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 4.914670705795288,
        "additional_info": {
            "duration": 4.903602123260498,
            "num_run": 226,
            "train_loss": 1.2288023279287388,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 226,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003724477981127405,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 647,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 1.3431087748338895,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2305980296521821,
        "time": 0.2634449005126953,
        "additional_info": {
            "duration": 0.2533879280090332,
            "num_run": 227,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 227,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 212,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.9480599934652507,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.227234304682979,
        "time": 0.28400707244873047,
        "additional_info": {
            "duration": 0.2708616256713867,
            "num_run": 228,
            "train_loss": 1.1836351229288613,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 228,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003995886720273788,
            "feature_preprocessor:select_rates_classification:alpha": 0.41662638933194446,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2468401449110917,
        "time": 0.18631291389465332,
        "additional_info": {
            "duration": 0.1768050193786621,
            "num_run": 229,
            "train_loss": 1.1994275516737307,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 229,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1126,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2266183672082904,
        "time": 0.5473499298095703,
        "additional_info": {
            "duration": 0.5251171588897705,
            "num_run": 230,
            "train_loss": 1.1583118550859557,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 230,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 45,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1163,
            "feature_preprocessor:kernel_pca:coef0": -0.54600912348389
        },
        "cost": 0.0,
        "time": 0.2052290439605713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.20917 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.20917 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 231,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00025617118134333696,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 354,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2330497159769178,
        "time": 0.3287670612335205,
        "additional_info": {
            "duration": 0.31316208839416504,
            "num_run": 232,
            "train_loss": 1.1873705784188573,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 232,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 46
        },
        "cost": 0.0,
        "time": 0.13627290725708008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 233,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7551537627468555,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.013403575424849126,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1964
        },
        "cost": 0.0,
        "time": 0.13854002952575684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 234,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06980837080085109,
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 351,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2305980296521821,
        "time": 0.292510986328125,
        "additional_info": {
            "duration": 0.27977800369262695,
            "num_run": 235,
            "train_loss": 1.2255102081024258,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 235,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 136,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.245041813352958,
        "time": 0.2699429988861084,
        "additional_info": {
            "duration": 0.2580380439758301,
            "num_run": 236,
            "train_loss": 1.1644723747917234,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 236,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004251962763944401,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 651
        },
        "cost": 1.238464424595111,
        "time": 0.7624366283416748,
        "additional_info": {
            "duration": 0.738990068435669,
            "num_run": 237,
            "train_loss": 1.1899976947496451,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 237,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.022273106417567943,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 687
        },
        "cost": 0.0,
        "time": 0.13621902465820312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 238,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002617889082792883,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 522,
            "feature_preprocessor:kernel_pca:coef0": -0.16094768857090846
        },
        "cost": 0.0,
        "time": 0.2379317283630371,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.135872 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.135872 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 239,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.31251765541212495,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1845,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 784
        },
        "cost": 0.0,
        "time": 0.15027213096618652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 240,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.03799950600416624,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2313362719809593,
        "time": 0.21272611618041992,
        "additional_info": {
            "duration": 0.20204806327819824,
            "num_run": 241,
            "train_loss": 1.1971361039818749,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 241,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03412319136305455,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.777395009994507,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 242,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18610776244169852,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8347142493703105,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2699210956218996,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2608220735090776,
        "time": 0.26468682289123535,
        "additional_info": {
            "duration": 0.25096702575683594,
            "num_run": 243,
            "train_loss": 1.17986386619773,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 243,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.575942039489746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 244,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7732316273242609,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.1682240010522839,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1374
        },
        "cost": 0.0,
        "time": 0.13827204704284668,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 245,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.871610164642334,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 246,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.030621530830056882,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 129
        },
        "cost": 0.0,
        "time": 0.23428702354431152,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 247,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0027869441205778623,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7607725348137844,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04379424683665809,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1502,
            "feature_preprocessor:kernel_pca:gamma": 0.0447781524123141
        },
        "cost": 0.0,
        "time": 0.253892183303833,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 248,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00018086269661645701,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9587814142333855,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.22610227737264169,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 7190,
            "feature_preprocessor:nystroem_sampler:coef0": -0.46039039637697243,
            "feature_preprocessor:nystroem_sampler:degree": 5,
            "feature_preprocessor:nystroem_sampler:gamma": 0.24562860651899218
        },
        "cost": 1.326858666156752,
        "time": 0.6602091789245605,
        "additional_info": {
            "duration": 0.6470947265625,
            "num_run": 249,
            "train_loss": 1.2487115337856416,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 249,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004403928083374823,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.6437017917633057,
        "additional_info": {
            "duration": 0.6304240226745605,
            "num_run": 250,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 250,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019131942490607724,
            "feature_preprocessor:kitchen_sinks:gamma": 0.11668941462208332,
            "feature_preprocessor:kitchen_sinks:n_components": 336
        },
        "cost": 0.0,
        "time": 0.11074090003967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 251,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8918544629257451,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2415300377988654,
        "time": 0.23540711402893066,
        "additional_info": {
            "duration": 0.20747017860412598,
            "num_run": 252,
            "train_loss": 1.1830581707412622,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 252,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 99
        },
        "cost": 0.0,
        "time": 0.1361861228942871,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 253,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006688513735383227,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 722,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 711,
            "feature_preprocessor:kernel_pca:gamma": 0.0007978774562590261
        },
        "cost": 0.0,
        "time": 0.21226811408996582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 254,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001957045570977051,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1049,
            "feature_preprocessor:nystroem_sampler:coef0": 0.0033058781186148245,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0006085246839434178
        },
        "cost": 1.2305980296521821,
        "time": 0.46685791015625,
        "additional_info": {
            "duration": 0.45444202423095703,
            "num_run": 255,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 255,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.6392781734466553,
        "additional_info": {
            "duration": 0.6235470771789551,
            "num_run": 256,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 256,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.5860528945922852,
        "additional_info": {
            "duration": 0.57505202293396,
            "num_run": 257,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 257,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 639,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.470232946082424e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 7808
        },
        "cost": 0.0,
        "time": 0.1720728874206543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 258,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.24270892143249512,
        "additional_info": {
            "duration": 0.22148609161376953,
            "num_run": 259,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 259,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.047627208878055126,
            "feature_preprocessor:kitchen_sinks:gamma": 1.819437767428419,
            "feature_preprocessor:kitchen_sinks:n_components": 366
        },
        "cost": 0.0,
        "time": 0.1355910301208496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 260,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 472,
            "feature_preprocessor:kernel_pca:coef0": 0.0057441201575809675
        },
        "cost": 0.0,
        "time": 0.1952371597290039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 261,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.005724906921387,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 262,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 303,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.9543650126096744,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.238105160402618,
        "time": 0.3141450881958008,
        "additional_info": {
            "duration": 0.2880818843841553,
            "num_run": 263,
            "train_loss": 1.168188214564894,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 263,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9521926052737907,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.20708424754766627,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 724.9533037528915,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00034009383575909965
        },
        "cost": 1.2473711948236048,
        "time": 0.18936395645141602,
        "additional_info": {
            "duration": 0.17975974082946777,
            "num_run": 264,
            "train_loss": 1.2034986758026587,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 264,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 41.979426919503645,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00048487215643197053
        },
        "cost": 1.2341492330938575,
        "time": 0.15649819374084473,
        "additional_info": {
            "duration": 0.14683103561401367,
            "num_run": 265,
            "train_loss": 1.2118170266763666,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 265,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.2046341896057129,
        "additional_info": {
            "duration": 0.1920948028564453,
            "num_run": 266,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 266,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00039841860772617884,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 432,
            "feature_preprocessor:nystroem_sampler:coef0": 0.3437485164456344,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 0.06352249681068231
        },
        "cost": 1.243665909010031,
        "time": 0.41971611976623535,
        "additional_info": {
            "duration": 0.40842700004577637,
            "num_run": 267,
            "train_loss": 1.0182174929606411,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 267,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1905411948558943,
            "feature_preprocessor:kitchen_sinks:gamma": 0.9226888624899984,
            "feature_preprocessor:kitchen_sinks:n_components": 1132
        },
        "cost": 0.0,
        "time": 0.13165807723999023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 268,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2329648284147425,
        "time": 6.596205949783325,
        "additional_info": {
            "duration": 6.582627058029175,
            "num_run": 269,
            "train_loss": 1.1922533412003662,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 269,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.023353720825948783,
            "feature_preprocessor:kitchen_sinks:gamma": 0.6202302178789746,
            "feature_preprocessor:kitchen_sinks:n_components": 67
        },
        "cost": 0.0,
        "time": 0.1038961410522461,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 270,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1781
        },
        "cost": 0.0,
        "time": 0.10648918151855469,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 271,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03914596377501433,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8120646359904842,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17459130496656167,
            "feature_preprocessor:pca:keep_variance": 0.8542967995395172,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2272560292224401,
        "time": 0.21234512329101562,
        "additional_info": {
            "duration": 0.19892096519470215,
            "num_run": 272,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 272,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20479295139375686,
            "feature_preprocessor:select_rates_classification:alpha": 0.053402717160058955,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2366049406099326,
        "time": 0.15927910804748535,
        "additional_info": {
            "duration": 0.14865493774414062,
            "num_run": 273,
            "train_loss": 1.2193138871555231,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 273,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.3151238198516035e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 604
        },
        "cost": 0.0,
        "time": 0.1357898712158203,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 274,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13630633523294236,
            "feature_preprocessor:pca:keep_variance": 0.9181981621136746,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.29575204849243164,
        "additional_info": {
            "duration": 0.2838568687438965,
            "num_run": 275,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 275,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.054502725601196,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 276,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 883,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4016699630984625,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2354619744140705,
        "time": 0.24751687049865723,
        "additional_info": {
            "duration": 0.2366809844970703,
            "num_run": 277,
            "train_loss": 1.1968590191920727,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 277,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020631549181680564,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 135,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.303983211517334,
        "additional_info": {
            "duration": 0.2917451858520508,
            "num_run": 278,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 278,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.446929931640625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 279,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 1.3601182440487547,
            "feature_preprocessor:kitchen_sinks:n_components": 54
        },
        "cost": 0.0,
        "time": 0.13351702690124512,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 280,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.746049880981445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 281,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 117
        },
        "cost": 0.0,
        "time": 0.13198113441467285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 282,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9709142882216228,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.21832363968973942,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 1.976497578758679,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00033723970585397247
        },
        "cost": 1.2332174805055987,
        "time": 0.15937018394470215,
        "additional_info": {
            "duration": 0.14969897270202637,
            "num_run": 283,
            "train_loss": 1.190496447371289,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 283,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 4063,
            "feature_preprocessor:nystroem_sampler:gamma": 0.02825524951517401
        },
        "cost": 1.2348460369393819,
        "time": 0.5418670177459717,
        "additional_info": {
            "duration": 0.5300848484039307,
            "num_run": 284,
            "train_loss": 1.0116332533080157,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 284,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1305,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.7047438621520996,
        "additional_info": {
            "duration": 0.6874308586120605,
            "num_run": 285,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 285,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06073927205065823
        },
        "cost": 1.245041813352958,
        "time": 0.18911290168762207,
        "additional_info": {
            "duration": 0.1759796142578125,
            "num_run": 286,
            "train_loss": 1.1644723747917234,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 286,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.7102997303009033,
        "additional_info": {
            "duration": 0.6863491535186768,
            "num_run": 287,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 287,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1383,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1604
        },
        "cost": 0.0,
        "time": 0.1456611156463623,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 288,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 78.28467677029681,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.21097397804260254,
        "additional_info": {
            "duration": 0.1974802017211914,
            "num_run": 289,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 289,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.9377448558807373,
        "additional_info": {
            "duration": 0.9271571636199951,
            "num_run": 290,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 290,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 1478,
            "feature_preprocessor:nystroem_sampler:coef0": -0.7426069963280706,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0001977795871928599
        },
        "cost": 1.2305980296521821,
        "time": 0.3695087432861328,
        "additional_info": {
            "duration": 0.3558189868927002,
            "num_run": 291,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 291,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.008670091629028,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 292,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2205720283629566,
        "time": 6.82114315032959,
        "additional_info": {
            "duration": 6.807314872741699,
            "num_run": 293,
            "train_loss": 1.2366643245056232,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 293,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.23670368011839765,
            "feature_preprocessor:select_percentile_classification:percentile": 7.27113764660159,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2345322324214814,
        "time": 0.1849226951599121,
        "additional_info": {
            "duration": 0.1752941608428955,
            "num_run": 294,
            "train_loss": 1.2275441867213053,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 294,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0024969668312928026,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.19882607460022,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 295,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014844111289151777,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 134,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1755
        },
        "cost": 0.0,
        "time": 0.13304615020751953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 296,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 74,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.3111708164215088,
        "additional_info": {
            "duration": 0.2931828498840332,
            "num_run": 297,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 297,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.53444504737854,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 298,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2407497633499703,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.21474099159240723,
        "additional_info": {
            "duration": 0.1963510513305664,
            "num_run": 299,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 299,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011265318578571356,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1452
        },
        "cost": 0.0,
        "time": 0.13037419319152832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 300,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.537782192230225,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 301,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002214929769600207,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1223,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8719597031463947,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.29958009719848633,
        "additional_info": {
            "duration": 0.2885000705718994,
            "num_run": 302,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 302,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0012841395025016845,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9094533953427202,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16681160992213956,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1060,
            "feature_preprocessor:kernel_pca:gamma": 0.012633242965879145
        },
        "cost": 0.0,
        "time": 0.3516550064086914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 303,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007480322136905948,
            "feature_preprocessor:select_rates_classification:alpha": 0.21542698637164762,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2305980296521821,
        "time": 0.1958780288696289,
        "additional_info": {
            "duration": 0.1815199851989746,
            "num_run": 304,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 304,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010601437361006997,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.10411810874939,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 305,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.7225048542022705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 306,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002732737246108792,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.349071979522705,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 307,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.228799698094048,
        "time": 4.1700439453125,
        "additional_info": {
            "duration": 4.096422910690308,
            "num_run": 308,
            "train_loss": 1.2173353254946044,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 308,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019764121782367788,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.856267213821411,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 309,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08075913690302931,
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 376,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2305980296521821,
        "time": 0.30822014808654785,
        "additional_info": {
            "duration": 0.29720091819763184,
            "num_run": 310,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 310,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8964583137744042,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2431606048283184,
        "time": 0.20911169052124023,
        "additional_info": {
            "duration": 0.19701004028320312,
            "num_run": 311,
            "train_loss": 1.1726570213744,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 311,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011190694207832188,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2546433768313068,
        "time": 7.0817060470581055,
        "additional_info": {
            "duration": 7.0670671463012695,
            "num_run": 312,
            "train_loss": 1.1870380766710948,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 312,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.949885129928589,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 313,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9989246547316202,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.045424427634641065,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.250012370216483,
        "time": 0.42029571533203125,
        "additional_info": {
            "duration": 0.4084351062774658,
            "num_run": 314,
            "train_loss": 1.1555054692481468,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 314,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.254138072649594,
        "time": 0.6213891506195068,
        "additional_info": {
            "duration": 0.6077039241790771,
            "num_run": 315,
            "train_loss": 1.1069938943551656,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 315,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0130221713542729,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.759191989898682,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 316,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00045321832598635794,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 758
        },
        "cost": 0.0,
        "time": 0.10707211494445801,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 317,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.11068470364710759,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.221142506163053,
        "time": 0.208176851272583,
        "additional_info": {
            "duration": 0.1971418857574463,
            "num_run": 318,
            "train_loss": 1.1808775569653271,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 318,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8539537526895666,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29590423052518355,
            "feature_preprocessor:pca:keep_variance": 0.820571114966852,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2272560292224401,
        "time": 0.24112892150878906,
        "additional_info": {
            "duration": 0.21419811248779297,
            "num_run": 319,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 319,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27440455298135563,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.373246908187866,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 320,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 79.48323954302116,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.18991303443908691,
        "additional_info": {
            "duration": 0.17604994773864746,
            "num_run": 321,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 321,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.4851109981536865,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 322,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7367558173736294,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.009456088781922826,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 241,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2483838137826997,
        "time": 0.29514122009277344,
        "additional_info": {
            "duration": 0.2786998748779297,
            "num_run": 323,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 323,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.280726194381714,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 324,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.6507899761199951,
        "additional_info": {
            "duration": 0.635390043258667,
            "num_run": 325,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 325,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002060652392870319,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1350,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.32198735436394066,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2330497159769178,
        "time": 0.3267552852630615,
        "additional_info": {
            "duration": 0.3134751319885254,
            "num_run": 326,
            "train_loss": 1.1787523601473524,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 326,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.39461128580253996,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2550678146421832,
        "time": 0.1625688076019287,
        "additional_info": {
            "duration": 0.15141510963439941,
            "num_run": 327,
            "train_loss": 1.1959137640155761,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 327,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07601366527068674,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 558.7024811399591,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0005067086483279306
        },
        "cost": 1.24349814448135,
        "time": 0.18902873992919922,
        "additional_info": {
            "duration": 0.17851591110229492,
            "num_run": 328,
            "train_loss": 1.1760502111417788,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 328,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1221,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 261
        },
        "cost": 1.2352073117275446,
        "time": 0.37351202964782715,
        "additional_info": {
            "duration": 0.34972524642944336,
            "num_run": 329,
            "train_loss": 1.1851149319681364,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 329,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006704692954011036,
            "feature_preprocessor:select_rates_classification:alpha": 0.3856927670793629,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2305980296521821,
        "time": 0.20752906799316406,
        "additional_info": {
            "duration": 0.1974940299987793,
            "num_run": 330,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 330,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4004143026916541,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.798673868179321,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 331,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037532250606497605,
            "feature_preprocessor:select_rates_classification:alpha": 0.2535834179178453,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22553300857543945,
        "additional_info": {
            "duration": 0.21566390991210938,
            "num_run": 332,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 332,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018270694146264022,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.23976707458496094,
        "additional_info": {
            "duration": 0.22471189498901367,
            "num_run": 333,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 333,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 150,
            "feature_preprocessor:nystroem_sampler:gamma": 3.4386301125222155e-05
        },
        "cost": 1.2305980296521821,
        "time": 0.2199857234954834,
        "additional_info": {
            "duration": 0.20439696311950684,
            "num_run": 334,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 334,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003539967761711605,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 214,
            "feature_preprocessor:nystroem_sampler:coef0": -0.6319497483888972,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00019606104110489147
        },
        "cost": 1.2305980296521821,
        "time": 0.342606782913208,
        "additional_info": {
            "duration": 0.32329392433166504,
            "num_run": 335,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 335,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0709564799923899,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.12571655215057487,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.3971412181854248,
        "additional_info": {
            "duration": 0.3589911460876465,
            "num_run": 336,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 336,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 269,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.245041813352958,
        "time": 0.298429012298584,
        "additional_info": {
            "duration": 0.2863349914550781,
            "num_run": 337,
            "train_loss": 1.1644723747917234,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 337,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009863315550949117,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.656590938568115,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 338,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.39903960569140107,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22939801216125488,
        "additional_info": {
            "duration": 0.21902704238891602,
            "num_run": 339,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 339,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010746241107570224,
            "feature_preprocessor:pca:keep_variance": 0.8443478064113781,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2272560292224401,
        "time": 0.2061018943786621,
        "additional_info": {
            "duration": 0.194810152053833,
            "num_run": 340,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 340,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 335,
            "feature_preprocessor:nystroem_sampler:gamma": 1.584495745220995
        },
        "cost": 1.2443035710241805,
        "time": 0.5018508434295654,
        "additional_info": {
            "duration": 0.488893985748291,
            "num_run": 341,
            "train_loss": 1.0740726960920377,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 341,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00711095906131244,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.877057790756226,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 342,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.2099950313568115,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 343,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011435648422176746,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7596985499579779,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 17,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2115823811679571,
        "time": 0.23570775985717773,
        "additional_info": {
            "duration": 0.2249281406402588,
            "num_run": 344,
            "train_loss": 1.194456737584296,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 344,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.9578869342803955,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 345,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2453182005789452,
        "time": 0.22354912757873535,
        "additional_info": {
            "duration": 0.2105419635772705,
            "num_run": 346,
            "train_loss": 1.1448532723577625,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 346,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002951896380639343,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 1.6225440502166748,
        "additional_info": {
            "duration": 1.6075561046600342,
            "num_run": 347,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 347,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.943860054016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 348,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 9175,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0032735500481715037
        },
        "cost": 1.2373431829387098,
        "time": 1.3893702030181885,
        "additional_info": {
            "duration": 1.3535518646240234,
            "num_run": 349,
            "train_loss": 1.1785306923155108,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 349,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17464204026366265,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 500.9084017717163,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 2.343128473634708e-05
        },
        "cost": 1.236752991194822,
        "time": 0.15936517715454102,
        "additional_info": {
            "duration": 0.149505615234375,
            "num_run": 350,
            "train_loss": 1.199505751239686,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 350,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.957942008972168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 351,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004435119956391112,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 6203,
            "feature_preprocessor:nystroem_sampler:gamma": 1.0300546977569496
        },
        "cost": 1.2305980296521821,
        "time": 0.9132909774780273,
        "additional_info": {
            "duration": 0.8965821266174316,
            "num_run": 352,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 352,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008044081675224734,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.565299034118652,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 353,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.707184502262783e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3149
        },
        "cost": 0.0,
        "time": 0.1347651481628418,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 354,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2483838137826997,
        "time": 0.19088172912597656,
        "additional_info": {
            "duration": 0.1787700653076172,
            "num_run": 355,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 355,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.217077970504761,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 356,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.8264079093933105,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 357,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2483838137826997,
        "time": 0.22110891342163086,
        "additional_info": {
            "duration": 0.2080399990081787,
            "num_run": 358,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 358,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.3333680629730225,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 359,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012162917060284101,
            "feature_preprocessor:select_rates_classification:alpha": 0.06038001061463833,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11684513092041016,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 360,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.416945934295654,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 361,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00010068360587661701,
            "feature_preprocessor:kitchen_sinks:n_components": 77
        },
        "cost": 0.0,
        "time": 0.13115501403808594,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 362,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0015471823284272594,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.448507308959961,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 363,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20001728242168798,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 299,
            "feature_preprocessor:nystroem_sampler:gamma": 0.13045864095642493
        },
        "cost": 1.2383578124934744,
        "time": 0.5594401359558105,
        "additional_info": {
            "duration": 0.547853946685791,
            "num_run": 364,
            "train_loss": 1.135475665500468,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 364,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009497397823986491,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5621453062555068,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2288628611167622,
        "time": 0.2468280792236328,
        "additional_info": {
            "duration": 0.2357027530670166,
            "num_run": 365,
            "train_loss": 1.2006856928811642,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 365,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012125984150752219,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8787170572488939,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.022417029353596237,
            "feature_preprocessor:pca:keep_variance": 0.6094937926939339,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2272560292224401,
        "time": 0.21592402458190918,
        "additional_info": {
            "duration": 0.19233322143554688,
            "num_run": 366,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 366,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.417840003967285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 367,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17621799512067812,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 793,
            "feature_preprocessor:kernel_pca:coef0": -0.2521461895592543,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 4.729445844995881e-05
        },
        "cost": 0.0,
        "time": 0.2920267581939697,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (3384.56 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (3384.56 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 368,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.151416063308716,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 369,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.466823101043701,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 370,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033318644814435104,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.29939603805542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 371,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3485856507753637,
            "feature_preprocessor:pca:keep_variance": 0.7416079986719868,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2432434817948241,
        "time": 0.22328805923461914,
        "additional_info": {
            "duration": 0.2117757797241211,
            "num_run": 372,
            "train_loss": 1.191399304222965,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 372,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016524733072406185,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5836338204898482,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.22426867485046387,
        "additional_info": {
            "duration": 0.21354174613952637,
            "num_run": 373,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 373,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003106629809028783,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 0.5141012371051285,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 2.892749020678551e-05
        },
        "cost": 1.2305980296521821,
        "time": 0.2165999412536621,
        "additional_info": {
            "duration": 0.20157980918884277,
            "num_run": 374,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 374,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005302968140313326,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.048386096954346,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 375,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.331542015075684,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 376,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2305980296521821,
        "time": 0.18234801292419434,
        "additional_info": {
            "duration": 0.16755986213684082,
            "num_run": 377,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 377,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.408870220184326,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 378,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002920053577792928,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7987759779692972,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2850432150272644,
            "feature_preprocessor:kitchen_sinks:gamma": 6.451663250648731e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 737
        },
        "cost": 0.0,
        "time": 0.13491201400756836,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 379,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2813596663254492,
        "time": 0.3648500442504883,
        "additional_info": {
            "duration": 0.352219820022583,
            "num_run": 380,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 380,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.17449469863700295,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2297926031093513,
        "time": 0.23658418655395508,
        "additional_info": {
            "duration": 0.22548198699951172,
            "num_run": 381,
            "train_loss": 1.1875726305338734,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 381,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16437129919784324,
            "feature_preprocessor:kitchen_sinks:gamma": 0.005583080917924019,
            "feature_preprocessor:kitchen_sinks:n_components": 1609
        },
        "cost": 0.0,
        "time": 0.13041305541992188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 382,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2305980296521821,
        "time": 0.2097773551940918,
        "additional_info": {
            "duration": 0.1864469051361084,
            "num_run": 383,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 383,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18528744371493508,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 846,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.027778120512582688,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.238527587617825,
        "time": 0.29578304290771484,
        "additional_info": {
            "duration": 0.28450703620910645,
            "num_run": 384,
            "train_loss": 1.1664867376937773,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 384,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.98158073425293,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 385,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1890,
            "feature_preprocessor:kernel_pca:coef0": 0.16551617530354168,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 1.5351048053176712
        },
        "cost": 0.0,
        "time": 0.138045072555542,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 386,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 141
        },
        "cost": 0.0,
        "time": 0.20591306686401367,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 387,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000389732270195557,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.0202720165252686,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 388,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 255,
            "feature_preprocessor:nystroem_sampler:coef0": 0.030964053469825448,
            "feature_preprocessor:nystroem_sampler:gamma": 0.008441196484789627
        },
        "cost": 1.2305980296521821,
        "time": 0.3338310718536377,
        "additional_info": {
            "duration": 0.32204222679138184,
            "num_run": 389,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 389,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01695165403602383,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.816097974777222,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 390,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.475039005279541,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 391,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 45,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2518107017746167,
        "time": 0.32041478157043457,
        "additional_info": {
            "duration": 0.3101799488067627,
            "num_run": 392,
            "train_loss": 1.1690422515422954,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 392,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.675689935684204,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 393,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.636909008026123,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 394,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.5456433720987948,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.18381476402282715,
        "additional_info": {
            "duration": 0.16815710067749023,
            "num_run": 395,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 395,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.994188070297241,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 396,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.01578134906958476,
            "feature_preprocessor:kitchen_sinks:n_components": 4047
        },
        "cost": 0.0,
        "time": 0.10430073738098145,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 397,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005222659382959374,
            "feature_preprocessor:select_percentile_classification:percentile": 48.32021790830699,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2363068288444843,
        "time": 0.1883378028869629,
        "additional_info": {
            "duration": 0.17279982566833496,
            "num_run": 398,
            "train_loss": 1.1889058044160927,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 398,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9221826186135365,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28472824039344774,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2254576976643063,
        "time": 4.537142038345337,
        "additional_info": {
            "duration": 4.524876832962036,
            "num_run": 399,
            "train_loss": 1.217279908536644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 399,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2279942715512175,
        "time": 0.5130119323730469,
        "additional_info": {
            "duration": 0.4966461658477783,
            "num_run": 400,
            "train_loss": 1.1764739310886365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 400,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9760638125572527,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17247221572523558,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 222,
            "feature_preprocessor:kernel_pca:gamma": 0.0007882263857977309
        },
        "cost": 0.0,
        "time": 0.19771099090576172,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 401,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.243075717266143,
        "time": 0.4495201110839844,
        "additional_info": {
            "duration": 0.4376180171966553,
            "num_run": 402,
            "train_loss": 1.173925014323804,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 402,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.579373121261597,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 403,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010128810474944974,
            "feature_preprocessor:kitchen_sinks:gamma": 0.005922699880488987,
            "feature_preprocessor:kitchen_sinks:n_components": 5168
        },
        "cost": 0.0,
        "time": 0.10932183265686035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 404,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16966630341479322,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 3,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2305980296521821,
        "time": 0.2662830352783203,
        "additional_info": {
            "duration": 0.25620508193969727,
            "num_run": 405,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 405,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023672555801136923,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2578787651594119,
        "time": 0.27781200408935547,
        "additional_info": {
            "duration": 0.2663710117340088,
            "num_run": 406,
            "train_loss": 1.0049935966974295,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 406,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.38867999451223895,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 67,
            "feature_preprocessor:nystroem_sampler:coef0": -0.3171430884220523,
            "feature_preprocessor:nystroem_sampler:degree": 2,
            "feature_preprocessor:nystroem_sampler:gamma": 1.5599731372805075
        },
        "cost": 1.2300452552002077,
        "time": 0.2293529510498047,
        "additional_info": {
            "duration": 0.2059640884399414,
            "num_run": 407,
            "train_loss": 1.1589539882063704,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 407,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.14813116412627225,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.222686175034661,
        "time": 0.24664306640625,
        "additional_info": {
            "duration": 0.2358839511871338,
            "num_run": 408,
            "train_loss": 1.1759947941838182,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 408,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 3313.2222209021265,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.07376527713428041
        },
        "cost": 1.245041813352958,
        "time": 0.1554560661315918,
        "additional_info": {
            "duration": 0.1456301212310791,
            "num_run": 409,
            "train_loss": 1.1790294449371546,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 409,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.2712550163269043,
        "additional_info": {
            "duration": 0.2603120803833008,
            "num_run": 410,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 410,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00029754073755654264,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9948066796549151,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.004347287739945246,
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 6189,
            "feature_preprocessor:nystroem_sampler:coef0": -0.41954982530090223,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.06842314094970038
        },
        "cost": 1.21540997183562,
        "time": 0.4474170207977295,
        "additional_info": {
            "duration": 0.4306938648223877,
            "num_run": 411,
            "train_loss": 1.1324964317050923,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 411,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 10.753522829283188,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0027571535857884347
        },
        "cost": 1.2305980296521821,
        "time": 0.15336132049560547,
        "additional_info": {
            "duration": 0.14361906051635742,
            "num_run": 412,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 412,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11832873660887008,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 714,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 3519,
            "feature_preprocessor:nystroem_sampler:coef0": -0.1470771774592221,
            "feature_preprocessor:nystroem_sampler:gamma": 0.29426521659843546
        },
        "cost": 1.2305980296521821,
        "time": 0.7947618961334229,
        "additional_info": {
            "duration": 0.7671380043029785,
            "num_run": 413,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 413,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18243314551293222,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6710680551299036,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 20,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1955277443815198,
        "time": 0.25792980194091797,
        "additional_info": {
            "duration": 0.24690580368041992,
            "num_run": 414,
            "train_loss": 1.1896978273518481,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 414,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8553851282757603,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11793255178244369,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 8547,
            "feature_preprocessor:nystroem_sampler:coef0": -0.16757789265336975,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0002726424602946671
        },
        "cost": 1.2305980296521821,
        "time": 0.7626559734344482,
        "additional_info": {
            "duration": 0.747424840927124,
            "num_run": 415,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 415,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8869194744482242,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.26211437096873536,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 291
        },
        "cost": 0.0,
        "time": 0.10943603515625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 416,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.003015608509874318,
            "feature_preprocessor:kitchen_sinks:n_components": 123
        },
        "cost": 0.0,
        "time": 0.1315300464630127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 417,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.74138879776001,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 418,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012729051709062094,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.453633069992065,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 419,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1474849505235117,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.967721939086914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 420,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 289,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2483838137826997,
        "time": 0.27372002601623535,
        "additional_info": {
            "duration": 0.26294708251953125,
            "num_run": 421,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 421,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.81415581703186,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 422,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.014024412624221579,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.661830902099609,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 423,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006400874496796193,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 3103
        },
        "cost": 1.2305980296521821,
        "time": 0.25276994705200195,
        "additional_info": {
            "duration": 0.23837590217590332,
            "num_run": 424,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 424,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.38031130059076806,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22406697273254395,
        "additional_info": {
            "duration": 0.21393990516662598,
            "num_run": 425,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 425,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2844501707446625,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 987,
            "feature_preprocessor:kernel_pca:gamma": 0.00012219837474125377
        },
        "cost": 0.0,
        "time": 0.199235200881958,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 426,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010400873388308873,
            "feature_preprocessor:select_percentile_classification:percentile": 76.11653575199703,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2364766039688349,
        "time": 0.2231581211090088,
        "additional_info": {
            "duration": 0.20918512344360352,
            "num_run": 427,
            "train_loss": 1.1673961916291389,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 427,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2265571972544173,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7449167453406658,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2799925192194618,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.253526156366245,
        "time": 1.124326229095459,
        "additional_info": {
            "duration": 1.1041259765625,
            "num_run": 428,
            "train_loss": 1.0115224193920949,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 428,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039485761295353264,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1866,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.1038121645565051,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2332174805055987,
        "time": 0.2793312072753906,
        "additional_info": {
            "duration": 0.26807522773742676,
            "num_run": 429,
            "train_loss": 1.1861807850354087,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 429,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005721378730557542,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.110817193984985,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 430,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007714012716532642,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.5323175698621468,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 12,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.1955277443815198,
        "time": 0.25715112686157227,
        "additional_info": {
            "duration": 0.24110889434814453,
            "num_run": 431,
            "train_loss": 1.1896978273518481,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 431,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1405,
            "feature_preprocessor:kernel_pca:coef0": -0.8323790461653877,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.00024066074410308803
        },
        "cost": 0.0,
        "time": 0.29091382026672363,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 432,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12038089091671511,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00854729807420903,
            "feature_preprocessor:kitchen_sinks:n_components": 1278
        },
        "cost": 0.0,
        "time": 0.13228201866149902,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 433,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00012257399268811433,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9838412174381124,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2765371462524873,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 443
        },
        "cost": 0.0,
        "time": 0.10845088958740234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 434,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003687818336242778,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8549958248565921,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.026261390511597354,
            "feature_preprocessor:select_rates_classification:alpha": 0.1395706417280879,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.15702199935913086,
        "additional_info": {
            "duration": 0.14730024337768555,
            "num_run": 435,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 435,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.07121752742258544,
            "feature_preprocessor:kitchen_sinks:gamma": 0.05169971796415583,
            "feature_preprocessor:kitchen_sinks:n_components": 135
        },
        "cost": 0.0,
        "time": 0.13096117973327637,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 436,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009318815180781197,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.8278679847717285,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 437,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 180
        },
        "cost": 1.2305980296521821,
        "time": 0.22961926460266113,
        "additional_info": {
            "duration": 0.21852993965148926,
            "num_run": 438,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 438,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011266083020487483,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 255,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.043886265207597676,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2305980296521821,
        "time": 0.18668675422668457,
        "additional_info": {
            "duration": 0.17640900611877441,
            "num_run": 439,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 439,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04539578117972339,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.74745350686768,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2433283693569994,
        "time": 0.2678699493408203,
        "additional_info": {
            "duration": 0.2570312023162842,
            "num_run": 440,
            "train_loss": 1.1856691015477405,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 440,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04520232644801494,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.775641918182373,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 441,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3107524004627397,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.088241815567017,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 442,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 616,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2305980296521821,
        "time": 0.31600093841552734,
        "additional_info": {
            "duration": 0.28946995735168457,
            "num_run": 443,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 443,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03384869860315519,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1023,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 2549,
            "feature_preprocessor:nystroem_sampler:gamma": 0.47594745344352024
        },
        "cost": 1.2305980296521821,
        "time": 0.4802389144897461,
        "additional_info": {
            "duration": 0.46630191802978516,
            "num_run": 444,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 444,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 1.0611069202423096,
        "additional_info": {
            "duration": 1.0482580661773682,
            "num_run": 445,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 445,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008052816963850741,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.662367105484009,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 446,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005201903156312672,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.63509726524353,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 447,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001310884632894446,
            "feature_preprocessor:pca:keep_variance": 0.8922209002364775,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2415300377988654,
        "time": 0.22682881355285645,
        "additional_info": {
            "duration": 0.21176505088806152,
            "num_run": 448,
            "train_loss": 1.182579033836444,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 448,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 66
        },
        "cost": 0.0,
        "time": 0.10715985298156738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 449,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006254527494690616,
            "feature_preprocessor:select_rates_classification:alpha": 0.09380927168647295,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2209727310387024,
        "time": 0.18451714515686035,
        "additional_info": {
            "duration": 0.17033600807189941,
            "num_run": 450,
            "train_loss": 1.1842805107075607,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 450,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1272861549614583,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6423281982262671,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.231251384418784,
        "time": 0.22887301445007324,
        "additional_info": {
            "duration": 0.2176530361175537,
            "num_run": 451,
            "train_loss": 1.2004836407661479,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 451,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.17450505168889713,
            "feature_preprocessor:kitchen_sinks:n_components": 254
        },
        "cost": 0.0,
        "time": 0.1553342342376709,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 452,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01860401002141824,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.882751941680908,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 453,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003590344502483252,
            "feature_preprocessor:select_rates_classification:alpha": 0.18107030530856236,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2305980296521821,
        "time": 0.18074893951416016,
        "additional_info": {
            "duration": 0.17084074020385742,
            "num_run": 454,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 454,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025616057804603663,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.293266876139314,
        "time": 0.3754239082336426,
        "additional_info": {
            "duration": 0.3027610778808594,
            "num_run": 455,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 455,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022392751796972295,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1569,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.9601269508291945,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.234678272410701,
        "time": 0.33895301818847656,
        "additional_info": {
            "duration": 0.3260009288787842,
            "num_run": 456,
            "train_loss": 1.1698342744780506,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 456,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.728427886962891,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 457,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3939701034032163,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.045971155166626,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 458,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004214978637557968,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 237,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2305980296521821,
        "time": 0.2674691677093506,
        "additional_info": {
            "duration": 0.25428009033203125,
            "num_run": 459,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 459,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.828686237335205,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 460,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1880,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2732128629651938,
        "time": 1.2928762435913086,
        "additional_info": {
            "duration": 1.278256893157959,
            "num_run": 461,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 461,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013837933648683107,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1300,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_rates_classification:alpha": 0.45911164210976046,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2483838137826997,
        "time": 0.31632399559020996,
        "additional_info": {
            "duration": 0.3046109676361084,
            "num_run": 462,
            "train_loss": 1.1656392978000616,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 462,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.067870855331421,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 463,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1857,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00014544945374768257,
            "feature_preprocessor:kitchen_sinks:n_components": 8373
        },
        "cost": 0.0,
        "time": 0.18087196350097656,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 464,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025920605694539422,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.137877941131592,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 465,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2567812586381417,
        "time": 0.3397209644317627,
        "additional_info": {
            "duration": 0.3251667022705078,
            "num_run": 466,
            "train_loss": 1.173925014323804,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 466,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019685758212155536,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.588018894195557,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 467,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1110,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.96500394090103,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2483838137826997,
        "time": 0.2422478199005127,
        "additional_info": {
            "duration": 0.22432374954223633,
            "num_run": 468,
            "train_loss": 1.169889691436011,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 468,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.09819943409743499,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 123,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2350158120637325,
        "time": 0.3494873046875,
        "additional_info": {
            "duration": 0.32919883728027344,
            "num_run": 469,
            "train_loss": 1.156610378214839,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 469,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08049537267091098,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2655162431466154,
        "time": 1.1326022148132324,
        "additional_info": {
            "duration": 1.1102509498596191,
            "num_run": 470,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 470,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.366177961852382,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1356
        },
        "cost": 0.0,
        "time": 0.10686683654785156,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 471,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03825508060066207,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.840322017669678,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 472,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.53050422668457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 473,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021242493374302715,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 743,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 485,
            "feature_preprocessor:nystroem_sampler:coef0": -0.339117469123003,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 0.03396153662092409
        },
        "cost": 1.2528233207337114,
        "time": 0.6328709125518799,
        "additional_info": {
            "duration": 0.6216356754302979,
            "num_run": 474,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 474,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.608665943145752,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 475,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.19762934310009087,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 604,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 6.33551405846734,
            "feature_preprocessor:kitchen_sinks:n_components": 51
        },
        "cost": 0.0,
        "time": 0.1369917392730713,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 476,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2659494783678875,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 217,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1098,
            "feature_preprocessor:kernel_pca:gamma": 0.5381232193957964
        },
        "cost": 0.0,
        "time": 0.22016310691833496,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 477,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9440382553992448,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.023720210666140187,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 265,
            "feature_preprocessor:nystroem_sampler:coef0": 0.3249440495736189,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0023965864423031737
        },
        "cost": 1.2322265860859651,
        "time": 0.2492210865020752,
        "additional_info": {
            "duration": 0.23598575592041016,
            "num_run": 478,
            "train_loss": 1.2255656250603864,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 478,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 313,
            "feature_preprocessor:kernel_pca:gamma": 0.0017036870228929423
        },
        "cost": 0.0,
        "time": 0.27956366539001465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 479,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.963354110717773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 480,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021112150723645865,
            "feature_preprocessor:pca:keep_variance": 0.663349296237043,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2243996190306194,
        "time": 0.22732806205749512,
        "additional_info": {
            "duration": 0.20334219932556152,
            "num_run": 481,
            "train_loss": 1.215353596942516,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 481,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 20.266901347921593,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2305980296521821,
        "time": 0.2224118709564209,
        "additional_info": {
            "duration": 0.21234798431396484,
            "num_run": 482,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 482,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005392106399211066,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.25754323610205,
        "time": 1.3844139575958252,
        "additional_info": {
            "duration": 1.365488052368164,
            "num_run": 483,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 483,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1340
        },
        "cost": 0.0,
        "time": 0.11256599426269531,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 484,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040916110299426856,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.6332268714904785,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 485,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005379611712781771,
            "feature_preprocessor:nystroem_sampler:kernel": "rbf",
            "feature_preprocessor:nystroem_sampler:n_components": 668,
            "feature_preprocessor:nystroem_sampler:gamma": 0.03764822494776443
        },
        "cost": 1.2305980296521821,
        "time": 0.5013461112976074,
        "additional_info": {
            "duration": 0.48000502586364746,
            "num_run": 486,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 486,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 1.1134631633758545,
        "additional_info": {
            "duration": 1.0914809703826904,
            "num_run": 487,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 487,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1605
        },
        "cost": 0.0,
        "time": 0.13135266304016113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 488,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0016755361027420488,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.211911201477051,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 489,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.267150163650513,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 490,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.0104310512542725,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 491,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1228
        },
        "cost": 0.0,
        "time": 0.13637232780456543,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 492,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00033546764185481246,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9762436583518047,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.0967706352505989,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 744,
            "feature_preprocessor:kernel_pca:gamma": 0.24197169425840576
        },
        "cost": 0.0,
        "time": 0.17979907989501953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 493,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.15267601463090213,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.30955274582013415,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.229707715547176,
        "time": 0.2579610347747803,
        "additional_info": {
            "duration": 0.2458357810974121,
            "num_run": 494,
            "train_loss": 1.1937885671976016,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 494,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.20272053261271397,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8486303795502871,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.13609607576303778,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1914
        },
        "cost": 0.0,
        "time": 0.11259007453918457,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 495,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2593612816039754,
        "time": 0.3158860206604004,
        "additional_info": {
            "duration": 0.30118417739868164,
            "num_run": 496,
            "train_loss": 1.2066799617130508,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 496,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 277,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.3111419677734375,
        "additional_info": {
            "duration": 0.2895798683166504,
            "num_run": 497,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 497,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002747427526096692,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1139,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 482
        },
        "cost": 0.0,
        "time": 0.14947199821472168,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 498,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.30978222395325367,
            "feature_preprocessor:kitchen_sinks:n_components": 683
        },
        "cost": 0.0,
        "time": 0.10569906234741211,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 499,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01595505809334834,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8541512489318848,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 500,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008241836878932342,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7868218421936035,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 501,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0005509637308128796,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1609,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 14.569724061200077,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.21422982215881348,
        "additional_info": {
            "duration": 0.20450258255004883,
            "num_run": 502,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 502,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014018187058502992,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9521473583847377,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2848627954898377,
            "feature_preprocessor:kitchen_sinks:gamma": 0.15464577307443164,
            "feature_preprocessor:kitchen_sinks:n_components": 2353
        },
        "cost": 0.0,
        "time": 0.1069490909576416,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 503,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8539477527996158,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2633996801880401
        },
        "cost": 1.2463308195380398,
        "time": 0.19385910034179688,
        "additional_info": {
            "duration": 0.1752779483795166,
            "num_run": 504,
            "train_loss": 1.177106300234196,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 504,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.199260950088501,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 505,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018331069179412425,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8807667925200573,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 2,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2027407845578468,
        "time": 0.29334402084350586,
        "additional_info": {
            "duration": 0.282102108001709,
            "num_run": 506,
            "train_loss": 1.18781708097371,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 506,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.37712078107199676,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2280791591133928,
        "time": 0.24023079872131348,
        "additional_info": {
            "duration": 0.22870898246765137,
            "num_run": 507,
            "train_loss": 1.1894403582788715,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 507,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1329,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 86.63241122419944,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.2859189510345459,
        "additional_info": {
            "duration": 0.26859593391418457,
            "num_run": 508,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 508,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4821987156590658,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1445
        },
        "cost": 0.0,
        "time": 0.21691012382507324,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 509,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.2412242889404297,
        "additional_info": {
            "duration": 0.17150115966796875,
            "num_run": 510,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 510,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02968604519981199,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 978,
            "feature_preprocessor:kernel_pca:coef0": 0.5052742845561728
        },
        "cost": 0.0,
        "time": 0.2135159969329834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.151967 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.151967 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 511,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.0754532934012031,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2280791591133928,
        "time": 0.24482107162475586,
        "additional_info": {
            "duration": 0.17307686805725098,
            "num_run": 512,
            "train_loss": 1.1678199115759968,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 512,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9057111740112305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 513,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0019313346474772925,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7814679145812988,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 514,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009980856317720727,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1047
        },
        "cost": 0.0,
        "time": 0.1769719123840332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 515,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007403679592398485,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.0103039741516113,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 516,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 90.47102327100683,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.2128148078918457,
        "additional_info": {
            "duration": 0.19266462326049805,
            "num_run": 517,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 517,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8306303024291992,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 518,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3804976137896066,
            "feature_preprocessor:select_rates_classification:alpha": 0.44786388829834367,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22263288497924805,
        "additional_info": {
            "duration": 0.2122659683227539,
            "num_run": 519,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 519,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8612430095672607,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 520,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.813873291015625,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 521,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.006776292318939007,
            "feature_preprocessor:kitchen_sinks:n_components": 85
        },
        "cost": 0.0,
        "time": 0.13164281845092773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 522,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011427152145312867,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.224060068781918,
        "time": 0.2997870445251465,
        "additional_info": {
            "duration": 0.2807433605194092,
            "num_run": 523,
            "train_loss": 1.1852811828420176,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 523,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.025501939372517483,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1298
        },
        "cost": 0.0,
        "time": 0.13805294036865234,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 524,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1766093109896146,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 520,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 322,
            "feature_preprocessor:kernel_pca:coef0": -0.5906266159188562
        },
        "cost": 0.0,
        "time": 0.2675058841705322,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.00386359 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.00386359 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 525,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017439739158237418,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 209,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2305980296521821,
        "time": 0.28669071197509766,
        "additional_info": {
            "duration": 0.274730920791626,
            "num_run": 526,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 526,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.7980339527130127,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 527,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 16.172642287005797,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2688819787114882,
        "time": 0.2208080291748047,
        "additional_info": {
            "duration": 0.21094179153442383,
            "num_run": 528,
            "train_loss": 1.1965265174443103,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 528,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.3279259204864502,
        "additional_info": {
            "duration": 0.31292200088500977,
            "num_run": 529,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 529,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.019891907049322356,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.228799698094048,
        "time": 3.4283032417297363,
        "additional_info": {
            "duration": 3.415614128112793,
            "num_run": 530,
            "train_loss": 1.2173353254946044,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 530,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012953264127520335,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8384408950805664,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 531,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.850085973739624,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 532,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012077660662307442,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 595
        },
        "cost": 0.0,
        "time": 0.14114594459533691,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 533,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006827501976678305,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8403491973876953,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 534,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016195958624569875,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.0270779132843018,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 535,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.6159845647311916,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.1924426555633545,
        "additional_info": {
            "duration": 0.16473388671875,
            "num_run": 536,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 536,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2279942715512175,
        "time": 0.7090411186218262,
        "additional_info": {
            "duration": 0.6946628093719482,
            "num_run": 537,
            "train_loss": 1.1731263943043633,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 537,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003351664751167075,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8231120629148282,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.260820899626431
        },
        "cost": 1.2517258142124414,
        "time": 0.20755934715270996,
        "additional_info": {
            "duration": 0.18577885627746582,
            "num_run": 538,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 538,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0011149868772505921,
            "feature_preprocessor:select_percentile_classification:percentile": 43.171959758067544,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.2022390365600586,
        "additional_info": {
            "duration": 0.18849515914916992,
            "num_run": 539,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 539,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.053973372469575794,
            "feature_preprocessor:kitchen_sinks:n_components": 510
        },
        "cost": 0.0,
        "time": 0.13253188133239746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 540,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00364716808839793,
            "feature_preprocessor:pca:keep_variance": 0.7774521959356815,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2251813104383191,
        "time": 0.23749613761901855,
        "additional_info": {
            "duration": 0.2256178855895996,
            "num_run": 541,
            "train_loss": 1.181878229099784,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 541,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3458826388276139,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2350158120637325,
        "time": 1.2625210285186768,
        "additional_info": {
            "duration": 1.2282609939575195,
            "num_run": 542,
            "train_loss": 1.1549643183016827,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 542,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 25.04604008139646,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 4.508007740034331e-05
        },
        "cost": 1.2331563280785542,
        "time": 0.23845291137695312,
        "additional_info": {
            "duration": 0.22838282585144043,
            "num_run": 543,
            "train_loss": 1.2025762032341571,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 543,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9058450021307234,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2431585942326486,
        "time": 0.2088000774383545,
        "additional_info": {
            "duration": 0.197005033493042,
            "num_run": 544,
            "train_loss": 1.188794970500172,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 544,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 3.5076758397733943,
            "feature_preprocessor:kitchen_sinks:n_components": 3707
        },
        "cost": 0.0,
        "time": 0.13561511039733887,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 545,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00032358794575437956,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.2470698356628418,
        "additional_info": {
            "duration": 0.23347091674804688,
            "num_run": 546,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 546,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00022379758360197553,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1426
        },
        "cost": 0.0,
        "time": 0.113739013671875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 547,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7147408135282303,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.021973779303350167
        },
        "cost": 1.2482989262205244,
        "time": 0.2269740104675293,
        "additional_info": {
            "duration": 0.20698118209838867,
            "num_run": 548,
            "train_loss": 1.173925014323804,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 548,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005039519573029485,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2452944654438143,
        "time": 0.6881241798400879,
        "additional_info": {
            "duration": 0.669360876083374,
            "num_run": 549,
            "train_loss": 1.1079717838816274,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 549,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.42695802759108464,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.819044828414917,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 550,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0004001178552969218,
            "feature_preprocessor:select_rates_classification:alpha": 0.4961364893796161,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.1952047348022461,
        "additional_info": {
            "duration": 0.18561887741088867,
            "num_run": 551,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 551,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.698655128479004,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 552,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03478590179782216,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.7446062564849854,
        "additional_info": {
            "duration": 0.7283127307891846,
            "num_run": 553,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 553,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004405607736486387,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 221,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1417
        },
        "cost": 0.0,
        "time": 0.16750192642211914,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 554,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7062700549061851,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12437381743623827,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.250012370216483,
        "time": 1.737860918045044,
        "additional_info": {
            "duration": 1.7162108421325684,
            "num_run": 555,
            "train_loss": 1.173925014323804,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 555,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002838777129430022,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 2865,
            "feature_preprocessor:nystroem_sampler:coef0": 0.8538687998518348,
            "feature_preprocessor:nystroem_sampler:gamma": 0.05052050945656687
        },
        "cost": 1.2305980296521821,
        "time": 0.699383020401001,
        "additional_info": {
            "duration": 0.6867890357971191,
            "num_run": 556,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 556,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.937108039855957,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 557,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020146287406272976,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8933508396148682,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 558,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9750881195068359,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 559,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1846,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 5.754708475211693,
            "feature_preprocessor:kitchen_sinks:n_components": 191
        },
        "cost": 0.0,
        "time": 0.19244599342346191,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 560,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023627032835614952,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.29091906547546387,
        "additional_info": {
            "duration": 0.27826523780822754,
            "num_run": 561,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 561,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2330497159769178,
        "time": 0.22504401206970215,
        "additional_info": {
            "duration": 0.21407318115234375,
            "num_run": 562,
            "train_loss": 1.1890166383320135,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 562,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 169
        },
        "cost": 0.0,
        "time": 0.13850927352905273,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 563,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3672931878878627,
            "feature_preprocessor:select_percentile_classification:percentile": 75.97897544162991,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.245041813352958,
        "time": 0.23474693298339844,
        "additional_info": {
            "duration": 0.21978116035461426,
            "num_run": 564,
            "train_loss": 1.1611802549654107,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 564,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0008905023275993676,
            "feature_preprocessor:select_percentile_classification:percentile": 64.59585812338707,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2376807225917414,
        "time": 0.23015093803405762,
        "additional_info": {
            "duration": 0.21345090866088867,
            "num_run": 565,
            "train_loss": 1.1720018696208456,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 565,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002535914714038565,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9593489170074463,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 566,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01588399417960724,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1753,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 90.59621696280512,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2367292560596912,
        "time": 0.32366108894348145,
        "additional_info": {
            "duration": 0.310014009475708,
            "num_run": 567,
            "train_loss": 1.1628360788534222,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 567,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00016258334102521688,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.326867341995239,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 568,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1794,
            "feature_preprocessor:kernel_pca:gamma": 0.2240614641193403
        },
        "cost": 0.0,
        "time": 0.1447439193725586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 569,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007158191173593954,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1988,
            "feature_preprocessor:kernel_pca:coef0": 0.9127750053737114,
            "feature_preprocessor:kernel_pca:degree": 2,
            "feature_preprocessor:kernel_pca:gamma": 0.03217515210242173
        },
        "cost": 0.0,
        "time": 0.1861870288848877,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 570,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 59.00033105307846,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2416998129232162,
        "time": 0.25452709197998047,
        "additional_info": {
            "duration": 0.23918509483337402,
            "num_run": 571,
            "train_loss": 1.1661184347048799,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 571,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 196,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2305980296521821,
        "time": 0.30219101905822754,
        "additional_info": {
            "duration": 0.2865128517150879,
            "num_run": 572,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 572,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.039399067027902815,
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 420,
            "feature_preprocessor:nystroem_sampler:coef0": -0.4806250286046554,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0001480568305114795
        },
        "cost": 1.2305980296521821,
        "time": 0.2892332077026367,
        "additional_info": {
            "duration": 0.2642209529876709,
            "num_run": 573,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 573,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03588510661793289,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 31
        },
        "cost": 0.0,
        "time": 0.10477375984191895,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 574,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04503876092522502,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2483838137826997,
        "time": 0.5874669551849365,
        "additional_info": {
            "duration": 0.5756092071533203,
            "num_run": 575,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 575,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2464177176958848,
        "time": 0.2542300224304199,
        "additional_info": {
            "duration": 0.2373819351196289,
            "num_run": 576,
            "train_loss": 1.175515657279,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 576,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.020900515851543663,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.5336482524871826,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 577,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00023076423294114996,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8081710338592529,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 578,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00971514622131492,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8264250755310059,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 579,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00120181240271082,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8143142779022455,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04237547408054043,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1193
        },
        "cost": 0.0,
        "time": 0.11255407333374023,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 580,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.20827317237854004,
        "additional_info": {
            "duration": 0.19282102584838867,
            "num_run": 581,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 581,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8049180507659912,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 582,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.22817612478083024,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8426060676574707,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 583,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015445726045887728,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8259079456329346,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 584,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.04664206368310886,
            "feature_preprocessor:kitchen_sinks:gamma": 6.883860170561302,
            "feature_preprocessor:kitchen_sinks:n_components": 144
        },
        "cost": 0.0,
        "time": 0.13147521018981934,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 585,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2350158120637325,
        "time": 0.23542499542236328,
        "additional_info": {
            "duration": 0.2239229679107666,
            "num_run": 586,
            "train_loss": 1.156610378214839,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 586,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1091,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "False"
        },
        "cost": 1.251109876737753,
        "time": 0.8313090801239014,
        "additional_info": {
            "duration": 0.8107731342315674,
            "num_run": 587,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 587,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8157367706298828,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 588,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1396,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 1422
        },
        "cost": 0.0,
        "time": 0.1921672821044922,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 589,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010553422341896887,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1441
        },
        "cost": 0.0,
        "time": 0.13228511810302734,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 590,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008704170645958678,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 2.310551166534424,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 591,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2305980296521821,
        "time": 0.20366406440734863,
        "additional_info": {
            "duration": 0.18668389320373535,
            "num_run": 592,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 592,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.004621386445579253,
            "feature_preprocessor:select_percentile_classification:percentile": 37.73910332725551,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2722851315682742,
        "time": 0.2304079532623291,
        "additional_info": {
            "duration": 0.21964287757873535,
            "num_run": 593,
            "train_loss": 1.1859265706207172,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 593,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7105675004562106,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10558213237449583,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 843
        },
        "cost": 0.0,
        "time": 0.13033509254455566,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 594,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 19
        },
        "cost": 0.0,
        "time": 0.10849404335021973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 595,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1133,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.2992659190167438,
            "feature_preprocessor:kitchen_sinks:n_components": 5286
        },
        "cost": 0.0,
        "time": 0.14708566665649414,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 596,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16842791216394426,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1112
        },
        "cost": 0.0,
        "time": 0.13584208488464355,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 597,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002605664723590227,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 293
        },
        "cost": 0.0,
        "time": 0.10471320152282715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 598,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9472655898428253,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.05571760808331295,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 566,
            "feature_preprocessor:kernel_pca:coef0": 0.16849155493154866
        },
        "cost": 0.0,
        "time": 0.17949509620666504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.153552 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.153552 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 599,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2279942715512175,
        "time": 3.3816142082214355,
        "additional_info": {
            "duration": 3.3669650554656982,
            "num_run": 600,
            "train_loss": 1.1764739310886365,
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 600,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.3122901916503906,
        "additional_info": {
            "duration": 0.2966949939727783,
            "num_run": 601,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 601,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.053564618766573945,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 86
        },
        "cost": 0.0,
        "time": 0.10454034805297852,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 602,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 1.1664149761199951,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 603,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01324254406890384,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8106718063354492,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 604,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008918337620021335,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8421230316162109,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 605,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 3.105842686898183,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.20696592330932617,
        "additional_info": {
            "duration": 0.19707202911376953,
            "num_run": 606,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 606,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00747767962096653,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8100160992106173,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23739964035446304,
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "ward",
            "feature_preprocessor:feature_agglomeration:n_clusters": 110,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2463308195380398,
        "time": 0.3597676753997803,
        "additional_info": {
            "duration": 0.29916977882385254,
            "num_run": 607,
            "train_loss": 1.177106300234196,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 607,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00017247976751321074,
            "feature_preprocessor:select_percentile_classification:percentile": 34.30231746875248,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2482989262205244,
        "time": 0.15590119361877441,
        "additional_info": {
            "duration": 0.14586377143859863,
            "num_run": 608,
            "train_loss": 1.2005390577241084,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 608,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009609456663473874,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.9501609802246094,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 609,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.270656575134491,
        "time": 0.7358779907226562,
        "additional_info": {
            "duration": 0.7082679271697998,
            "num_run": 610,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 610,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3785559747086482,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7797016662665786,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.02399912176847032,
            "feature_preprocessor:kitchen_sinks:gamma": 0.46673009457910564,
            "feature_preprocessor:kitchen_sinks:n_components": 111
        },
        "cost": 0.0,
        "time": 0.11495709419250488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 611,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1802,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 0.00010364773895979036,
            "feature_preprocessor:kitchen_sinks:n_components": 129
        },
        "cost": 0.0,
        "time": 0.13509297370910645,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 612,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.5414040696181663,
        "time": 1.127539873123169,
        "additional_info": {
            "duration": 1.1147840023040771,
            "num_run": 613,
            "train_loss": 1.5415537114284534,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 613,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2546433768313068,
        "time": 3.691560745239258,
        "additional_info": {
            "duration": 3.6733181476593018,
            "num_run": 614,
            "train_loss": 1.1870380766710948,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 614,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 138,
            "feature_preprocessor:kernel_pca:gamma": 0.10998363833114905
        },
        "cost": 0.0,
        "time": 0.17365622520446777,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 615,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 61,
            "feature_preprocessor:kernel_pca:coef0": 0.4615225429222014
        },
        "cost": 0.0,
        "time": 0.16489291191101074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 616,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1777708312871892,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.80222487449646,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 617,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037130204104390274,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00997101510322671,
            "feature_preprocessor:kitchen_sinks:n_components": 6183
        },
        "cost": 0.0,
        "time": 0.10417699813842773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 618,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8602880815013907,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10146875959531972,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "True",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2619215906260173,
        "time": 0.6670949459075928,
        "additional_info": {
            "duration": 0.6497418880462646,
            "num_run": 619,
            "train_loss": 1.0265032094843836,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 619,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003404205044173262,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.4164600372314453,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 620,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1125112416450709,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7879761905596605,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.15137995946645283,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 1435.2299709780923,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.00011049137210954401
        },
        "cost": 1.2201041414731577,
        "time": 0.16397714614868164,
        "additional_info": {
            "duration": 0.15409612655639648,
            "num_run": 621,
            "train_loss": 1.1678753285339571,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 621,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00010318028774039637,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1444,
            "feature_preprocessor:kernel_pca:coef0": -0.4498114912003863,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 4.425350802434043
        },
        "cost": 0.0,
        "time": 0.13462305068969727,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 622,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.39850865551968423,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 206
        },
        "cost": 0.0,
        "time": 0.13300204277038574,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 623,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.006285564972148742,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.789294958114624,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 624,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.7038739983197121,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 4,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.257033910728998,
        "time": 0.3067309856414795,
        "additional_info": {
            "duration": 0.2619059085845947,
            "num_run": 625,
            "train_loss": 1.1777516880128955,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 625,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2305980296521821,
        "time": 0.17909479141235352,
        "additional_info": {
            "duration": 0.1592240333557129,
            "num_run": 626,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 626,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.06623189913512857,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1078,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kitchen_sinks:gamma": 0.0037882381415871753,
            "feature_preprocessor:kitchen_sinks:n_components": 64
        },
        "cost": 0.0,
        "time": 0.14682984352111816,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 627,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9931237524471128,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2945518950213713,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1132
        },
        "cost": 0.0,
        "time": 0.13933205604553223,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 628,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.18255652380793252,
            "feature_preprocessor:select_percentile_classification:percentile": 90.17704223897992,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.226280827555259,
        "time": 0.21778321266174316,
        "additional_info": {
            "duration": 0.20165610313415527,
            "num_run": 629,
            "train_loss": 1.1627708979206066,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 629,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 815
        },
        "cost": 0.0,
        "time": 0.1588878631591797,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 630,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 324,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2305980296521821,
        "time": 0.29837894439697266,
        "additional_info": {
            "duration": 0.2749490737915039,
            "num_run": 631,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 631,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.13597935748488166,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.14063405990600586,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 632,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.26600256565805597,
            "feature_preprocessor:pca:keep_variance": 0.5149840342395591,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.22769594192504883,
        "additional_info": {
            "duration": 0.21063613891601562,
            "num_run": 633,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 633,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 723
        },
        "cost": 0.0,
        "time": 0.11102414131164551,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 634,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9402542254971346,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.12784490796205394,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1286
        },
        "cost": 0.0,
        "time": 0.13942885398864746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 635,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.012740226254422974,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.821972131729126,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 636,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8373439311981201,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 637,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 0.8495891094207764,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 638,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0313770816691098,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.040994644165039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 639,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1070
        },
        "cost": 0.0,
        "time": 0.17145919799804688,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 640,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.4714443510288999,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2836730480194092,
        "additional_info": {
            "duration": 0.2728729248046875,
            "num_run": 641,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 641,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 811
        },
        "cost": 0.0,
        "time": 0.10464811325073242,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 642,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020994026506845266,
            "feature_preprocessor:select_percentile_classification:percentile": 93.9472812820607,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22269010543823242,
        "additional_info": {
            "duration": 0.2075340747833252,
            "num_run": 643,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 643,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1209,
            "feature_preprocessor:kernel_pca:gamma": 0.0036437917232232625
        },
        "cost": 0.0,
        "time": 0.15847396850585938,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 644,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6591837195333928,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2479848861694336,
        "additional_info": {
            "duration": 0.2368028163909912,
            "num_run": 645,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 645,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7214226187526929,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.012000294405257139,
            "feature_preprocessor:select_percentile_classification:percentile": 46.47620304767889,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2500972577786582,
        "time": 0.2846379280090332,
        "additional_info": {
            "duration": 0.270435094833374,
            "num_run": 646,
            "train_loss": 1.180988390881248,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 646,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005277377093400703,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2356297389427513,
        "time": 0.4605848789215088,
        "additional_info": {
            "duration": 0.4491748809814453,
            "num_run": 647,
            "train_loss": 1.178586109273471,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 647,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014716157911875006
        },
        "cost": 1.2305980296521821,
        "time": 0.20831727981567383,
        "additional_info": {
            "duration": 0.19015908241271973,
            "num_run": 648,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 648,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1084,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 210
        },
        "cost": 0.0,
        "time": 0.13500595092773438,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 649,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.038057185648397954,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.611684083938599,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 650,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.037510645729107714,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1088
        },
        "cost": 0.0,
        "time": 0.13670730590820312,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 651,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 647
        },
        "cost": 0.0,
        "time": 0.1368250846862793,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 652,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005176021101509005,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7951913230925183,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23091621307484833,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 501,
            "feature_preprocessor:kernel_pca:gamma": 0.00011165671534774983
        },
        "cost": 0.0,
        "time": 0.14170503616333008,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 653,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1600,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal"
        },
        "cost": 1.2468401449110917,
        "time": 0.27568602561950684,
        "additional_info": {
            "duration": 0.25824499130249023,
            "num_run": 654,
            "train_loss": 1.1561964222428363,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 654,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0018864743562952786,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1717,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:select_percentile_classification:percentile": 40.53908699104272,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2366681036326468,
        "time": 0.2912178039550781,
        "additional_info": {
            "duration": 0.2814819812774658,
            "num_run": 655,
            "train_loss": 1.2110835875897412,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 655,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7038063243420783,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.10343288519445627
        },
        "cost": 1.2254576976643063,
        "time": 0.2167651653289795,
        "additional_info": {
            "duration": 0.2020711898803711,
            "num_run": 656,
            "train_loss": 1.217279908536644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 656,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.060885824206283724,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0006645808881629149,
            "feature_preprocessor:kitchen_sinks:n_components": 556
        },
        "cost": 0.0,
        "time": 0.10926008224487305,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 657,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.478895902633667,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 658,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.40720539683833734,
            "feature_preprocessor:pca:keep_variance": 0.5464809271603747,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2380202728404428,
        "time": 0.23831915855407715,
        "additional_info": {
            "duration": 0.2249891757965088,
            "num_run": 659,
            "train_loss": 1.179710633956989,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 659,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.12293148141174379,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 60,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.3375689139201524,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 14,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2463328301337095,
        "time": 0.22042512893676758,
        "additional_info": {
            "duration": 0.2092909812927246,
            "num_run": 660,
            "train_loss": 1.1892741074049902,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 660,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 27
        },
        "cost": 0.0,
        "time": 0.13389182090759277,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 661,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 273,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2350158120637325,
        "time": 0.3461120128631592,
        "additional_info": {
            "duration": 0.328110933303833,
            "num_run": 662,
            "train_loss": 1.156610378214839,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 662,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.27454897576273124,
            "feature_preprocessor:select_rates_classification:alpha": 0.46352164619974384,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 1.2305980296521821,
        "time": 0.1590557098388672,
        "additional_info": {
            "duration": 0.1487870216369629,
            "num_run": 663,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 663,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1141635392086804,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.779333356565642,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2991845759702264,
            "feature_preprocessor:kitchen_sinks:gamma": 0.012585697729745994,
            "feature_preprocessor:kitchen_sinks:n_components": 8858
        },
        "cost": 0.0,
        "time": 0.10842609405517578,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 664,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00640677599911609,
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1919,
            "feature_preprocessor:kernel_pca:gamma": 0.9863020382161172
        },
        "cost": 0.0,
        "time": 0.18955326080322266,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 665,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00040835481333640445,
            "feature_preprocessor:select_percentile_classification:percentile": 80.60637400967433,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.245041813352958,
        "time": 0.22465777397155762,
        "additional_info": {
            "duration": 0.20453190803527832,
            "num_run": 666,
            "train_loss": 1.1611802549654107,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 666,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009846238215829889,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8596333770259521,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2329648284147425,
        "time": 0.24365782737731934,
        "additional_info": {
            "duration": 0.23166418075561523,
            "num_run": 667,
            "train_loss": 1.1905518643292492,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 667,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 0.007407792450418639,
            "feature_preprocessor:kitchen_sinks:n_components": 1114
        },
        "cost": 0.0,
        "time": 0.1043400764465332,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 668,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "rbf",
            "feature_preprocessor:kernel_pca:n_components": 1208,
            "feature_preprocessor:kernel_pca:gamma": 0.0003229490111290651
        },
        "cost": 0.0,
        "time": 0.24326205253601074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 669,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005137151378278908,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.967851161956787,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 670,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.9572403493275307,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2467552573489165,
        "time": 0.29401183128356934,
        "additional_info": {
            "duration": 0.2771787643432617,
            "num_run": 671,
            "train_loss": 1.1727026743575055,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 671,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011663991195860186,
            "feature_preprocessor:select_rates_classification:alpha": 0.25849842934442013,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2296228279850008,
        "time": 0.19985318183898926,
        "additional_info": {
            "duration": 0.18256497383117676,
            "num_run": 672,
            "train_loss": 1.1771617171921565,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 672,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.021000349089950545,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.9998390674591064,
        "additional_info": {
            "duration": 0.9839310646057129,
            "num_run": 673,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 673,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.546380996704102,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 674,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.46244069553435574,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9750658754640151,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17623568547803287,
            "feature_preprocessor:select_rates_classification:alpha": 0.2592701381363113,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.24034764371542,
        "time": 0.20455312728881836,
        "additional_info": {
            "duration": 0.1783292293548584,
            "num_run": 675,
            "train_loss": 1.1821226795396207,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 675,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.401321887969971,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 676,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.35932503415661354,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 365,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.8501051826482319,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2332194911012684,
        "time": 0.31011295318603516,
        "additional_info": {
            "duration": 0.29227614402770996,
            "num_run": 677,
            "train_loss": 1.1714249174332465,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 677,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01988658959181165,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.695733070373535,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 678,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 363,
            "feature_preprocessor:kernel_pca:coef0": -0.9015256213569984,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.04139332813657756
        },
        "cost": 0.0,
        "time": 0.45123720169067383,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.00152018 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.00152018 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 679,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.26949405670166,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 680,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0002916349055385202,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 953,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:pca:keep_variance": 0.6136605074095596,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.224737158683651,
        "time": 0.2642951011657715,
        "additional_info": {
            "duration": 0.2501790523529053,
            "num_run": 681,
            "train_loss": 1.2070678804187736,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 681,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006693432816266665
        },
        "cost": 1.2350158120637325,
        "time": 0.24311208724975586,
        "additional_info": {
            "duration": 0.22934913635253906,
            "num_run": 682,
            "train_loss": 1.156610378214839,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 682,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.016081878713093977,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9266532154430285,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.23219803300824382,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.05985095687554831,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.217715618171136,
        "time": 0.24900293350219727,
        "additional_info": {
            "duration": 0.23766803741455078,
            "num_run": 683,
            "train_loss": 1.179710633956989,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 683,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.245041813352958,
        "time": 0.22285914421081543,
        "additional_info": {
            "duration": 0.21053266525268555,
            "num_run": 684,
            "train_loss": 1.1690422515422954,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 684,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00020558533365140397,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1028,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.22658265637642658,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.248468701344875,
        "time": 0.2922849655151367,
        "additional_info": {
            "duration": 0.2771880626678467,
            "num_run": 685,
            "train_loss": 1.176105628099739,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 685,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11675283898182107,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7424424539703475,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.049927366288815125,
            "feature_preprocessor:kitchen_sinks:gamma": 0.0003813940322345611,
            "feature_preprocessor:kitchen_sinks:n_components": 136
        },
        "cost": 0.0,
        "time": 0.140272855758667,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 686,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1959,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2305980296521821,
        "time": 0.9006881713867188,
        "additional_info": {
            "duration": 0.8859410285949707,
            "num_run": 687,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 687,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.2860816265839492,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.735852956771851,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 688,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.3938469853842359,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.858132839202881,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 689,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "cosine",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 60,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.229707715547176,
        "time": 0.3656330108642578,
        "additional_info": {
            "duration": 0.3529539108276367,
            "num_run": 690,
            "train_loss": 1.1764739310886365,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 690,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.01647105244071445,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2388256993832734,
        "time": 0.23875832557678223,
        "additional_info": {
            "duration": 0.22766995429992676,
            "num_run": 691,
            "train_loss": 1.2156338486234874,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 691,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.11900530254533737,
            "feature_preprocessor:select_rates_classification:alpha": 0.12398546719113736,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2499512177894385,
        "time": 0.18476223945617676,
        "additional_info": {
            "duration": 0.1712634563446045,
            "num_run": 692,
            "train_loss": 1.2074589660156658,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 692,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14719330863735736,
            "feature_preprocessor:nystroem_sampler:kernel": "cosine",
            "feature_preprocessor:nystroem_sampler:n_components": 3619
        },
        "cost": 1.2305980296521821,
        "time": 0.45545196533203125,
        "additional_info": {
            "duration": 0.4400491714477539,
            "num_run": 693,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 693,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.013571551085363542,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.18035888671875,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 694,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1024838411028008,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.969707328133121,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2991449477999019,
            "feature_preprocessor:polynomial:degree": 3,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2361390643158032,
        "time": 1.1119072437286377,
        "additional_info": {
            "duration": 1.0980911254882812,
            "num_run": 695,
            "train_loss": 1.0711684949714477,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 695,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.11676168757950699,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.14043188095092773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 696,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.211566686630249,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 697,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008608496415867776,
            "feature_preprocessor:kitchen_sinks:gamma": 0.08487893587899126,
            "feature_preprocessor:kitchen_sinks:n_components": 122
        },
        "cost": 0.0,
        "time": 0.15659308433532715,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 698,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00030549753390701496,
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1805,
            "feature_preprocessor:kernel_pca:coef0": 0.20336441530902838
        },
        "cost": 0.0,
        "time": 0.25045180320739746,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.13994 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.13994 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 699,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0003930706824179663,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.55603101626878,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 7,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2583249275097497,
        "time": 0.2510850429534912,
        "additional_info": {
            "duration": 0.23989391326904297,
            "num_run": 700,
            "train_loss": 1.1742933173127015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 700,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.189853191375732,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 701,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.4955923070021149,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6713048613907325,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 16,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 3,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2475419044494629,
        "additional_info": {
            "duration": 0.23649096488952637,
            "num_run": 702,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 702,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.20663595199585,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 703,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 88.97106167874516,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.1898057460784912,
        "additional_info": {
            "duration": 0.17618894577026367,
            "num_run": 704,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 704,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8647620010734687,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.04337145631526009,
            "feature_preprocessor:kitchen_sinks:gamma": 5.29855578869453,
            "feature_preprocessor:kitchen_sinks:n_components": 1278
        },
        "cost": 0.0,
        "time": 0.11276793479919434,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 705,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.08150643082139183,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.60357403755188,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 706,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.112932205200195,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 707,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9768998243474694,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2720478302097022,
            "feature_preprocessor:kitchen_sinks:gamma": 0.004172884244730281,
            "feature_preprocessor:kitchen_sinks:n_components": 2512
        },
        "cost": 0.0,
        "time": 0.1370999813079834,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 708,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00014303710248638268,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.38464617729187,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 709,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0021432829374014423,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8030503864155101,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2384622079813819,
            "feature_preprocessor:kitchen_sinks:gamma": 0.9200461163945531,
            "feature_preprocessor:kitchen_sinks:n_components": 4158
        },
        "cost": 0.0,
        "time": 0.10969066619873047,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 710,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 931
        },
        "cost": 0.0,
        "time": 0.13194799423217773,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 711,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05242099937431209,
            "feature_preprocessor:kitchen_sinks:gamma": 2.2963419382193013,
            "feature_preprocessor:kitchen_sinks:n_components": 111
        },
        "cost": 0.0,
        "time": 0.10498309135437012,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 712,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 34
        },
        "cost": 0.0,
        "time": 0.13637495040893555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 713,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.033318644814435104,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.019266128540039,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 714,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.03554747660074583,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.329567909240723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 715,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8289023752290556,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 13,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.228799698094048,
        "time": 0.24096107482910156,
        "additional_info": {
            "duration": 0.22929668426513672,
            "num_run": 716,
            "train_loss": 1.2189813854077607,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 716,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.01084577925100075,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.829149007797241,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 717,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 387,
            "feature_preprocessor:nystroem_sampler:coef0": 0.06726171386172952,
            "feature_preprocessor:nystroem_sampler:gamma": 6.721745715734857e-05
        },
        "cost": 1.2305980296521821,
        "time": 0.3872509002685547,
        "additional_info": {
            "duration": 0.35898303985595703,
            "num_run": 718,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 718,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1072,
            "feature_preprocessor:kernel_pca:coef0": -0.31373731911140923,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.011478032973969482
        },
        "cost": 0.0,
        "time": 0.26045989990234375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (4.68391e+06 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (4.68391e+06 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 719,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0014720757523490294,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 106,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_percentile_classification:percentile": 37.55896469507217,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2416998129232162,
        "time": 0.17002177238464355,
        "additional_info": {
            "duration": 0.15959906578063965,
            "num_run": 720,
            "train_loss": 1.18056467093439,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 720,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.21771178531787372,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 68,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:kitchen_sinks:gamma": 2.070100760535387,
            "feature_preprocessor:kitchen_sinks:n_components": 512
        },
        "cost": 0.0,
        "time": 0.13831233978271484,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 721,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.765338865154094,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.11915794466985725,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49180557432940597,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 9,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 11,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2272560292224401,
        "time": 0.2294173240661621,
        "additional_info": {
            "duration": 0.21698594093322754,
            "num_run": 722,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 722,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.002252992716390795,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1812,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:pca:keep_variance": 0.9622942128207697,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2313362719809593,
        "time": 0.2663869857788086,
        "additional_info": {
            "duration": 0.24947404861450195,
            "num_run": 723,
            "train_loss": 1.1727580913154658,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 723,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.000431997964724179,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.793470135678357,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.17304069307882905,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 1330
        },
        "cost": 0.0,
        "time": 0.13753485679626465,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 724,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.011140255004299857,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.758310317993164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 725,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 67.2582388634446,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.228164046675568,
        "time": 0.21065497398376465,
        "additional_info": {
            "duration": 0.19761371612548828,
            "num_run": 726,
            "train_loss": 1.1760502111417788,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 726,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14140447990418825,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9312152891035067,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.29426736223416106,
            "feature_preprocessor:kernel_pca:kernel": "cosine",
            "feature_preprocessor:kernel_pca:n_components": 751
        },
        "cost": 0.0,
        "time": 0.17694401741027832,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 727,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1000,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:select_rates_classification:alpha": 0.13482616487799362,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2231086022498678,
        "time": 0.22177815437316895,
        "additional_info": {
            "duration": 0.21152305603027344,
            "num_run": 728,
            "train_loss": 1.1710663784192041,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 728,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.007633143277507773,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "logcosh",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.245041813352958,
        "time": 1.9940757751464844,
        "additional_info": {
            "duration": 1.9789998531341553,
            "num_run": 729,
            "train_loss": 1.1673407746711786,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 729,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0009463697646773193,
            "feature_preprocessor:select_percentile_classification:percentile": 2.9395970680851917,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.22897100448608398,
        "additional_info": {
            "duration": 0.21813583374023438,
            "num_run": 730,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 730,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0711823483563504,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 3.4727983474731445,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 731,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.01676715667996739,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.20787596702575684,
        "additional_info": {
            "duration": 0.19655418395996094,
            "num_run": 732,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 732,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1367,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1974,
            "feature_preprocessor:kernel_pca:coef0": 0.5263993774758944,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.005870364178786341
        },
        "cost": 0.0,
        "time": 0.38654303550720215,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 733,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2"
        },
        "cost": 1.2363068288444843,
        "time": 0.2423698902130127,
        "additional_info": {
            "duration": 0.22501516342163086,
            "num_run": 734,
            "train_loss": 1.1856691015477405,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 734,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.03227545738164617,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2304065299883702,
        "time": 0.1844019889831543,
        "additional_info": {
            "duration": 0.17356610298156738,
            "num_run": 735,
            "train_loss": 1.2134304522395574,
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 735,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.015490384069334834,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 5.919238090515137,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 736,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.6571369462129866,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 10,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 19,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.23464298248291016,
        "additional_info": {
            "duration": 0.22272706031799316,
            "num_run": 737,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 737,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 89.22687196467338,
            "feature_preprocessor:select_percentile_classification:score_func": "mutual_info"
        },
        "cost": 1.2305980296521821,
        "time": 0.26338911056518555,
        "additional_info": {
            "duration": 0.24728703498840332,
            "num_run": 738,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 738,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0070069592307869365,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1165,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.49114256042628524,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 18,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2305980296521821,
        "time": 0.2559387683868408,
        "additional_info": {
            "duration": 0.24445796012878418,
            "num_run": 739,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 739,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "cube",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 628
        },
        "cost": 0.0,
        "time": 0.13727807998657227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 740,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.8846558962698912,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.03967262682434826,
            "feature_preprocessor:liblinear_svc_preprocessor:C": 226.49167452449257,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0005346250055216101
        },
        "cost": 1.2473711948236048,
        "time": 0.18527507781982422,
        "additional_info": {
            "duration": 0.17489218711853027,
            "num_run": 741,
            "train_loss": 1.2034986758026587,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 741,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9624026418080751,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.18727494424303495,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "True",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "entropy",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8008688190204944,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 1,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 8,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2345933848485258,
        "time": 0.253187894821167,
        "additional_info": {
            "duration": 0.2413330078125,
            "num_run": 742,
            "train_loss": 1.185447433715899,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 742,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 18.182734148683874,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.18074274063110352,
        "additional_info": {
            "duration": 0.1708688735961914,
            "num_run": 743,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 743,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 859,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "uniform",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 385,
            "feature_preprocessor:feature_agglomeration:pooling_func": "max"
        },
        "cost": 1.2266183672082904,
        "time": 0.33583712577819824,
        "additional_info": {
            "duration": 0.32407402992248535,
            "num_run": 744,
            "train_loss": 1.1583118550859557,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 744,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kitchen_sinks:gamma": 5.0790125452780766e-05,
            "feature_preprocessor:kitchen_sinks:n_components": 3537
        },
        "cost": 0.0,
        "time": 0.10741496086120605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 745,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "extra_trees_preproc_for_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.407938813835658,
            "feature_preprocessor:extra_trees_preproc_for_classification:bootstrap": "False",
            "feature_preprocessor:extra_trees_preproc_for_classification:criterion": "gini",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_depth": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:max_features": 0.8580083160563738,
            "feature_preprocessor:extra_trees_preproc_for_classification:max_leaf_nodes": "None",
            "feature_preprocessor:extra_trees_preproc_for_classification:min_impurity_decrease": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_leaf": 6,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_samples_split": 15,
            "feature_preprocessor:extra_trees_preproc_for_classification:min_weight_fraction_leaf": 0.0,
            "feature_preprocessor:extra_trees_preproc_for_classification:n_estimators": 100
        },
        "cost": 1.2309987323279277,
        "time": 0.24787187576293945,
        "additional_info": {
            "duration": 0.23690128326416016,
            "num_run": 746,
            "train_loss": 1.182579033836444,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 746,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 1085,
            "feature_preprocessor:nystroem_sampler:coef0": -0.0003612677583491042,
            "feature_preprocessor:nystroem_sampler:degree": 4,
            "feature_preprocessor:nystroem_sampler:gamma": 5.2333736239734225
        },
        "cost": 1.2347631599728763,
        "time": 0.7525739669799805,
        "additional_info": {
            "duration": 0.7343640327453613,
            "num_run": 747,
            "train_loss": 1.0,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 747,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 4.613867998123169,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 748,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.10786619288922102,
            "feature_preprocessor:select_rates_classification:alpha": 0.0167071399064508,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13896393775939941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 749,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "quantile_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.16969285338509696,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles": 1945,
            "data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution": "normal",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 463,
            "feature_preprocessor:kernel_pca:coef0": 0.3353756719748162,
            "feature_preprocessor:kernel_pca:degree": 5,
            "feature_preprocessor:kernel_pca:gamma": 0.0002548548903801571
        },
        "cost": 0.0,
        "time": 0.3787567615509033,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 750,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05024886317066324,
            "feature_preprocessor:select_percentile_classification:percentile": 45.844181478387966,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.245041813352958,
        "time": 0.19986701011657715,
        "additional_info": {
            "duration": 0.18413615226745605,
            "num_run": 751,
            "train_loss": 1.1744041512286223,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 751,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.33704340386991,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1604,
            "feature_preprocessor:kernel_pca:coef0": -0.19981337099589602,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.00448406598706486
        },
        "cost": 0.0,
        "time": 0.2180790901184082,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.12073 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.12073 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 752,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.02361725571350065,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.11781191825866699,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 753,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7254343959124232,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.010039498856171471,
            "feature_preprocessor:select_percentile_classification:percentile": 92.4210772736773,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2451267009151332,
        "time": 0.2395000457763672,
        "additional_info": {
            "duration": 0.22354984283447266,
            "num_run": 754,
            "train_loss": 1.1681327976069338,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 754,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0006576564104327193
        },
        "cost": 1.2305980296521821,
        "time": 0.2155170440673828,
        "additional_info": {
            "duration": 0.20213890075683594,
            "num_run": 755,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 755,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.14676374596290045,
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1220,
            "feature_preprocessor:kernel_pca:coef0": 0.4600447851042455,
            "feature_preprocessor:kernel_pca:degree": 4,
            "feature_preprocessor:kernel_pca:gamma": 0.0036035487310883433
        },
        "cost": 0.0,
        "time": 0.33956098556518555,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 756,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.26350750344312035,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11787819862365723,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 757,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "sigmoid",
            "feature_preprocessor:nystroem_sampler:n_components": 90,
            "feature_preprocessor:nystroem_sampler:coef0": 0.44077643669476774,
            "feature_preprocessor:nystroem_sampler:gamma": 0.00019098074968345124
        },
        "cost": 1.2305980296521821,
        "time": 0.18910598754882812,
        "additional_info": {
            "duration": 0.1766350269317627,
            "num_run": 758,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 758,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.1789943893702266,
            "feature_preprocessor:select_rates_classification:score_func": "f_classif",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2305980296521821,
        "time": 0.2192368507385254,
        "additional_info": {
            "duration": 0.20707201957702637,
            "num_run": 759,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 759,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:feature_agglomeration:affinity": "euclidean",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 28,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2305980296521821,
        "time": 0.2916879653930664,
        "additional_info": {
            "duration": 0.280703067779541,
            "num_run": 760,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 760,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010703874973905972,
            "feature_preprocessor:select_rates_classification:alpha": 0.11985490233555572,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11144614219665527,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 761,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0059446453968496635,
            "feature_preprocessor:pca:keep_variance": 0.7365549711041931,
            "feature_preprocessor:pca:whiten": "True"
        },
        "cost": 1.2305980296521821,
        "time": 0.24414801597595215,
        "additional_info": {
            "duration": 0.2287290096282959,
            "num_run": 762,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 762,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "poly",
            "feature_preprocessor:kernel_pca:n_components": 1471,
            "feature_preprocessor:kernel_pca:coef0": 0.0994617783898295,
            "feature_preprocessor:kernel_pca:degree": 3,
            "feature_preprocessor:kernel_pca:gamma": 0.0010325904717104193
        },
        "cost": 0.0,
        "time": 0.17202425003051758,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 53, in fit\n    if len(self.preprocessor.alphas_ / self.preprocessor.lambdas_) == 0:\nAttributeError: 'KernelPCA' object has no attribute 'alphas_'\n",
            "error": "AttributeError(\"'KernelPCA' object has no attribute 'alphas_'\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 763,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.1,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11124300956726074,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 764,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0038080782643648533,
            "feature_preprocessor:select_rates_classification:alpha": 0.2332503123720286,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.11091780662536621,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 765,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.29250149261910585,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13856720924377441,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 766,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010493551722240702,
            "feature_preprocessor:select_rates_classification:alpha": 0.0847992988178507,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 1.2280791591133928,
        "time": 0.18523120880126953,
        "additional_info": {
            "duration": 0.16631317138671875,
            "num_run": 767,
            "train_loss": 1.1678199115759968,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 767,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "True",
            "feature_preprocessor:fast_ica:n_components": 980
        },
        "cost": 0.0,
        "time": 0.1094818115234375,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/fast_ica.py\", line 59, in transform\n    return self.preprocessor.transform(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py\", line 741, in transform\n    check_is_fitted(self)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1462, in check_is_fitted\n    raise NotFittedError(msg % {\"name\": type(estimator).__name__})\nsklearn.exceptions.NotFittedError: This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
            "error": "NotFittedError(\"This FastICA instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\")",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 768,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7563210392905648,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.28757418406654817,
            "feature_preprocessor:kitchen_sinks:gamma": 0.00827670937897672,
            "feature_preprocessor:kitchen_sinks:n_components": 109
        },
        "cost": 0.0,
        "time": 0.11123394966125488,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 769,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003134244018766997,
            "feature_preprocessor:select_rates_classification:alpha": 0.49679804858105764,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13782501220703125,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 770,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008105695825821999,
            "feature_preprocessor:select_rates_classification:alpha": 0.05531470819830696,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.13785409927368164,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 771,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.05103617216205004,
            "feature_preprocessor:fast_ica:algorithm": "parallel",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 1.2483838137826997,
        "time": 1.2838411331176758,
        "additional_info": {
            "duration": 1.2725589275360107,
            "num_run": 772,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 772,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0007718805587643025,
            "feature_preprocessor:select_rates_classification:alpha": 0.034160312240372775,
            "feature_preprocessor:select_rates_classification:score_func": "mutual_info_classif"
        },
        "cost": 1.2305980296521821,
        "time": 0.22202205657958984,
        "additional_info": {
            "duration": 0.21220111846923828,
            "num_run": 773,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 773,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.00013671586573731938,
            "feature_preprocessor:select_percentile_classification:percentile": 55.48483570688829,
            "feature_preprocessor:select_percentile_classification:score_func": "f_classif"
        },
        "cost": 1.240071256489433,
        "time": 0.2173919677734375,
        "additional_info": {
            "duration": 0.20337820053100586,
            "num_run": 774,
            "train_loss": 1.171056614444349,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 774,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.17765672776497524,
            "feature_preprocessor:select_rates_classification:alpha": 0.10149293988723626,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.11115503311157227,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 775,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "minmax",
            "feature_preprocessor:__choice__": "kernel_pca",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:kernel_pca:kernel": "sigmoid",
            "feature_preprocessor:kernel_pca:n_components": 1334,
            "feature_preprocessor:kernel_pca:coef0": 0.10624645159071044
        },
        "cost": 0.0,
        "time": 0.18236613273620605,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kernel_pca.py\", line 50, in fit\n    self.preprocessor.fit(X)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 437, in fit\n    self._fit_transform(K)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/decomposition/_kernel_pca.py\", line 361, in _fit_transform\n    self.eigenvalues_ = _check_psd_eigenvalues(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1753, in _check_psd_eigenvalues\n    raise ValueError(\nValueError: There are significant negative eigenvalues (0.256824 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
            "error": "ValueError('There are significant negative eigenvalues (0.256824 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 776,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.366177961852382,
            "feature_preprocessor:select_rates_classification:alpha": 0.09129674848284654,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.13859295845031738,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 777,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010365087492926917
        },
        "cost": 1.2305980296521821,
        "time": 0.22598004341125488,
        "additional_info": {
            "duration": 0.21004319190979004,
            "num_run": 778,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 778,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "standardize",
            "feature_preprocessor:__choice__": "polynomial",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.02482826991583654,
            "feature_preprocessor:polynomial:degree": 2,
            "feature_preprocessor:polynomial:include_bias": "False",
            "feature_preprocessor:polynomial:interaction_only": "True"
        },
        "cost": 1.2670599120182233,
        "time": 0.20765328407287598,
        "additional_info": {
            "duration": 0.1871488094329834,
            "num_run": 779,
            "train_loss": 1.0479019883554166,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 779,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:pca:keep_variance": 0.8613663005848633,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2339162949467928,
        "time": 0.24840807914733887,
        "additional_info": {
            "duration": 0.23078608512878418,
            "num_run": 780,
            "train_loss": 1.1720018696208456,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 780,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010332986475382032,
            "feature_preprocessor:select_rates_classification:alpha": 0.02892949435585703,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 1.2297926031093513,
        "time": 0.22483110427856445,
        "additional_info": {
            "duration": 0.20651817321777344,
            "num_run": 781,
            "train_loss": 1.1678199115759968,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 781,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "power_transformer",
            "feature_preprocessor:__choice__": "nystroem_sampler",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:nystroem_sampler:kernel": "poly",
            "feature_preprocessor:nystroem_sampler:n_components": 126,
            "feature_preprocessor:nystroem_sampler:coef0": -0.9265953820931572,
            "feature_preprocessor:nystroem_sampler:degree": 3,
            "feature_preprocessor:nystroem_sampler:gamma": 0.0010814853459425759
        },
        "cost": 1.2465854822245659,
        "time": 0.27782297134399414,
        "additional_info": {
            "duration": 0.26583027839660645,
            "num_run": 782,
            "train_loss": 1.1742933173127015,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 782,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 10.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.13024489783957832,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "average",
            "feature_preprocessor:feature_agglomeration:n_clusters": 246,
            "feature_preprocessor:feature_agglomeration:pooling_func": "median"
        },
        "cost": 1.2296228279850008,
        "time": 0.3234219551086426,
        "additional_info": {
            "duration": 0.31230902671813965,
            "num_run": 783,
            "train_loss": 1.1744041512286223,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 783,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "fast_ica",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.009937502913367788,
            "feature_preprocessor:fast_ica:algorithm": "deflation",
            "feature_preprocessor:fast_ica:fun": "exp",
            "feature_preprocessor:fast_ica:whiten": "False"
        },
        "cost": 0.0,
        "time": 6.115673065185547,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 105, in fit\n    self.fit_estimator(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 123, in fit_estimator\n    self._final_estimator.fit(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/evaluation/german/german_LRG_EOD_age.py\", line 238, in fit\n    self.estimator.fit(X, y)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1207, in fit\n    X, y = self._validate_data(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1147, in check_X_y\n    X = check_array(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n    _assert_all_finite(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
            "error": "ValueError('Input X contains NaN.\\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 784,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "liblinear_svc_preprocessor",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:liblinear_svc_preprocessor:C": 4.3434793149076745,
            "feature_preprocessor:liblinear_svc_preprocessor:dual": "False",
            "feature_preprocessor:liblinear_svc_preprocessor:fit_intercept": "True",
            "feature_preprocessor:liblinear_svc_preprocessor:intercept_scaling": 1,
            "feature_preprocessor:liblinear_svc_preprocessor:loss": "squared_hinge",
            "feature_preprocessor:liblinear_svc_preprocessor:multi_class": "ovr",
            "feature_preprocessor:liblinear_svc_preprocessor:penalty": "l1",
            "feature_preprocessor:liblinear_svc_preprocessor:tol": 0.0002456134995714265
        },
        "cost": 1.2305980296521821,
        "time": 0.15487003326416016,
        "additional_info": {
            "duration": 0.14466094970703125,
            "num_run": 785,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 785,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.015439023151482057,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11487698554992676,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 786,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.3316768385818471,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.1207280158996582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 787,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.005232305185569094,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9686776911242574,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.16325227948294455
        },
        "cost": 1.2254576976643063,
        "time": 0.22064590454101562,
        "additional_info": {
            "duration": 0.20150399208068848,
            "num_run": 788,
            "train_loss": 1.217279908536644,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 788,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.14282955978344578,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.14097809791564941,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 789,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.010000000000000005,
            "feature_preprocessor:select_rates_classification:alpha": 0.03033576387133405,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13681602478027344,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 790,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.3102934141013746,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.139235258102417,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 791,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_percentile_classification",
            "classifier:CustomLRG:C": 0.0001,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_percentile_classification:percentile": 15.067926336000992,
            "feature_preprocessor:select_percentile_classification:score_func": "chi2"
        },
        "cost": 1.2305980296521821,
        "time": 0.1852428913116455,
        "additional_info": {
            "duration": 0.1750941276550293,
            "num_run": 792,
            "train_loss": 1.230448387841895,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 792,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.1573613803370816
        },
        "cost": 1.2546433768313068,
        "time": 0.19382810592651367,
        "additional_info": {
            "duration": 0.1693868637084961,
            "num_run": 793,
            "train_loss": 1.1870380766710948,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 793,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 15.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0010800178682435345,
            "feature_preprocessor:select_rates_classification:alpha": 0.09111347267576922,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13792729377746582,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 794,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.008445716124901708,
            "feature_preprocessor:select_rates_classification:alpha": 0.010048185435679181,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fdr"
        },
        "cost": 0.0,
        "time": 0.11727499961853027,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 795,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "kitchen_sinks",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.0001857290057417766,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9825831167060167,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.09771483487901832,
            "feature_preprocessor:kitchen_sinks:gamma": 2.105651235633189,
            "feature_preprocessor:kitchen_sinks:n_components": 394
        },
        "cost": 0.0,
        "time": 0.13548874855041504,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/base.py\", line 444, in fit\n    return self.choice.fit(X, y, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/kitchen_sinks.py\", line 31, in fit\n    self.preprocessor = sklearn.kernel_approximation.RBFSampler(\nTypeError: RBFSampler.__init__() takes 1 positional argument but 4 were given\n",
            "error": "TypeError('RBFSampler.__init__() takes 1 positional argument but 4 were given')",
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 796,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.048002628815573184,
            "feature_preprocessor:select_rates_classification:alpha": 0.4872905495806727,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.13785195350646973,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Random Search (sorted)"
        }
    },
    {
        "config_id": 797,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.1,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.12723701383223837,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fpr"
        },
        "cost": 0.0,
        "time": 0.11092710494995117,
        "additional_info": {
            "traceback": "Traceback (most recent call last):\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/__init__.py\", line 41, in fit_predict_try_except_decorator\n    return ta(queue=queue, **kwargs)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 1283, in eval_holdout\n    evaluator.fit_predict_and_loss(iterative=iterative)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 558, in fit_predict_and_loss\n    ) = self._partial_fit_and_predict_standard(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/train_evaluator.py\", line 945, in _partial_fit_and_predict_standard\n    _fit_and_suppress_warnings(\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/evaluation/abstract_evaluator.py\", line 174, in _fit_and_suppress_warnings\n    model.fit(X, y)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 104, in fit\n    X, fit_params = self.fit_transformer(X, y, **fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/classification.py\", line 116, in fit_transformer\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/base.py\", line 116, in fit_transformer\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/joblib/memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/sayannath/miniconda3/envs/fairness-autosklearn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 952, in _fit_transform_one\n    res = transformer.fit(X, y, **fit_params).transform(X)\n  File \"/Users/sayannath/Projects/Fair-AutoML/autosklearn/pipeline/components/feature_preprocessing/select_rates_classification.py\", line 88, in transform\n    raise ValueError(\"%s removed all features.\" % self.__class__.__name__)\nValueError: SelectClassificationRates removed all features.\n",
            "error": "ValueError('SelectClassificationRates removed all features.')",
            "configuration_origin": "Local Search"
        }
    },
    {
        "config_id": 798,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "one_hot_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "mean",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "feature_agglomeration",
            "classifier:CustomLRG:C": 5.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.003106605697542132,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.9445155671993455,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.01068940508801506,
            "feature_preprocessor:feature_agglomeration:affinity": "manhattan",
            "feature_preprocessor:feature_agglomeration:linkage": "complete",
            "feature_preprocessor:feature_agglomeration:n_clusters": 333,
            "feature_preprocessor:feature_agglomeration:pooling_func": "mean"
        },
        "cost": 1.2517258142124414,
        "time": 0.3051619529724121,
        "additional_info": {
            "duration": 0.2882802486419678,
            "num_run": 799,
            "train_loss": 1.1706883114554518,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 799,
        "configuration": {
            "balancing:strategy": "none",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "minority_coalescer",
            "data_preprocessing:numerical_transformer:imputation:strategy": "most_frequent",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "none",
            "feature_preprocessor:__choice__": "no_preprocessing",
            "classifier:CustomLRG:C": 0.01,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction": 0.043001511525526885
        },
        "cost": 1.228799698094048,
        "time": 0.21123099327087402,
        "additional_info": {
            "duration": 0.19937801361083984,
            "num_run": 800,
            "train_loss": 1.2206274453209172,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 800,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "robust_scaler",
            "feature_preprocessor:__choice__": "pca",
            "classifier:CustomLRG:C": 1.0,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max": 0.7793648577651797,
            "data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min": 0.2763442109707519,
            "feature_preprocessor:pca:keep_variance": 0.6355606154148743,
            "feature_preprocessor:pca:whiten": "False"
        },
        "cost": 1.2272560292224401,
        "time": 0.24456191062927246,
        "additional_info": {
            "duration": 0.23131680488586426,
            "num_run": 801,
            "train_loss": 1.2271562680155823,
            "configuration_origin": "Random Search"
        }
    },
    {
        "config_id": 801,
        "configuration": {
            "balancing:strategy": "weighting",
            "classifier:__choice__": "CustomLRG",
            "data_preprocessing:categorical_transformer:categorical_encoding:__choice__": "no_encoding",
            "data_preprocessing:categorical_transformer:category_coalescence:__choice__": "no_coalescense",
            "data_preprocessing:numerical_transformer:imputation:strategy": "median",
            "data_preprocessing:numerical_transformer:rescaling:__choice__": "normalize",
            "feature_preprocessor:__choice__": "select_rates_classification",
            "classifier:CustomLRG:C": 0.5,
            "classifier:CustomLRG:dual": false,
            "classifier:CustomLRG:penalty": "l2",
            "feature_preprocessor:select_rates_classification:alpha": 0.05038010914975795,
            "feature_preprocessor:select_rates_classification:score_func": "chi2",
            "feature_preprocessor:select_rates_classification:mode": "fwe"
        },
        "cost": 0.0,
        "time": 0.0,
        "additional_info": {}
    }
]